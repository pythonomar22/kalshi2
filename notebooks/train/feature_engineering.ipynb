{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-22 17:14:00,693 - INFO - feature_engineering_per_minute.<module>:37 - Kalshi data expected at: /Users/omarabul-hassan/Desktop/projects/kalshi/notebooks/data/kalshi_data\n",
      "2025-05-22 17:14:00,693 - INFO - feature_engineering_per_minute.<module>:38 - Binance data expected at: /Users/omarabul-hassan/Desktop/projects/kalshi/notebooks/data/binance_data\n",
      "2025-05-22 17:14:00,693 - INFO - feature_engineering_per_minute.<module>:39 - Per-minute decision features will be saved to: /Users/omarabul-hassan/Desktop/projects/kalshi/notebooks/features\n",
      "2025-05-22 17:14:00,694 - INFO - feature_engineering_per_minute.<module>:51 - Decision points will be generated up to T-1m before market resolution.\n",
      "2025-05-22 17:14:00,694 - INFO - feature_engineering_per_minute.<module>:52 - Using lag windows: [1, 3, 5, 10, 15, 30] minutes.\n",
      "2025-05-22 17:14:00,694 - INFO - feature_engineering_per_minute.<module>:53 - Using rolling windows: [5, 15, 30] minutes.\n",
      "2025-05-22 17:14:00,694 - INFO - feature_engineering_per_minute.<module>:54 - Debug logging for first 1 markets, first 3 decision points each.\n",
      "2025-05-22 17:14:00,695 - INFO - feature_engineering_per_minute.<module>:55 - Cell 1: Setup complete.\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Imports and Setup\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "from datetime import timezone, timedelta\n",
    "from pathlib import Path\n",
    "import logging\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "import glob\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# --- Logging Setup ---\n",
    "logger = logging.getLogger(\"feature_engineering_per_minute\")\n",
    "if not logger.handlers:\n",
    "    logger.setLevel(logging.INFO) \n",
    "    formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(name)s.%(funcName)s:%(lineno)d - %(message)s')\n",
    "    ch = logging.StreamHandler()\n",
    "    ch.setFormatter(formatter)\n",
    "    logger.addHandler(ch)\n",
    "else:\n",
    "    logger.setLevel(logging.INFO)\n",
    "\n",
    "# --- Base Directories ---\n",
    "BASE_PROJECT_DIR = Path(\"/Users/omarabul-hassan/Desktop/projects/kalshi\") \n",
    "NOTEBOOKS_DIR = BASE_PROJECT_DIR / \"notebooks\"\n",
    "DATA_DIR = NOTEBOOKS_DIR / \"data\"\n",
    "\n",
    "KALSHI_DATA_BASE_DIR = DATA_DIR / \"kalshi_data\"\n",
    "BINANCE_DATA_BASE_DIR = DATA_DIR / \"binance_data\"\n",
    "FEATURES_OUTPUT_DIR = NOTEBOOKS_DIR / \"features\"\n",
    "\n",
    "FEATURES_OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "logger.info(f\"Kalshi data expected at: {KALSHI_DATA_BASE_DIR}\")\n",
    "logger.info(f\"Binance data expected at: {BINANCE_DATA_BASE_DIR}\")\n",
    "logger.info(f\"Per-minute decision features will be saved to: {FEATURES_OUTPUT_DIR}\")\n",
    "\n",
    "# --- Constants ---\n",
    "MIN_MINUTES_BEFORE_RESOLUTION_FOR_DECISION = 1\n",
    "LAG_WINDOWS_MINUTES = [1, 3, 5, 10, 15, 30] \n",
    "ROLLING_WINDOWS_MINUTES = [5, 15, 30]\n",
    "\n",
    "# For detailed debugging of BTC price fetching for the first N original markets AND their first few decision points\n",
    "DEBUG_FIRST_N_ORIG_MARKETS = 1 # Set >0 for targeted debug logs\n",
    "DEBUG_FIRST_N_DECISION_POINTS_PER_MARKET = 3 # How many decision points to log for for the debugged markets\n",
    "debug_orig_market_count = 0 # Counter for markets being debugged\n",
    "\n",
    "logger.info(f\"Decision points will be generated up to T-{MIN_MINUTES_BEFORE_RESOLUTION_FOR_DECISION}m before market resolution.\")\n",
    "logger.info(f\"Using lag windows: {LAG_WINDOWS_MINUTES} minutes.\")\n",
    "logger.info(f\"Using rolling windows: {ROLLING_WINDOWS_MINUTES} minutes.\")\n",
    "logger.info(f\"Debug logging for first {DEBUG_FIRST_N_ORIG_MARKETS} markets, first {DEBUG_FIRST_N_DECISION_POINTS_PER_MARKET} decision points each.\")\n",
    "logger.info(\"Cell 1: Setup complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-22 17:14:00,709 - INFO - feature_engineering_per_minute.<module>:145 - Cell 2: Utility functions defined/updated.\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Utility Functions (Data Loading & Parsing)\n",
    "\n",
    "_binance_day_data_cache = {}\n",
    "_kalshi_market_data_cache = {} \n",
    "\n",
    "def clear_all_caches():\n",
    "    global _binance_day_data_cache, _kalshi_market_data_cache, debug_orig_market_count # Use new counter\n",
    "    _binance_day_data_cache = {}\n",
    "    _kalshi_market_data_cache = {}\n",
    "    debug_orig_market_count = 0 # Reset this counter\n",
    "    logger.info(\"Cleared Binance, Kalshi caches and debug_orig_market_count.\")\n",
    "\n",
    "def load_binance_day_data(date_str_yyyy_mm_dd: str) -> pd.DataFrame | None:\n",
    "    global _binance_day_data_cache\n",
    "    # Return cache if available\n",
    "    if date_str_yyyy_mm_dd in _binance_day_data_cache:\n",
    "        return _binance_day_data_cache[date_str_yyyy_mm_dd]\n",
    "\n",
    "    filename_base = f\"BTCUSDT-1m-{date_str_yyyy_mm_dd}\"\n",
    "    filepath = BINANCE_DATA_BASE_DIR / f\"{filename_base}.csv\"\n",
    "    if not filepath.exists():\n",
    "        _binance_day_data_cache[date_str_yyyy_mm_dd] = None\n",
    "        return None\n",
    "\n",
    "    try:\n",
    "        # --- 1. Read CSV ---\n",
    "        column_names = [\n",
    "            \"open_time_raw\", \"open\", \"high\", \"low\", \"close\", \"volume\",\n",
    "            \"close_time_ms_raw\", \"quote_asset_volume\", \"number_of_trades\",\n",
    "            \"taker_buy_base_asset_volume\", \"taker_buy_quote_asset_volume\", \"ignore\"\n",
    "        ]\n",
    "        df = pd.read_csv(filepath, header=None, names=column_names, low_memory=False)\n",
    "        if df.empty:\n",
    "            logger.warning(f\"[LOAD_BINANCE] File is empty: {filepath}\")\n",
    "            _binance_day_data_cache[date_str_yyyy_mm_dd] = None\n",
    "            return None\n",
    "\n",
    "        # --- 2. Detect units of open_time_raw and convert to seconds ---\n",
    "        first_raw = df[\"open_time_raw\"].iloc[0]\n",
    "        # MICROSECONDS (≈1e15), MILLISECONDS (≈1e12), or SECONDS (≈1e9)\n",
    "        if first_raw > 1e14:\n",
    "            logger.info(f\"[LOAD_BINANCE DEBUG {filepath.name}] Detected MICROSECONDS. Dividing by 1,000,000.\")\n",
    "            df[\"timestamp_s\"] = df[\"open_time_raw\"] // 1_000_000\n",
    "        elif 1e12 < first_raw <= 1e14:\n",
    "            logger.info(f\"[LOAD_BINANCE DEBUG {filepath.name}] Detected MILLISECONDS. Dividing by 1,000.\")\n",
    "            df[\"timestamp_s\"] = df[\"open_time_raw\"] // 1_000\n",
    "        elif 1e9 < first_raw <= 1e10:\n",
    "            logger.info(f\"[LOAD_BINANCE DEBUG {filepath.name}] Detected SECONDS. Using as is.\")\n",
    "            df[\"timestamp_s\"] = df[\"open_time_raw\"]\n",
    "        else:\n",
    "            logger.warning(f\"[LOAD_BINANCE WARNING {filepath.name}] Unusual timestamp magnitude: {first_raw}. Attempting to use as is.\")\n",
    "            df[\"timestamp_s\"] = df[\"open_time_raw\"]\n",
    "\n",
    "        # --- 3. Set index, sort, and coerce numerics ---\n",
    "        df.set_index(\"timestamp_s\", inplace=True)\n",
    "        if not df.index.is_monotonic_increasing:\n",
    "            df.sort_index(inplace=True)\n",
    "\n",
    "        for col in [\"open\", \"high\", \"low\", \"close\", \"volume\"]:\n",
    "            df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
    "\n",
    "        # --- 4. Cache and return ---\n",
    "        _binance_day_data_cache[date_str_yyyy_mm_dd] = df\n",
    "        return df\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"[LOAD_BINANCE] Error loading Binance data from {filepath}: {e}\", exc_info=True)\n",
    "        _binance_day_data_cache[date_str_yyyy_mm_dd] = None\n",
    "        return None\n",
    "\n",
    "\n",
    "\n",
    "def get_btc_kline_at_or_before_ts(target_timestamp_s: int, current_market_ticker_for_debug: str = None, decision_point_count_for_debug: int = 0) -> pd.Series | None:\n",
    "    global debug_orig_market_count \n",
    "    target_dt_utc = dt.datetime.fromtimestamp(target_timestamp_s, tz=timezone.utc); date_str_needed = target_dt_utc.strftime(\"%Y-%m-%d\")\n",
    "    perform_debug_logging = (DEBUG_FIRST_N_ORIG_MARKETS > 0 and current_market_ticker_for_debug is not None and \n",
    "                             debug_orig_market_count < DEBUG_FIRST_N_ORIG_MARKETS and\n",
    "                             decision_point_count_for_debug < DEBUG_FIRST_N_DECISION_POINTS_PER_MARKET)\n",
    "    if perform_debug_logging: logger.info(f\"[DEBUG BTC KLINE Market: {current_market_ticker_for_debug} (Overall #{debug_orig_market_count}), DecisionPt#{decision_point_count_for_debug}] Request kline for ts: {target_timestamp_s} ({target_dt_utc.isoformat()})\")\n",
    "    binance_df = load_binance_day_data(date_str_needed)\n",
    "    if binance_df is None or binance_df.empty:\n",
    "        if target_dt_utc.hour == 0 and target_dt_utc.minute < 5: \n",
    "            prev_date_dt_utc = target_dt_utc - timedelta(days=1); prev_date_str = prev_date_dt_utc.strftime(\"%Y-%m-%d\")\n",
    "            binance_df_prev = load_binance_day_data(prev_date_str)\n",
    "            if binance_df_prev is not None and not binance_df_prev.empty:\n",
    "                idx_pos_prev = binance_df_prev.index.searchsorted(target_timestamp_s, side='right')\n",
    "                if idx_pos_prev > 0:\n",
    "                    kline_data = binance_df_prev.iloc[idx_pos_prev - 1]\n",
    "                    if kline_data.name <= target_timestamp_s: return kline_data # Check against lookahead\n",
    "        return None\n",
    "    try:\n",
    "        idx_pos = binance_df.index.searchsorted(target_timestamp_s, side='right')\n",
    "        if idx_pos == 0: return None\n",
    "        kline_data = binance_df.iloc[idx_pos - 1]\n",
    "        if kline_data.name > target_timestamp_s: logger.error(f\"LOOKAHEAD (get_btc_kline)! Kline ts {kline_data.name} > target {target_timestamp_s}\"); return None \n",
    "        if perform_debug_logging: logger.info(f\"[DEBUG BTC KLINE Market: {current_market_ticker_for_debug}] Found kline ending ts {kline_data.name} for target {target_timestamp_s}\")\n",
    "        return kline_data\n",
    "    except Exception: return None\n",
    "\n",
    "def get_kalshi_candle_at_or_before_ts(market_df: pd.DataFrame, target_timestamp_s: int) -> pd.Series | None:\n",
    "    if market_df is None or market_df.empty: return None\n",
    "    try:\n",
    "        idx_pos = market_df.index.searchsorted(target_timestamp_s, side='right')\n",
    "        if idx_pos == 0: return None\n",
    "        candle_data = market_df.iloc[idx_pos - 1]\n",
    "        if candle_data.name > target_timestamp_s: logger.error(f\"LOOKAHEAD (get_kalshi_candle)! Candle ts {candle_data.name} > target {target_timestamp_s}\"); return None\n",
    "        if target_timestamp_s - candle_data.name > (3 * 60): return None \n",
    "        return candle_data\n",
    "    except Exception: return None\n",
    "\n",
    "def get_event_details_from_ticker(ticker_string: str | None) -> dict | None:\n",
    "    if not ticker_string: return None\n",
    "    m = re.match(r\"^(.*?)-(\\d{2}[A-Z]{3}\\d{2})(\\d{2})(?:-(T(\\d+\\.?\\d*)))?$\", ticker_string) or \\\n",
    "        re.match(r\"^(.*?)-(\\d{2}[A-Z]{3}\\d{2})(\\d{2})$\", ticker_string)\n",
    "    if not m: return None\n",
    "    g = m.groups(); strike = float(g[4]) if len(g) >=5 and g[4] else None\n",
    "    return {\"series\":g[0],\"date_str_yymmmdd\":g[1],\"hour_str_edt\":g[2],\"strike_price_from_ticker\":strike}\n",
    "\n",
    "def parse_iso_to_unix_timestamp(ds: str|None) -> int|None:\n",
    "    if not ds: return None\n",
    "    try:\n",
    "        dt_obj = dt.datetime.fromisoformat(ds.replace('Z','+00:00')) if ds.endswith('Z') else dt.datetime.fromisoformat(ds)\n",
    "        return int((dt_obj.replace(tzinfo=timezone.utc) if dt_obj.tzinfo is None else dt_obj).timestamp())\n",
    "    except Exception: return None\n",
    "\n",
    "def load_kalshi_market_data(market_ticker: str) -> pd.DataFrame | None:\n",
    "    global _kalshi_market_data_cache\n",
    "    if market_ticker in _kalshi_market_data_cache: return _kalshi_market_data_cache[market_ticker]\n",
    "    details = get_event_details_from_ticker(market_ticker)\n",
    "    if not details: return None\n",
    "    fp = KALSHI_DATA_BASE_DIR/details['date_str_yymmmdd']/(details['hour_str_edt'].zfill(2))/f\"{market_ticker}.csv\"\n",
    "    if not fp.exists(): return None\n",
    "    try:\n",
    "        df = pd.read_csv(fp, low_memory=False); _kalshi_market_data_cache[market_ticker] = df\n",
    "        if df.empty: return None\n",
    "        df['timestamp_s'] = pd.to_numeric(df['timestamp_s'], errors='coerce').astype('Int64'); df.dropna(subset=['timestamp_s'], inplace=True) \n",
    "        df.set_index('timestamp_s', inplace=True); \n",
    "        if not df.index.is_monotonic_increasing: df.sort_index(inplace=True)\n",
    "        cols = [c for c in df.columns if 'cents' in c]; df[cols] = df[cols].apply(pd.to_numeric, errors='coerce') / 100.0\n",
    "        for v_col in ['volume', 'open_interest']: \n",
    "            if v_col in df.columns: df[v_col] = pd.to_numeric(df[v_col], errors='coerce')\n",
    "        return df\n",
    "    except Exception as e: logger.error(f\"Err load Kalshi {fp}: {e}\", exc_info=True); return None\n",
    "\n",
    "logger.info(\"Cell 2: Utility functions defined/updated.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-22 17:14:00,721 - INFO - feature_engineering_per_minute.<module>:14 - Using NTM outcomes manifest from: /Users/omarabul-hassan/Desktop/projects/kalshi/notebooks/data/kalshi_data/kalshi_btc_hourly_NTM_filtered_market_outcomes_20250519_014250.csv\n",
      "2025-05-22 17:14:00,730 - INFO - feature_engineering_per_minute.<module>:17 - Loaded NTM outcomes manifest with 9192 markets initially.\n",
      "2025-05-22 17:14:00,745 - INFO - feature_engineering_per_minute.<module>:30 - Processed NTM outcomes. 9192 markets remain for feature engineering.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>market_ticker</th>\n",
       "      <th>result</th>\n",
       "      <th>event_resolution_time_iso</th>\n",
       "      <th>reference_btc_price_for_ntm</th>\n",
       "      <th>kalshi_strike_price</th>\n",
       "      <th>market_open_time_iso</th>\n",
       "      <th>market_close_time_iso</th>\n",
       "      <th>event_ticker_parent</th>\n",
       "      <th>target</th>\n",
       "      <th>resolution_time_ts</th>\n",
       "      <th>market_open_ts</th>\n",
       "      <th>market_close_ts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KXBTCD-25MAY1522-T106249.99</td>\n",
       "      <td>no</td>\n",
       "      <td>2025-05-16T02:00:00+00:00</td>\n",
       "      <td>103709.1</td>\n",
       "      <td>106249.99</td>\n",
       "      <td>2025-05-16T01:00:00+00:00</td>\n",
       "      <td>2025-05-16T02:00:00+00:00</td>\n",
       "      <td>KXBTCD-25MAY1522</td>\n",
       "      <td>0</td>\n",
       "      <td>1747360800</td>\n",
       "      <td>1747357200</td>\n",
       "      <td>1747360800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KXBTCD-25MAY1522-T105999.99</td>\n",
       "      <td>no</td>\n",
       "      <td>2025-05-16T02:00:00+00:00</td>\n",
       "      <td>103709.1</td>\n",
       "      <td>105999.99</td>\n",
       "      <td>2025-05-16T01:00:00+00:00</td>\n",
       "      <td>2025-05-16T02:00:00+00:00</td>\n",
       "      <td>KXBTCD-25MAY1522</td>\n",
       "      <td>0</td>\n",
       "      <td>1747360800</td>\n",
       "      <td>1747357200</td>\n",
       "      <td>1747360800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KXBTCD-25MAY1522-T105749.99</td>\n",
       "      <td>no</td>\n",
       "      <td>2025-05-16T02:00:00+00:00</td>\n",
       "      <td>103709.1</td>\n",
       "      <td>105749.99</td>\n",
       "      <td>2025-05-16T01:00:00+00:00</td>\n",
       "      <td>2025-05-16T02:00:00+00:00</td>\n",
       "      <td>KXBTCD-25MAY1522</td>\n",
       "      <td>0</td>\n",
       "      <td>1747360800</td>\n",
       "      <td>1747357200</td>\n",
       "      <td>1747360800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>KXBTCD-25MAY1522-T105499.99</td>\n",
       "      <td>no</td>\n",
       "      <td>2025-05-16T02:00:00+00:00</td>\n",
       "      <td>103709.1</td>\n",
       "      <td>105499.99</td>\n",
       "      <td>2025-05-16T01:00:00+00:00</td>\n",
       "      <td>2025-05-16T02:00:00+00:00</td>\n",
       "      <td>KXBTCD-25MAY1522</td>\n",
       "      <td>0</td>\n",
       "      <td>1747360800</td>\n",
       "      <td>1747357200</td>\n",
       "      <td>1747360800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>KXBTCD-25MAY1522-T105249.99</td>\n",
       "      <td>no</td>\n",
       "      <td>2025-05-16T02:00:00+00:00</td>\n",
       "      <td>103709.1</td>\n",
       "      <td>105249.99</td>\n",
       "      <td>2025-05-16T01:00:00+00:00</td>\n",
       "      <td>2025-05-16T02:00:00+00:00</td>\n",
       "      <td>KXBTCD-25MAY1522</td>\n",
       "      <td>0</td>\n",
       "      <td>1747360800</td>\n",
       "      <td>1747357200</td>\n",
       "      <td>1747360800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 market_ticker result  event_resolution_time_iso  \\\n",
       "0  KXBTCD-25MAY1522-T106249.99     no  2025-05-16T02:00:00+00:00   \n",
       "1  KXBTCD-25MAY1522-T105999.99     no  2025-05-16T02:00:00+00:00   \n",
       "2  KXBTCD-25MAY1522-T105749.99     no  2025-05-16T02:00:00+00:00   \n",
       "3  KXBTCD-25MAY1522-T105499.99     no  2025-05-16T02:00:00+00:00   \n",
       "4  KXBTCD-25MAY1522-T105249.99     no  2025-05-16T02:00:00+00:00   \n",
       "\n",
       "   reference_btc_price_for_ntm  kalshi_strike_price  \\\n",
       "0                     103709.1            106249.99   \n",
       "1                     103709.1            105999.99   \n",
       "2                     103709.1            105749.99   \n",
       "3                     103709.1            105499.99   \n",
       "4                     103709.1            105249.99   \n",
       "\n",
       "        market_open_time_iso      market_close_time_iso event_ticker_parent  \\\n",
       "0  2025-05-16T01:00:00+00:00  2025-05-16T02:00:00+00:00    KXBTCD-25MAY1522   \n",
       "1  2025-05-16T01:00:00+00:00  2025-05-16T02:00:00+00:00    KXBTCD-25MAY1522   \n",
       "2  2025-05-16T01:00:00+00:00  2025-05-16T02:00:00+00:00    KXBTCD-25MAY1522   \n",
       "3  2025-05-16T01:00:00+00:00  2025-05-16T02:00:00+00:00    KXBTCD-25MAY1522   \n",
       "4  2025-05-16T01:00:00+00:00  2025-05-16T02:00:00+00:00    KXBTCD-25MAY1522   \n",
       "\n",
       "   target  resolution_time_ts  market_open_ts  market_close_ts  \n",
       "0       0          1747360800      1747357200       1747360800  \n",
       "1       0          1747360800      1747357200       1747360800  \n",
       "2       0          1747360800      1747357200       1747360800  \n",
       "3       0          1747360800      1747357200       1747360800  \n",
       "4       0          1747360800      1747357200       1747360800  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-22 17:14:00,749 - INFO - feature_engineering_per_minute.<module>:34 - Cell 3: NTM Outcomes Manifest loading complete.\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Load NTM Outcomes Manifest\n",
    "# (Same as your previous version that successfully loaded 9192 markets)\n",
    "\n",
    "list_of_outcome_files = sorted(\n",
    "    glob.glob(str(KALSHI_DATA_BASE_DIR / \"kalshi_btc_hourly_NTM_filtered_market_outcomes_*.csv\")),\n",
    "    key=os.path.getctime,\n",
    "    reverse=True \n",
    ")\n",
    "ntm_outcomes_df = pd.DataFrame() \n",
    "if not list_of_outcome_files:\n",
    "    logger.critical(f\"CRITICAL: No NTM outcome CSV files found in {KALSHI_DATA_BASE_DIR}.\")\n",
    "else:\n",
    "    LATEST_NTM_OUTCOMES_CSV_PATH = Path(list_of_outcome_files[0])\n",
    "    logger.info(f\"Using NTM outcomes manifest from: {LATEST_NTM_OUTCOMES_CSV_PATH}\")\n",
    "    try:\n",
    "        ntm_outcomes_df = pd.read_csv(LATEST_NTM_OUTCOMES_CSV_PATH, low_memory=False)\n",
    "        logger.info(f\"Loaded NTM outcomes manifest with {len(ntm_outcomes_df)} markets initially.\")\n",
    "        required_cols = ['market_ticker', 'result', 'event_resolution_time_iso', 'kalshi_strike_price', 'market_open_time_iso', 'market_close_time_iso']\n",
    "        if any(col not in ntm_outcomes_df.columns for col in required_cols):\n",
    "            logger.critical(f\"NTM outcomes CSV is missing required columns.\"); ntm_outcomes_df = pd.DataFrame() \n",
    "        if not ntm_outcomes_df.empty:\n",
    "            ntm_outcomes_df['target'] = ntm_outcomes_df['result'].astype(str).str.upper().apply(lambda x: 1 if x=='YES' else (0 if x=='NO' else np.nan))\n",
    "            ntm_outcomes_df.dropna(subset=['target'], inplace=True)\n",
    "            if not ntm_outcomes_df.empty:\n",
    "                ntm_outcomes_df['target'] = ntm_outcomes_df['target'].astype(int)\n",
    "                for col, func_col_name in {'resolution_time_ts':'event_resolution_time_iso', 'market_open_ts':'market_open_time_iso', 'market_close_ts':'market_close_time_iso'}.items():\n",
    "                    ntm_outcomes_df[col] = ntm_outcomes_df[func_col_name].apply(parse_iso_to_unix_timestamp)\n",
    "                ntm_outcomes_df['kalshi_strike_price'] = pd.to_numeric(ntm_outcomes_df['kalshi_strike_price'], errors='coerce')\n",
    "                ntm_outcomes_df.dropna(subset=['market_ticker', 'resolution_time_ts', 'market_open_ts', 'market_close_ts', 'kalshi_strike_price', 'target'], how='any', inplace=True)\n",
    "                logger.info(f\"Processed NTM outcomes. {len(ntm_outcomes_df)} markets remain for feature engineering.\")\n",
    "                if not ntm_outcomes_df.empty: display(ntm_outcomes_df.head())\n",
    "    except Exception as e: logger.critical(f\"Error loading NTM outcomes CSV: {e}\", exc_info=True); ntm_outcomes_df = pd.DataFrame() \n",
    "if ntm_outcomes_df.empty: logger.warning(\"No NTM markets loaded. Feature engineering will not proceed.\")\n",
    "logger.info(\"Cell 3: NTM Outcomes Manifest loading complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-22 17:14:00,763 - INFO - feature_engineering_per_minute.<module>:8 - Starting PER-MINUTE feature engineering for 9192 NTM markets...\n",
      "2025-05-22 17:14:00,764 - INFO - feature_engineering_per_minute.clear_all_caches:11 - Cleared Binance, Kalshi caches and debug_orig_market_count.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc17bd0511d64a11a4e855a3e2bb45e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing NTM Markets:   0%|          | 0/9192 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-22 17:14:00,779 - INFO - feature_engineering_per_minute.<module>:23 - --- Debugging Market #0: KXBTCD-25MAY1522-T106249.99 ---\n",
      "2025-05-22 17:14:00,785 - INFO - feature_engineering_per_minute.get_btc_kline_at_or_before_ts:79 - [DEBUG BTC KLINE Market: KXBTCD-25MAY1522-T106249.99 (Overall #0), DecisionPt#0] Request kline for ts: 1747357260 (2025-05-16T01:01:00+00:00)\n",
      "2025-05-22 17:14:00,787 - INFO - feature_engineering_per_minute.load_binance_day_data:42 - [LOAD_BINANCE DEBUG BTCUSDT-1m-2025-05-16.csv] Detected MICROSECONDS. Dividing by 1,000,000.\n",
      "2025-05-22 17:14:00,788 - INFO - feature_engineering_per_minute.get_btc_kline_at_or_before_ts:96 - [DEBUG BTC KLINE Market: KXBTCD-25MAY1522-T106249.99] Found kline ending ts 1747357260 for target 1747357260\n",
      "2025-05-22 17:14:00,789 - INFO - feature_engineering_per_minute.<module>:99 -   [DEBUG] BTC History for KXBTCD-25MAY1522-T106249.99 @ decision 1747357260 (kline_ts 1747357260):\n",
      "2025-05-22 17:14:00,789 - INFO - feature_engineering_per_minute.<module>:100 -   [DEBUG]   Needed from: 2025-05-16T00:26:00+00:00\n",
      "2025-05-22 17:14:00,790 - INFO - feature_engineering_per_minute.<module>:101 -   [DEBUG]   Series len: 36, min_ts: 2025-05-16T00:26:00+00:00, max_ts: 2025-05-16T01:01:00+00:00\n",
      "2025-05-22 17:14:00,791 - INFO - feature_engineering_per_minute.<module>:117 -   [DEBUG]   Lag 1m: target_ts=2025-05-16T01:00:00+00:00, past_price=103709.1, calc_pct=0.0007382187291182516\n",
      "2025-05-22 17:14:00,791 - INFO - feature_engineering_per_minute.<module>:117 -   [DEBUG]   Lag 3m: target_ts=2025-05-16T00:58:00+00:00, past_price=103739.55, calc_pct=0.00044447850409993665\n",
      "2025-05-22 17:14:00,792 - INFO - feature_engineering_per_minute.<module>:117 -   [DEBUG]   Lag 5m: target_ts=2025-05-16T00:56:00+00:00, past_price=103702.45, calc_pct=0.0008023918432014519\n",
      "2025-05-22 17:14:00,792 - INFO - feature_engineering_per_minute.<module>:117 -   [DEBUG]   Lag 10m: target_ts=2025-05-16T00:51:00+00:00, past_price=103777.77, calc_pct=7.602784295711323e-05\n",
      "2025-05-22 17:14:00,792 - INFO - feature_engineering_per_minute.<module>:117 -   [DEBUG]   Lag 15m: target_ts=2025-05-16T00:46:00+00:00, past_price=103899.76, calc_pct=-0.0010981738552619494\n",
      "2025-05-22 17:14:00,793 - INFO - feature_engineering_per_minute.<module>:117 -   [DEBUG]   Lag 30m: target_ts=2025-05-16T00:31:00+00:00, past_price=103894.92, calc_pct=-0.0010516394834318634\n",
      "2025-05-22 17:14:00,793 - INFO - feature_engineering_per_minute.<module>:132 -   [DEBUG]   Roll 5m: std_val=30.572030191009425, assigned_feature=30.572030191009425\n",
      "2025-05-22 17:14:00,793 - INFO - feature_engineering_per_minute.<module>:132 -   [DEBUG]   Roll 15m: std_val=79.3776278185194, assigned_feature=79.3776278185194\n",
      "2025-05-22 17:14:00,793 - INFO - feature_engineering_per_minute.<module>:132 -   [DEBUG]   Roll 30m: std_val=113.56189185162296, assigned_feature=113.56189185162296\n",
      "2025-05-22 17:14:00,794 - INFO - feature_engineering_per_minute.get_btc_kline_at_or_before_ts:79 - [DEBUG BTC KLINE Market: KXBTCD-25MAY1522-T106249.99 (Overall #0), DecisionPt#1] Request kline for ts: 1747357320 (2025-05-16T01:02:00+00:00)\n",
      "2025-05-22 17:14:00,794 - INFO - feature_engineering_per_minute.get_btc_kline_at_or_before_ts:96 - [DEBUG BTC KLINE Market: KXBTCD-25MAY1522-T106249.99] Found kline ending ts 1747357320 for target 1747357320\n",
      "2025-05-22 17:14:00,795 - INFO - feature_engineering_per_minute.<module>:99 -   [DEBUG] BTC History for KXBTCD-25MAY1522-T106249.99 @ decision 1747357320 (kline_ts 1747357320):\n",
      "2025-05-22 17:14:00,795 - INFO - feature_engineering_per_minute.<module>:100 -   [DEBUG]   Needed from: 2025-05-16T00:27:00+00:00\n",
      "2025-05-22 17:14:00,795 - INFO - feature_engineering_per_minute.<module>:101 -   [DEBUG]   Series len: 36, min_ts: 2025-05-16T00:27:00+00:00, max_ts: 2025-05-16T01:02:00+00:00\n",
      "2025-05-22 17:14:00,796 - INFO - feature_engineering_per_minute.<module>:117 -   [DEBUG]   Lag 1m: target_ts=2025-05-16T01:01:00+00:00, past_price=103785.66, calc_pct=-0.0009096632424942279\n",
      "2025-05-22 17:14:00,796 - INFO - feature_engineering_per_minute.<module>:117 -   [DEBUG]   Lag 3m: target_ts=2025-05-16T00:59:00+00:00, past_price=103764.81, calc_pct=-0.0007089108533037132\n",
      "2025-05-22 17:14:00,796 - INFO - feature_engineering_per_minute.<module>:117 -   [DEBUG]   Lag 5m: target_ts=2025-05-16T00:57:00+00:00, past_price=103725.65, calc_pct=-0.0003316441015312431\n",
      "2025-05-22 17:14:00,796 - INFO - feature_engineering_per_minute.<module>:117 -   [DEBUG]   Lag 10m: target_ts=2025-05-16T00:52:00+00:00, past_price=103685.34, calc_pct=5.6999379082939716e-05\n",
      "2025-05-22 17:14:00,796 - INFO - feature_engineering_per_minute.<module>:117 -   [DEBUG]   Lag 15m: target_ts=2025-05-16T00:47:00+00:00, past_price=103919.14, calc_pct=-0.0021929550225300116\n",
      "2025-05-22 17:14:00,796 - INFO - feature_engineering_per_minute.<module>:117 -   [DEBUG]   Lag 30m: target_ts=2025-05-16T00:32:00+00:00, past_price=103976.99, calc_pct=-0.0027481080188992315\n",
      "2025-05-22 17:14:00,797 - INFO - feature_engineering_per_minute.<module>:132 -   [DEBUG]   Roll 5m: std_val=38.77305546381365, assigned_feature=38.77305546381365\n",
      "2025-05-22 17:14:00,797 - INFO - feature_engineering_per_minute.<module>:132 -   [DEBUG]   Roll 15m: std_val=69.4087131074929, assigned_feature=69.4087131074929\n",
      "2025-05-22 17:14:00,797 - INFO - feature_engineering_per_minute.<module>:132 -   [DEBUG]   Roll 30m: std_val=115.61295530356067, assigned_feature=115.61295530356067\n",
      "2025-05-22 17:14:00,797 - INFO - feature_engineering_per_minute.get_btc_kline_at_or_before_ts:79 - [DEBUG BTC KLINE Market: KXBTCD-25MAY1522-T106249.99 (Overall #0), DecisionPt#2] Request kline for ts: 1747357380 (2025-05-16T01:03:00+00:00)\n",
      "2025-05-22 17:14:00,798 - INFO - feature_engineering_per_minute.get_btc_kline_at_or_before_ts:96 - [DEBUG BTC KLINE Market: KXBTCD-25MAY1522-T106249.99] Found kline ending ts 1747357380 for target 1747357380\n",
      "2025-05-22 17:14:00,799 - INFO - feature_engineering_per_minute.<module>:99 -   [DEBUG] BTC History for KXBTCD-25MAY1522-T106249.99 @ decision 1747357380 (kline_ts 1747357380):\n",
      "2025-05-22 17:14:00,799 - INFO - feature_engineering_per_minute.<module>:100 -   [DEBUG]   Needed from: 2025-05-16T00:28:00+00:00\n",
      "2025-05-22 17:14:00,799 - INFO - feature_engineering_per_minute.<module>:101 -   [DEBUG]   Series len: 36, min_ts: 2025-05-16T00:28:00+00:00, max_ts: 2025-05-16T01:03:00+00:00\n",
      "2025-05-22 17:14:00,800 - INFO - feature_engineering_per_minute.<module>:117 -   [DEBUG]   Lag 1m: target_ts=2025-05-16T01:02:00+00:00, past_price=103691.25, calc_pct=-0.0005968681060359425\n",
      "2025-05-22 17:14:00,800 - INFO - feature_engineering_per_minute.<module>:117 -   [DEBUG]   Lag 3m: target_ts=2025-05-16T01:00:00+00:00, past_price=103709.1, calc_pct=-0.0007688814192776259\n",
      "2025-05-22 17:14:00,801 - INFO - feature_engineering_per_minute.<module>:117 -   [DEBUG]   Lag 5m: target_ts=2025-05-16T00:58:00+00:00, past_price=103739.55, calc_pct=-0.001062179274924581\n",
      "2025-05-22 17:14:00,802 - INFO - feature_engineering_per_minute.<module>:117 -   [DEBUG]   Lag 10m: target_ts=2025-05-16T00:53:00+00:00, past_price=103727.78, calc_pct=-0.0009488297156267902\n",
      "2025-05-22 17:14:00,802 - INFO - feature_engineering_per_minute.<module>:117 -   [DEBUG]   Lag 15m: target_ts=2025-05-16T00:48:00+00:00, past_price=103932.97, calc_pct=-0.0029212096989049826\n",
      "2025-05-22 17:14:00,803 - INFO - feature_engineering_per_minute.<module>:117 -   [DEBUG]   Lag 30m: target_ts=2025-05-16T00:33:00+00:00, past_price=103929.31, calc_pct=-0.002886096328360085\n",
      "2025-05-22 17:14:00,803 - INFO - feature_engineering_per_minute.<module>:132 -   [DEBUG]   Roll 5m: std_val=62.051565894826695, assigned_feature=62.051565894826695\n",
      "2025-05-22 17:14:00,803 - INFO - feature_engineering_per_minute.<module>:132 -   [DEBUG]   Roll 15m: std_val=55.81513583761625, assigned_feature=55.81513583761625\n",
      "2025-05-22 17:14:00,803 - INFO - feature_engineering_per_minute.<module>:132 -   [DEBUG]   Roll 30m: std_val=121.61886762889002, assigned_feature=121.61886762889002\n",
      "2025-05-22 17:14:01,446 - INFO - feature_engineering_per_minute.load_binance_day_data:42 - [LOAD_BINANCE DEBUG BTCUSDT-1m-2025-05-15.csv] Detected MICROSECONDS. Dividing by 1,000,000.\n",
      "2025-05-22 17:14:03,980 - INFO - feature_engineering_per_minute.load_binance_day_data:42 - [LOAD_BINANCE DEBUG BTCUSDT-1m-2025-05-14.csv] Detected MICROSECONDS. Dividing by 1,000,000.\n",
      "2025-05-22 17:14:19,240 - INFO - feature_engineering_per_minute.load_binance_day_data:42 - [LOAD_BINANCE DEBUG BTCUSDT-1m-2025-05-13.csv] Detected MICROSECONDS. Dividing by 1,000,000.\n",
      "2025-05-22 17:14:34,583 - INFO - feature_engineering_per_minute.load_binance_day_data:42 - [LOAD_BINANCE DEBUG BTCUSDT-1m-2025-05-12.csv] Detected MICROSECONDS. Dividing by 1,000,000.\n",
      "2025-05-22 17:14:49,760 - INFO - feature_engineering_per_minute.load_binance_day_data:42 - [LOAD_BINANCE DEBUG BTCUSDT-1m-2025-05-11.csv] Detected MICROSECONDS. Dividing by 1,000,000.\n",
      "2025-05-22 17:15:05,111 - INFO - feature_engineering_per_minute.load_binance_day_data:42 - [LOAD_BINANCE DEBUG BTCUSDT-1m-2025-05-10.csv] Detected MICROSECONDS. Dividing by 1,000,000.\n",
      "2025-05-22 17:15:21,131 - INFO - feature_engineering_per_minute.load_binance_day_data:42 - [LOAD_BINANCE DEBUG BTCUSDT-1m-2025-05-09.csv] Detected MICROSECONDS. Dividing by 1,000,000.\n",
      "2025-05-22 17:15:37,153 - INFO - feature_engineering_per_minute.load_binance_day_data:42 - [LOAD_BINANCE DEBUG BTCUSDT-1m-2025-05-02.csv] Detected MICROSECONDS. Dividing by 1,000,000.\n",
      "2025-05-22 17:15:37,260 - INFO - feature_engineering_per_minute.load_binance_day_data:42 - [LOAD_BINANCE DEBUG BTCUSDT-1m-2025-05-03.csv] Detected MICROSECONDS. Dividing by 1,000,000.\n",
      "2025-05-22 17:15:37,891 - INFO - feature_engineering_per_minute.load_binance_day_data:42 - [LOAD_BINANCE DEBUG BTCUSDT-1m-2025-05-04.csv] Detected MICROSECONDS. Dividing by 1,000,000.\n",
      "2025-05-22 17:15:38,514 - INFO - feature_engineering_per_minute.load_binance_day_data:42 - [LOAD_BINANCE DEBUG BTCUSDT-1m-2025-05-05.csv] Detected MICROSECONDS. Dividing by 1,000,000.\n",
      "2025-05-22 17:15:39,177 - INFO - feature_engineering_per_minute.load_binance_day_data:42 - [LOAD_BINANCE DEBUG BTCUSDT-1m-2025-05-06.csv] Detected MICROSECONDS. Dividing by 1,000,000.\n",
      "2025-05-22 17:15:39,808 - INFO - feature_engineering_per_minute.load_binance_day_data:42 - [LOAD_BINANCE DEBUG BTCUSDT-1m-2025-05-07.csv] Detected MICROSECONDS. Dividing by 1,000,000.\n",
      "2025-05-22 17:15:40,431 - INFO - feature_engineering_per_minute.load_binance_day_data:42 - [LOAD_BINANCE DEBUG BTCUSDT-1m-2025-05-08.csv] Detected MICROSECONDS. Dividing by 1,000,000.\n",
      "2025-05-22 17:17:57,871 - INFO - feature_engineering_per_minute.load_binance_day_data:42 - [LOAD_BINANCE DEBUG BTCUSDT-1m-2025-04-25.csv] Detected MICROSECONDS. Dividing by 1,000,000.\n",
      "2025-05-22 17:17:57,977 - INFO - feature_engineering_per_minute.load_binance_day_data:42 - [LOAD_BINANCE DEBUG BTCUSDT-1m-2025-04-26.csv] Detected MICROSECONDS. Dividing by 1,000,000.\n",
      "2025-05-22 17:17:58,619 - INFO - feature_engineering_per_minute.load_binance_day_data:42 - [LOAD_BINANCE DEBUG BTCUSDT-1m-2025-04-27.csv] Detected MICROSECONDS. Dividing by 1,000,000.\n",
      "2025-05-22 17:17:59,248 - INFO - feature_engineering_per_minute.load_binance_day_data:42 - [LOAD_BINANCE DEBUG BTCUSDT-1m-2025-04-28.csv] Detected MICROSECONDS. Dividing by 1,000,000.\n",
      "2025-05-22 17:17:59,879 - INFO - feature_engineering_per_minute.load_binance_day_data:42 - [LOAD_BINANCE DEBUG BTCUSDT-1m-2025-04-29.csv] Detected MICROSECONDS. Dividing by 1,000,000.\n",
      "2025-05-22 17:18:00,560 - INFO - feature_engineering_per_minute.load_binance_day_data:42 - [LOAD_BINANCE DEBUG BTCUSDT-1m-2025-04-30.csv] Detected MICROSECONDS. Dividing by 1,000,000.\n",
      "2025-05-22 17:18:01,188 - INFO - feature_engineering_per_minute.load_binance_day_data:42 - [LOAD_BINANCE DEBUG BTCUSDT-1m-2025-05-01.csv] Detected MICROSECONDS. Dividing by 1,000,000.\n",
      "2025-05-22 17:20:15,654 - INFO - feature_engineering_per_minute.load_binance_day_data:42 - [LOAD_BINANCE DEBUG BTCUSDT-1m-2025-04-18.csv] Detected MICROSECONDS. Dividing by 1,000,000.\n",
      "2025-05-22 17:20:15,760 - INFO - feature_engineering_per_minute.load_binance_day_data:42 - [LOAD_BINANCE DEBUG BTCUSDT-1m-2025-04-19.csv] Detected MICROSECONDS. Dividing by 1,000,000.\n",
      "2025-05-22 17:20:16,389 - INFO - feature_engineering_per_minute.load_binance_day_data:42 - [LOAD_BINANCE DEBUG BTCUSDT-1m-2025-04-20.csv] Detected MICROSECONDS. Dividing by 1,000,000.\n",
      "2025-05-22 17:20:17,008 - INFO - feature_engineering_per_minute.load_binance_day_data:42 - [LOAD_BINANCE DEBUG BTCUSDT-1m-2025-04-21.csv] Detected MICROSECONDS. Dividing by 1,000,000.\n",
      "2025-05-22 17:20:17,638 - INFO - feature_engineering_per_minute.load_binance_day_data:42 - [LOAD_BINANCE DEBUG BTCUSDT-1m-2025-04-22.csv] Detected MICROSECONDS. Dividing by 1,000,000.\n",
      "2025-05-22 17:20:18,261 - INFO - feature_engineering_per_minute.load_binance_day_data:42 - [LOAD_BINANCE DEBUG BTCUSDT-1m-2025-04-23.csv] Detected MICROSECONDS. Dividing by 1,000,000.\n",
      "2025-05-22 17:20:18,887 - INFO - feature_engineering_per_minute.load_binance_day_data:42 - [LOAD_BINANCE DEBUG BTCUSDT-1m-2025-04-24.csv] Detected MICROSECONDS. Dividing by 1,000,000.\n",
      "2025-05-22 17:22:19,606 - INFO - feature_engineering_per_minute.load_binance_day_data:42 - [LOAD_BINANCE DEBUG BTCUSDT-1m-2025-04-11.csv] Detected MICROSECONDS. Dividing by 1,000,000.\n",
      "2025-05-22 17:22:19,712 - INFO - feature_engineering_per_minute.load_binance_day_data:42 - [LOAD_BINANCE DEBUG BTCUSDT-1m-2025-04-12.csv] Detected MICROSECONDS. Dividing by 1,000,000.\n",
      "2025-05-22 17:22:20,356 - INFO - feature_engineering_per_minute.load_binance_day_data:42 - [LOAD_BINANCE DEBUG BTCUSDT-1m-2025-04-13.csv] Detected MICROSECONDS. Dividing by 1,000,000.\n",
      "2025-05-22 17:22:20,978 - INFO - feature_engineering_per_minute.load_binance_day_data:42 - [LOAD_BINANCE DEBUG BTCUSDT-1m-2025-04-14.csv] Detected MICROSECONDS. Dividing by 1,000,000.\n",
      "2025-05-22 17:22:21,609 - INFO - feature_engineering_per_minute.load_binance_day_data:42 - [LOAD_BINANCE DEBUG BTCUSDT-1m-2025-04-15.csv] Detected MICROSECONDS. Dividing by 1,000,000.\n",
      "2025-05-22 17:22:22,240 - INFO - feature_engineering_per_minute.load_binance_day_data:42 - [LOAD_BINANCE DEBUG BTCUSDT-1m-2025-04-16.csv] Detected MICROSECONDS. Dividing by 1,000,000.\n",
      "2025-05-22 17:22:22,867 - INFO - feature_engineering_per_minute.load_binance_day_data:42 - [LOAD_BINANCE DEBUG BTCUSDT-1m-2025-04-17.csv] Detected MICROSECONDS. Dividing by 1,000,000.\n",
      "2025-05-22 17:23:47,855 - INFO - feature_engineering_per_minute.<module>:167 - Successfully engineered features for 1286808 (market, decision_minute) points.\n",
      "2025-05-22 17:23:47,856 - INFO - feature_engineering_per_minute.<module>:170 - Cell 4: Per-Minute Feature engineering loop complete.\n"
     ]
    }
   ],
   "source": [
    "# Cell 4: Per-Minute Feature Engineering Loop (REFINED BTC STATS)\n",
    "\n",
    "all_decision_point_features_list = []\n",
    "\n",
    "if 'ntm_outcomes_df' not in locals() or ntm_outcomes_df.empty:\n",
    "    logger.warning(\"Skipping per-minute feature engineering: NTM outcomes manifest is empty.\")\n",
    "else:\n",
    "    logger.info(f\"Starting PER-MINUTE feature engineering for {len(ntm_outcomes_df)} NTM markets...\")\n",
    "    \n",
    "    clear_all_caches() \n",
    "\n",
    "    for index, ntm_market_row in tqdm(ntm_outcomes_df.iterrows(), total=ntm_outcomes_df.shape[0], desc=\"Processing NTM Markets\"):\n",
    "        market_ticker = ntm_market_row['market_ticker']\n",
    "        kalshi_strike_price = ntm_market_row['kalshi_strike_price']\n",
    "        resolution_time_ts = int(ntm_market_row['resolution_time_ts'])\n",
    "        market_open_ts = int(ntm_market_row['market_open_ts'])\n",
    "        target_outcome = ntm_market_row['target']\n",
    "\n",
    "        # Debug control for the outer loop (per NTM market)\n",
    "        is_market_being_debugged = (DEBUG_FIRST_N_ORIG_MARKETS > 0 and \n",
    "                                    debug_orig_market_count < DEBUG_FIRST_N_ORIG_MARKETS)\n",
    "        if is_market_being_debugged:\n",
    "            logger.info(f\"--- Debugging Market #{debug_orig_market_count}: {market_ticker} ---\")\n",
    "            \n",
    "        kalshi_market_df = load_kalshi_market_data(market_ticker)\n",
    "\n",
    "        first_possible_decision_ts = market_open_ts + 60 \n",
    "        last_possible_decision_ts = resolution_time_ts - (MIN_MINUTES_BEFORE_RESOLUTION_FOR_DECISION * 60)\n",
    "\n",
    "        if first_possible_decision_ts > last_possible_decision_ts:\n",
    "            if is_market_being_debugged: debug_orig_market_count += 1 # Count it as debugged even if skipped\n",
    "            continue\n",
    "        \n",
    "        decision_point_counter_for_this_market = 0 # For debugging first N decision points\n",
    "\n",
    "        for decision_minute_ts in range(first_possible_decision_ts, last_possible_decision_ts + 1, 60):\n",
    "            # Debug control for inner loop (per decision point of a debugged market)\n",
    "            should_log_this_decision_point = (is_market_being_debugged and \n",
    "                                              decision_point_counter_for_this_market < DEBUG_FIRST_N_DECISION_POINTS_PER_MARKET)\n",
    "\n",
    "            features = {'market_ticker': market_ticker, 'decision_timestamp_s': decision_minute_ts,\n",
    "                        'resolution_time_ts': resolution_time_ts, 'strike_price': kalshi_strike_price,\n",
    "                        'target': target_outcome,\n",
    "                        'time_to_resolution_minutes': round((resolution_time_ts - decision_minute_ts) / 60.0, 2)}\n",
    "\n",
    "            current_btc_kline = get_btc_kline_at_or_before_ts(decision_minute_ts, \n",
    "                                                              current_market_ticker_for_debug=market_ticker if is_market_being_debugged else None,\n",
    "                                                              decision_point_count_for_debug=decision_point_counter_for_this_market if is_market_being_debugged else -1)\n",
    "            \n",
    "            if current_btc_kline is not None and pd.notna(current_btc_kline['close']):\n",
    "                features['current_btc_price'] = float(current_btc_kline['close'])\n",
    "                features['current_dist_strike_abs'] = features['current_btc_price'] - kalshi_strike_price\n",
    "                features['current_dist_strike_pct'] = (features['current_dist_strike_abs'] / kalshi_strike_price) if kalshi_strike_price != 0 else np.nan\n",
    "                \n",
    "                # --- REFINED: Build BTC Price History for Lags/Rolling ---\n",
    "                # Determine the earliest timestamp needed for any stat based on current_btc_kline.name\n",
    "                max_lookback_seconds = (max(LAG_WINDOWS_MINUTES + ROLLING_WINDOWS_MINUTES) + 5) * 60 # Add buffer\n",
    "                history_needed_start_ts = current_btc_kline.name - max_lookback_seconds\n",
    "\n",
    "                # Efficiently gather historical klines up to current_btc_kline.name\n",
    "                # This part requires a helper or careful iteration if crossing many day boundaries.\n",
    "                # For simplicity, let's assume a helper function `get_btc_history_series` could do this.\n",
    "                # For now, we will adapt the previous multi-day loading logic.\n",
    "                \n",
    "                btc_price_series_for_stats = pd.Series(dtype=float)\n",
    "                relevant_day_dfs_data = []\n",
    "\n",
    "                # Iterate backwards from current_btc_kline's day until history_needed_start_ts is covered\n",
    "                # or we run out of data. Start with current kline's day.\n",
    "                current_eval_day_ts = current_btc_kline.name\n",
    "                num_days_to_check = (current_btc_kline.name - history_needed_start_ts) // (24*60*60) + 2 # Estimate days needed\n",
    "\n",
    "                for i in range(num_days_to_check):\n",
    "                    day_str_to_load = (dt.datetime.fromtimestamp(current_eval_day_ts, tz=timezone.utc) - timedelta(days=i)).strftime(\"%Y-%m-%d\")\n",
    "                    daily_df = load_binance_day_data(day_str_to_load)\n",
    "                    if daily_df is not None and not daily_df.empty:\n",
    "                        # Slice relevant part of this day's data\n",
    "                        day_slice = daily_df.loc[\n",
    "                            (daily_df.index >= history_needed_start_ts) & # Data must be after needed start\n",
    "                            (daily_df.index <= current_btc_kline.name)   # And not after current kline\n",
    "                        ]['close']\n",
    "                        if not day_slice.empty:\n",
    "                            relevant_day_dfs_data.append(day_slice)\n",
    "                        # If the earliest data loaded already covers history_needed_start_ts, we can stop for this day's df\n",
    "                        if daily_df.index.min() <= history_needed_start_ts:\n",
    "                            break \n",
    "                    elif i == 0 and daily_df is None : # Current day data missing, something is wrong\n",
    "                        if should_log_this_decision_point: logger.warning(f\"  [DEBUG] Current day Binance data missing for {day_str_to_load}\")\n",
    "                        break # Can't get current price or history\n",
    "                \n",
    "                if relevant_day_dfs_data:\n",
    "                    btc_price_series_for_stats = pd.concat(relevant_day_dfs_data)\n",
    "                    if not btc_price_series_for_stats.empty:\n",
    "                        btc_price_series_for_stats = btc_price_series_for_stats[\n",
    "                            ~btc_price_series_for_stats.index.duplicated(keep='last')\n",
    "                        ].sort_index()\n",
    "                \n",
    "                if should_log_this_decision_point and (DEBUG_FIRST_N_ORIG_MARKETS > 0):\n",
    "                    logger.info(f\"  [DEBUG] BTC History for {market_ticker} @ decision {decision_minute_ts} (kline_ts {current_btc_kline.name}):\")\n",
    "                    logger.info(f\"  [DEBUG]   Needed from: {dt.datetime.fromtimestamp(history_needed_start_ts, tz=timezone.utc).isoformat()}\")\n",
    "                    logger.info(f\"  [DEBUG]   Series len: {len(btc_price_series_for_stats)}, min_ts: {dt.datetime.fromtimestamp(btc_price_series_for_stats.index.min(), tz=timezone.utc).isoformat() if not btc_price_series_for_stats.empty else 'N/A'}, max_ts: {dt.datetime.fromtimestamp(btc_price_series_for_stats.index.max(), tz=timezone.utc).isoformat() if not btc_price_series_for_stats.empty else 'N/A'}\")\n",
    "\n",
    "                if not btc_price_series_for_stats.empty:\n",
    "                    # Convert index to DatetimeIndex for asof\n",
    "                    temp_series_for_asof = pd.Series(btc_price_series_for_stats.values, \n",
    "                                                     index=pd.to_datetime(btc_price_series_for_stats.index, unit='s', utc=True))\n",
    "\n",
    "                    for lag in LAG_WINDOWS_MINUTES:\n",
    "                        # target_lag_ts is the exact point in the past we're looking for data at/before\n",
    "                        target_lag_ts = current_btc_kline.name - (lag * 60)\n",
    "                        past_price = temp_series_for_asof.asof(pd.Timestamp(target_lag_ts, unit='s', tz='utc'))\n",
    "                        \n",
    "                        if pd.notna(past_price) and pd.notna(features.get('current_btc_price')):\n",
    "                            features[f'btc_price_change_pct_{lag}m'] = (features['current_btc_price'] - past_price) / past_price if past_price != 0 else np.nan\n",
    "                        else:\n",
    "                            features[f'btc_price_change_pct_{lag}m'] = np.nan\n",
    "                        if should_log_this_decision_point and (DEBUG_FIRST_N_ORIG_MARKETS > 0): logger.info(f\"  [DEBUG]   Lag {lag}m: target_ts={dt.datetime.fromtimestamp(target_lag_ts, tz=timezone.utc).isoformat()}, past_price={past_price}, calc_pct={features[f'btc_price_change_pct_{lag}m']}\")\n",
    "                    \n",
    "                    # Rolling window calculations using the same series, index already DatetimeIndex\n",
    "                    for window in ROLLING_WINDOWS_MINUTES:\n",
    "                        # We need 'window' number of 1-minute klines.\n",
    "                        # The series `temp_series_for_asof` contains history up to `current_btc_kline.name`.\n",
    "                        # We want the rolling std of the last `window` points of this series.\n",
    "                        if len(temp_series_for_asof) >= window:\n",
    "                            # .std() will be calculated on the values of the last 'window' elements.\n",
    "                            std_val = temp_series_for_asof.iloc[-window:].std() \n",
    "                        elif len(temp_series_for_asof) >= 2: # Fallback: std of available points if fewer than window but at least 2\n",
    "                            std_val = temp_series_for_asof.std()\n",
    "                        else: # Not enough data for any std calculation\n",
    "                            std_val = np.nan\n",
    "                        features[f'btc_volatility_{window}m'] = std_val # Already NaN if std_val is NaN\n",
    "                        if should_log_this_decision_point and (DEBUG_FIRST_N_ORIG_MARKETS > 0): logger.info(f\"  [DEBUG]   Roll {window}m: std_val={std_val}, assigned_feature={features[f'btc_volatility_{window}m']}\")\n",
    "                else: \n",
    "                    if should_log_this_decision_point and (DEBUG_FIRST_N_ORIG_MARKETS > 0): logger.info(f\"  [DEBUG]   BTC price series FOR STATS was EMPTY for decision_ts {decision_minute_ts}.\")\n",
    "                    for lag in LAG_WINDOWS_MINUTES: features[f'btc_price_change_pct_{lag}m'] = np.nan\n",
    "                    for window in ROLLING_WINDOWS_MINUTES: features[f'btc_volatility_{window}m'] = np.nan\n",
    "            else: # current_btc_kline is None\n",
    "                features.update({f:np.nan for f in ['current_btc_price','current_dist_strike_abs','current_dist_strike_pct']})\n",
    "                for lag in LAG_WINDOWS_MINUTES: features[f'btc_price_change_pct_{lag}m'] = np.nan\n",
    "                for window in ROLLING_WINDOWS_MINUTES: features[f'btc_volatility_{window}m'] = np.nan\n",
    "\n",
    "            # --- Kalshi Market Features ---\n",
    "            # (This part remains the same as your previous version)\n",
    "            if kalshi_market_df is not None:\n",
    "                current_kalshi_candle = get_kalshi_candle_at_or_before_ts(kalshi_market_df, decision_minute_ts)\n",
    "                if current_kalshi_candle is not None:\n",
    "                    features['current_kalshi_yes_bid'] = current_kalshi_candle.get('yes_bid_close_cents', np.nan)\n",
    "                    features['current_kalshi_yes_ask'] = current_kalshi_candle.get('yes_ask_close_cents', np.nan)\n",
    "                    features['current_kalshi_volume'] = current_kalshi_candle.get('volume', np.nan)\n",
    "                    features['current_kalshi_oi'] = current_kalshi_candle.get('open_interest', np.nan)\n",
    "                    if pd.notna(features['current_kalshi_yes_bid']) and pd.notna(features['current_kalshi_yes_ask']):\n",
    "                        features['current_kalshi_mid_price']=(features['current_kalshi_yes_bid']+features['current_kalshi_yes_ask'])/2.0\n",
    "                        features['current_kalshi_spread_abs']=features['current_kalshi_yes_ask']-features['current_kalshi_yes_bid']\n",
    "                        features['current_kalshi_spread_pct']=(features['current_kalshi_spread_abs']/features['current_kalshi_mid_price']) if features['current_kalshi_mid_price']!=0 else np.nan\n",
    "                    else: features.update({f:np.nan for f in ['current_kalshi_mid_price','current_kalshi_spread_abs','current_kalshi_spread_pct']})\n",
    "                else: features.update({f:np.nan for f in ['current_kalshi_yes_bid','current_kalshi_yes_ask','current_kalshi_mid_price','current_kalshi_spread_abs','current_kalshi_spread_pct','current_kalshi_volume','current_kalshi_oi']})\n",
    "            else: features.update({f:np.nan for f in ['current_kalshi_yes_bid','current_kalshi_yes_ask','current_kalshi_mid_price','current_kalshi_spread_abs','current_kalshi_spread_pct','current_kalshi_volume','current_kalshi_oi']})\n",
    "            \n",
    "            all_decision_point_features_list.append(features)\n",
    "            if is_market_being_debugged: decision_point_counter_for_this_market +=1\n",
    "        \n",
    "        if is_market_being_debugged: \n",
    "            debug_orig_market_count += 1 # Increment after all decision points for this market\n",
    "\n",
    "    if all_decision_point_features_list:\n",
    "        output_features_df = pd.DataFrame(all_decision_point_features_list)\n",
    "        logger.info(f\"Successfully engineered features for {len(output_features_df)} (market, decision_minute) points.\")\n",
    "    else:\n",
    "        output_features_df = pd.DataFrame(); logger.warning(\"No (market, decision_minute) features generated.\")\n",
    "logger.info(\"Cell 4: Per-Minute Feature engineering loop complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-22 17:24:00,373 - INFO - feature_engineering_per_minute.<module>:9 - Successfully saved per-minute decision features for 1286808 points to: /Users/omarabul-hassan/Desktop/projects/kalshi/notebooks/features/kalshi_per_minute_decision_features_20250522_172347.csv\n",
      "2025-05-22 17:24:00,373 - INFO - feature_engineering_per_minute.<module>:14 - Cell 5: Feature saving process complete.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features saved to: /Users/omarabul-hassan/Desktop/projects/kalshi/notebooks/features/kalshi_per_minute_decision_features_20250522_172347.csv\n"
     ]
    }
   ],
   "source": [
    "# Cell 5: Save Features\n",
    "\n",
    "if 'output_features_df' in locals() and not output_features_df.empty:\n",
    "    timestamp_str = dt.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    features_filename = f\"kalshi_per_minute_decision_features_{timestamp_str}.csv\" \n",
    "    features_filepath = FEATURES_OUTPUT_DIR / features_filename\n",
    "    try:\n",
    "        output_features_df.to_csv(features_filepath, index=False)\n",
    "        logger.info(f\"Successfully saved per-minute decision features for {len(output_features_df)} points to: {features_filepath}\")\n",
    "        print(f\"Features saved to: {features_filepath}\")\n",
    "    except Exception as e: logger.error(f\"Error saving features: {e}\", exc_info=True)\n",
    "elif 'output_features_df' in locals() and output_features_df.empty: logger.warning(\"output_features_df empty. Nothing to save.\")\n",
    "else: logger.warning(\"output_features_df not defined. Nothing to save.\")\n",
    "logger.info(\"Cell 5: Feature saving process complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-22 17:24:00,385 - INFO - feature_engineering_per_minute.<module>:11 - Inspecting features from: /Users/omarabul-hassan/Desktop/projects/kalshi/notebooks/features/kalshi_per_minute_decision_features_20250522_172347.csv\n",
      "2025-05-22 17:24:00,404 - INFO - feature_engineering_per_minute.<module>:13 - Shape of loaded sample: (10000, 25)\n",
      "2025-05-22 17:24:00,404 - INFO - feature_engineering_per_minute.<module>:13 - \n",
      "First 5 rows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>market_ticker</th>\n",
       "      <th>decision_timestamp_s</th>\n",
       "      <th>resolution_time_ts</th>\n",
       "      <th>strike_price</th>\n",
       "      <th>target</th>\n",
       "      <th>time_to_resolution_minutes</th>\n",
       "      <th>current_btc_price</th>\n",
       "      <th>current_dist_strike_abs</th>\n",
       "      <th>current_dist_strike_pct</th>\n",
       "      <th>btc_price_change_pct_1m</th>\n",
       "      <th>...</th>\n",
       "      <th>btc_volatility_5m</th>\n",
       "      <th>btc_volatility_15m</th>\n",
       "      <th>btc_volatility_30m</th>\n",
       "      <th>current_kalshi_yes_bid</th>\n",
       "      <th>current_kalshi_yes_ask</th>\n",
       "      <th>current_kalshi_volume</th>\n",
       "      <th>current_kalshi_oi</th>\n",
       "      <th>current_kalshi_mid_price</th>\n",
       "      <th>current_kalshi_spread_abs</th>\n",
       "      <th>current_kalshi_spread_pct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KXBTCD-25MAY1522-T106249.99</td>\n",
       "      <td>1747357260</td>\n",
       "      <td>1747360800</td>\n",
       "      <td>106249.99</td>\n",
       "      <td>0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>103785.66</td>\n",
       "      <td>-2464.33</td>\n",
       "      <td>-0.023194</td>\n",
       "      <td>0.000738</td>\n",
       "      <td>...</td>\n",
       "      <td>30.572030</td>\n",
       "      <td>79.377628</td>\n",
       "      <td>113.561892</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.3</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KXBTCD-25MAY1522-T106249.99</td>\n",
       "      <td>1747357320</td>\n",
       "      <td>1747360800</td>\n",
       "      <td>106249.99</td>\n",
       "      <td>0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>103691.25</td>\n",
       "      <td>-2558.74</td>\n",
       "      <td>-0.024082</td>\n",
       "      <td>-0.000910</td>\n",
       "      <td>...</td>\n",
       "      <td>38.773055</td>\n",
       "      <td>69.408713</td>\n",
       "      <td>115.612955</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.3</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KXBTCD-25MAY1522-T106249.99</td>\n",
       "      <td>1747357380</td>\n",
       "      <td>1747360800</td>\n",
       "      <td>106249.99</td>\n",
       "      <td>0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>103629.36</td>\n",
       "      <td>-2620.63</td>\n",
       "      <td>-0.024665</td>\n",
       "      <td>-0.000597</td>\n",
       "      <td>...</td>\n",
       "      <td>62.051566</td>\n",
       "      <td>55.815136</td>\n",
       "      <td>121.618868</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.3</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>KXBTCD-25MAY1522-T106249.99</td>\n",
       "      <td>1747357440</td>\n",
       "      <td>1747360800</td>\n",
       "      <td>106249.99</td>\n",
       "      <td>0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>103619.99</td>\n",
       "      <td>-2630.00</td>\n",
       "      <td>-0.024753</td>\n",
       "      <td>-0.000090</td>\n",
       "      <td>...</td>\n",
       "      <td>67.180637</td>\n",
       "      <td>55.082336</td>\n",
       "      <td>126.305198</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.3</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>KXBTCD-25MAY1522-T106249.99</td>\n",
       "      <td>1747357500</td>\n",
       "      <td>1747360800</td>\n",
       "      <td>106249.99</td>\n",
       "      <td>0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>103622.60</td>\n",
       "      <td>-2627.39</td>\n",
       "      <td>-0.024728</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>...</td>\n",
       "      <td>71.112425</td>\n",
       "      <td>52.244428</td>\n",
       "      <td>126.704856</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.3</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 market_ticker  decision_timestamp_s  resolution_time_ts  \\\n",
       "0  KXBTCD-25MAY1522-T106249.99            1747357260          1747360800   \n",
       "1  KXBTCD-25MAY1522-T106249.99            1747357320          1747360800   \n",
       "2  KXBTCD-25MAY1522-T106249.99            1747357380          1747360800   \n",
       "3  KXBTCD-25MAY1522-T106249.99            1747357440          1747360800   \n",
       "4  KXBTCD-25MAY1522-T106249.99            1747357500          1747360800   \n",
       "\n",
       "   strike_price  target  time_to_resolution_minutes  current_btc_price  \\\n",
       "0     106249.99       0                        59.0          103785.66   \n",
       "1     106249.99       0                        58.0          103691.25   \n",
       "2     106249.99       0                        57.0          103629.36   \n",
       "3     106249.99       0                        56.0          103619.99   \n",
       "4     106249.99       0                        55.0          103622.60   \n",
       "\n",
       "   current_dist_strike_abs  current_dist_strike_pct  btc_price_change_pct_1m  \\\n",
       "0                 -2464.33                -0.023194                 0.000738   \n",
       "1                 -2558.74                -0.024082                -0.000910   \n",
       "2                 -2620.63                -0.024665                -0.000597   \n",
       "3                 -2630.00                -0.024753                -0.000090   \n",
       "4                 -2627.39                -0.024728                 0.000025   \n",
       "\n",
       "   ...  btc_volatility_5m  btc_volatility_15m  btc_volatility_30m  \\\n",
       "0  ...          30.572030           79.377628          113.561892   \n",
       "1  ...          38.773055           69.408713          115.612955   \n",
       "2  ...          62.051566           55.815136          121.618868   \n",
       "3  ...          67.180637           55.082336          126.305198   \n",
       "4  ...          71.112425           52.244428          126.704856   \n",
       "\n",
       "   current_kalshi_yes_bid  current_kalshi_yes_ask  current_kalshi_volume  \\\n",
       "0                     0.0                     0.3                    0.0   \n",
       "1                     0.0                     0.3                    0.0   \n",
       "2                     0.0                     0.3                    0.0   \n",
       "3                     0.0                     0.3                    0.0   \n",
       "4                     0.0                     0.3                    0.0   \n",
       "\n",
       "   current_kalshi_oi  current_kalshi_mid_price  current_kalshi_spread_abs  \\\n",
       "0                0.0                      0.15                        0.3   \n",
       "1                0.0                      0.15                        0.3   \n",
       "2                0.0                      0.15                        0.3   \n",
       "3                0.0                      0.15                        0.3   \n",
       "4                0.0                      0.15                        0.3   \n",
       "\n",
       "   current_kalshi_spread_pct  \n",
       "0                        2.0  \n",
       "1                        2.0  \n",
       "2                        2.0  \n",
       "3                        2.0  \n",
       "4                        2.0  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-22 17:24:00,410 - INFO - feature_engineering_per_minute.<module>:14 - \n",
      "Basic Info:\n",
      "2025-05-22 17:24:00,413 - INFO - feature_engineering_per_minute.<module>:15 - \n",
      "NaN Percentage per column (for the loaded sample):\n",
      "2025-05-22 17:24:00,414 - INFO - feature_engineering_per_minute.<module>:20 - \n",
      "Value counts for 'time_to_resolution_minutes' (sample):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 25 columns):\n",
      " #   Column                      Non-Null Count  Dtype  \n",
      "---  ------                      --------------  -----  \n",
      " 0   market_ticker               10000 non-null  object \n",
      " 1   decision_timestamp_s        10000 non-null  int64  \n",
      " 2   resolution_time_ts          10000 non-null  int64  \n",
      " 3   strike_price                10000 non-null  float64\n",
      " 4   target                      10000 non-null  int64  \n",
      " 5   time_to_resolution_minutes  10000 non-null  float64\n",
      " 6   current_btc_price           10000 non-null  float64\n",
      " 7   current_dist_strike_abs     10000 non-null  float64\n",
      " 8   current_dist_strike_pct     10000 non-null  float64\n",
      " 9   btc_price_change_pct_1m     10000 non-null  float64\n",
      " 10  btc_price_change_pct_3m     10000 non-null  float64\n",
      " 11  btc_price_change_pct_5m     10000 non-null  float64\n",
      " 12  btc_price_change_pct_10m    10000 non-null  float64\n",
      " 13  btc_price_change_pct_15m    10000 non-null  float64\n",
      " 14  btc_price_change_pct_30m    10000 non-null  float64\n",
      " 15  btc_volatility_5m           10000 non-null  float64\n",
      " 16  btc_volatility_15m          10000 non-null  float64\n",
      " 17  btc_volatility_30m          10000 non-null  float64\n",
      " 18  current_kalshi_yes_bid      9274 non-null   float64\n",
      " 19  current_kalshi_yes_ask      9274 non-null   float64\n",
      " 20  current_kalshi_volume       9274 non-null   float64\n",
      " 21  current_kalshi_oi           9274 non-null   float64\n",
      " 22  current_kalshi_mid_price    9274 non-null   float64\n",
      " 23  current_kalshi_spread_abs   9274 non-null   float64\n",
      " 24  current_kalshi_spread_pct   9274 non-null   float64\n",
      "dtypes: float64(21), int64(3), object(1)\n",
      "memory usage: 1.9+ MB\n",
      "current_kalshi_yes_bid       7.26\n",
      "current_kalshi_yes_ask       7.26\n",
      "current_kalshi_volume        7.26\n",
      "current_kalshi_oi            7.26\n",
      "current_kalshi_mid_price     7.26\n",
      "current_kalshi_spread_abs    7.26\n",
      "current_kalshi_spread_pct    7.26\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "time_to_resolution_minutes\n",
       "1.0     107\n",
       "2.0     107\n",
       "3.0     107\n",
       "4.0     107\n",
       "5.0     107\n",
       "6.0     107\n",
       "7.0     107\n",
       "8.0     107\n",
       "9.0     107\n",
       "10.0    107\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "time_to_resolution_minutes\n",
       "1490.0    3\n",
       "1491.0    3\n",
       "1492.0    3\n",
       "1493.0    3\n",
       "1494.0    3\n",
       "1495.0    3\n",
       "1496.0    3\n",
       "1497.0    3\n",
       "1498.0    3\n",
       "1499.0    3\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-22 17:24:00,417 - INFO - feature_engineering_per_minute.<module>:24 - \n",
      "Number of decision points per market (sample of first few markets):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "market_ticker\n",
       "KXBTCD-25MAY1517-T104999.99    1499\n",
       "KXBTCD-25MAY1517-T105499.99    1499\n",
       "KXBTCD-25MAY1517-T104499.99     807\n",
       "KXBTCD-25MAY1519-T104749.99      59\n",
       "KXBTCD-25MAY1519-T101999.99      59\n",
       "KXBTCD-25MAY1519-T102249.99      59\n",
       "KXBTCD-25MAY1519-T102499.99      59\n",
       "KXBTCD-25MAY1519-T102749.99      59\n",
       "KXBTCD-25MAY1519-T102999.99      59\n",
       "KXBTCD-25MAY1519-T103249.99      59\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-22 17:24:00,418 - INFO - feature_engineering_per_minute.<module>:27 - \n",
      "Descriptive statistics for key numeric features (sample):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>strike_price</th>\n",
       "      <th>current_btc_price</th>\n",
       "      <th>current_dist_strike_pct</th>\n",
       "      <th>time_to_resolution_minutes</th>\n",
       "      <th>current_kalshi_mid_price</th>\n",
       "      <th>current_kalshi_spread_pct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>9274.000000</td>\n",
       "      <td>9274.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>104136.315000</td>\n",
       "      <td>103329.470000</td>\n",
       "      <td>-0.007534</td>\n",
       "      <td>331.882200</td>\n",
       "      <td>0.395736</td>\n",
       "      <td>0.925448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1433.802575</td>\n",
       "      <td>585.567751</td>\n",
       "      <td>0.016429</td>\n",
       "      <td>465.516815</td>\n",
       "      <td>0.377687</td>\n",
       "      <td>0.816996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>100749.990000</td>\n",
       "      <td>101452.020000</td>\n",
       "      <td>-0.038369</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.005000</td>\n",
       "      <td>0.010050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>102999.990000</td>\n",
       "      <td>103047.620000</td>\n",
       "      <td>-0.020067</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>0.095000</td>\n",
       "      <td>0.173913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>104499.990000</td>\n",
       "      <td>103512.290000</td>\n",
       "      <td>-0.011563</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.533333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>105249.990000</td>\n",
       "      <td>103760.000000</td>\n",
       "      <td>0.005326</td>\n",
       "      <td>653.000000</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>106249.990000</td>\n",
       "      <td>104144.230000</td>\n",
       "      <td>0.031863</td>\n",
       "      <td>1499.000000</td>\n",
       "      <td>0.995000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        strike_price  current_btc_price  current_dist_strike_pct  \\\n",
       "count   10000.000000       10000.000000             10000.000000   \n",
       "mean   104136.315000      103329.470000                -0.007534   \n",
       "std      1433.802575         585.567751                 0.016429   \n",
       "min    100749.990000      101452.020000                -0.038369   \n",
       "25%    102999.990000      103047.620000                -0.020067   \n",
       "50%    104499.990000      103512.290000                -0.011563   \n",
       "75%    105249.990000      103760.000000                 0.005326   \n",
       "max    106249.990000      104144.230000                 0.031863   \n",
       "\n",
       "       time_to_resolution_minutes  current_kalshi_mid_price  \\\n",
       "count                10000.000000               9274.000000   \n",
       "mean                   331.882200                  0.395736   \n",
       "std                    465.516815                  0.377687   \n",
       "min                      1.000000                  0.005000   \n",
       "25%                     24.000000                  0.095000   \n",
       "50%                     47.000000                  0.150000   \n",
       "75%                    653.000000                  0.850000   \n",
       "max                   1499.000000                  0.995000   \n",
       "\n",
       "       current_kalshi_spread_pct  \n",
       "count                9274.000000  \n",
       "mean                    0.925448  \n",
       "std                     0.816996  \n",
       "min                     0.010050  \n",
       "25%                     0.173913  \n",
       "50%                     0.533333  \n",
       "75%                     2.000000  \n",
       "max                     2.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-22 17:24:00,425 - INFO - feature_engineering_per_minute.<module>:29 - Cell 6: Inspection complete.\n"
     ]
    }
   ],
   "source": [
    "# Cell 6: Inspect Output CSV\n",
    "\n",
    "LATEST_PER_MINUTE_FEATURES_CSV_PATH = None\n",
    "if 'features_filepath' in locals() and Path(features_filepath).exists(): \n",
    "    LATEST_PER_MINUTE_FEATURES_CSV_PATH = features_filepath\n",
    "else: \n",
    "    list_of_feature_files = sorted(glob.glob(str(FEATURES_OUTPUT_DIR / \"kalshi_per_minute_decision_features_*.csv\")), key=os.path.getctime, reverse=True)\n",
    "    if list_of_feature_files: LATEST_PER_MINUTE_FEATURES_CSV_PATH = Path(list_of_feature_files[0])\n",
    "\n",
    "if LATEST_PER_MINUTE_FEATURES_CSV_PATH and LATEST_PER_MINUTE_FEATURES_CSV_PATH.exists():\n",
    "    logger.info(f\"Inspecting features from: {LATEST_PER_MINUTE_FEATURES_CSV_PATH}\")\n",
    "    df_inspect = pd.read_csv(LATEST_PER_MINUTE_FEATURES_CSV_PATH, nrows=10000) \n",
    "    logger.info(f\"Shape of loaded sample: {df_inspect.shape}\"); logger.info(\"\\nFirst 5 rows:\"); display(df_inspect.head())\n",
    "    logger.info(\"\\nBasic Info:\"); df_inspect.info()\n",
    "    logger.info(\"\\nNaN Percentage per column (for the loaded sample):\")\n",
    "    nan_summary_inspect = ((df_inspect.isnull().sum() / len(df_inspect)) * 100)[lambda x: x > 0].sort_values(ascending=False)\n",
    "    if not nan_summary_inspect.empty: print(nan_summary_inspect.to_string())\n",
    "    else: logger.info(\"No NaNs found in the loaded sample of feature columns.\")\n",
    "    if 'time_to_resolution_minutes' in df_inspect.columns:\n",
    "        logger.info(\"\\nValue counts for 'time_to_resolution_minutes' (sample):\")\n",
    "        display(df_inspect['time_to_resolution_minutes'].value_counts().sort_index().head(10))\n",
    "        display(df_inspect['time_to_resolution_minutes'].value_counts().sort_index().tail(10))\n",
    "    if 'market_ticker' in df_inspect.columns:\n",
    "        logger.info(\"\\nNumber of decision points per market (sample of first few markets):\")\n",
    "        display(df_inspect['market_ticker'].value_counts().head(10))\n",
    "    numeric_cols_to_describe = [c for c in ['strike_price', 'current_btc_price', 'current_dist_strike_pct', 'time_to_resolution_minutes', 'current_kalshi_mid_price', 'current_kalshi_spread_pct'] if c in df_inspect.columns]\n",
    "    if numeric_cols_to_describe: logger.info(\"\\nDescriptive statistics for key numeric features (sample):\"); display(df_inspect[numeric_cols_to_describe].describe())\n",
    "else: logger.warning(\"No per-minute features CSV file found for inspection.\")\n",
    "logger.info(\"Cell 6: Inspection complete.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
