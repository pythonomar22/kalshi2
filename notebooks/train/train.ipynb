{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-20 22:47:13,375 - INFO - model_training_classifier_20250520_224713.<module>:39 - Attempting to find feature files in: /Users/omarabul-hassan/Desktop/projects/kalshi/features\n",
      "2025-05-20 22:47:13,376 - INFO - model_training_classifier_20250520_224713.<module>:47 - Primary FEATURES_DIR not found, using alternative: /Users/omarabul-hassan/Desktop/projects/kalshi/notebooks/features\n",
      "2025-05-20 22:47:13,377 - INFO - model_training_classifier_20250520_224713.<module>:57 - Using features CSV: /Users/omarabul-hassan/Desktop/projects/kalshi/notebooks/features/kalshi_btc_features_target_v1_20250520_224529.csv\n",
      "2025-05-20 22:47:13,378 - INFO - model_training_classifier_20250520_224713.<module>:68 - Trained classifier models will be saved in: /Users/omarabul-hassan/Desktop/projects/kalshi/notebooks/trained_models\n",
      "2025-05-20 22:47:15,329 - INFO - model_training_classifier_20250520_224713.<module>:77 - Successfully loaded features data from: /Users/omarabul-hassan/Desktop/projects/kalshi/notebooks/features/kalshi_btc_features_target_v1_20250520_224529.csv\n",
      "2025-05-20 22:47:15,329 - INFO - model_training_classifier_20250520_224713.<module>:78 - Shape of loaded data: (1294800, 29)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Data Head (Raw from CSV) ---\n",
      "          kalshi_market_ticker  decision_point_ts_utc  kalshi_strike_price  \\\n",
      "0  KXBTCD-25MAY1522-T106249.99             1747357200            106249.99   \n",
      "1  KXBTCD-25MAY1522-T106249.99             1747357260            106249.99   \n",
      "2  KXBTCD-25MAY1522-T106249.99             1747357320            106249.99   \n",
      "3  KXBTCD-25MAY1522-T106249.99             1747357380            106249.99   \n",
      "4  KXBTCD-25MAY1522-T106249.99             1747357440            106249.99   \n",
      "\n",
      "   btc_price_t_minus_1  btc_mom_5m  btc_mom_10m  btc_mom_15m  btc_mom_30m  \\\n",
      "0            103764.81       73.29       -69.79      -182.17        22.80   \n",
      "1            103709.10       17.67      -111.60      -246.90       -68.90   \n",
      "2            103785.66       83.21         7.89      -114.10      -109.26   \n",
      "3            103691.25      -34.40         5.91      -227.89      -285.74   \n",
      "4            103629.36     -110.19       -98.42      -303.61      -299.95   \n",
      "\n",
      "   btc_vol_15m  btc_sma_10m  ...  TARGET_btc_diff_from_strike  kalshi_yes_bid  \\\n",
      "0    95.991753   103732.700  ...                     -2011.89             NaN   \n",
      "1    86.424046   103721.540  ...                     -2011.89             NaN   \n",
      "2    79.377628   103722.329  ...                     -2011.89             0.0   \n",
      "3    69.408713   103722.920  ...                     -2011.89             0.0   \n",
      "4    55.815136   103713.078  ...                     -2011.89             0.0   \n",
      "\n",
      "   kalshi_yes_ask  kalshi_spread  kalshi_mid_price  kalshi_volume_t_minus_1  \\\n",
      "0             NaN            NaN               NaN                      NaN   \n",
      "1             NaN            NaN               NaN                      NaN   \n",
      "2            30.0           30.0              15.0                      0.0   \n",
      "3            30.0           30.0              15.0                      0.0   \n",
      "4            30.0           30.0              15.0                      0.0   \n",
      "\n",
      "   kalshi_open_interest_t_minus_1  kalshi_mid_chg_1m  kalshi_mid_chg_3m  \\\n",
      "0                             NaN                NaN                NaN   \n",
      "1                             NaN                NaN                NaN   \n",
      "2                             0.0                NaN                NaN   \n",
      "3                             0.0                0.0                NaN   \n",
      "4                             0.0                0.0                NaN   \n",
      "\n",
      "   kalshi_mid_chg_5m  \n",
      "0                NaN  \n",
      "1                NaN  \n",
      "2                NaN  \n",
      "3                NaN  \n",
      "4                NaN  \n",
      "\n",
      "[5 rows x 29 columns]\n",
      "\n",
      "--- Data Info (Raw from CSV) ---\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1294800 entries, 0 to 1294799\n",
      "Data columns (total 29 columns):\n",
      " #   Column                          Non-Null Count    Dtype  \n",
      "---  ------                          --------------    -----  \n",
      " 0   kalshi_market_ticker            1294800 non-null  object \n",
      " 1   decision_point_ts_utc           1294800 non-null  int64  \n",
      " 2   kalshi_strike_price             1294800 non-null  float64\n",
      " 3   btc_price_t_minus_1             1294800 non-null  float64\n",
      " 4   btc_mom_5m                      1289175 non-null  float64\n",
      " 5   btc_mom_10m                     1283550 non-null  float64\n",
      " 6   btc_mom_15m                     1277925 non-null  float64\n",
      " 7   btc_mom_30m                     1261050 non-null  float64\n",
      " 8   btc_vol_15m                     1293675 non-null  float64\n",
      " 9   btc_sma_10m                     1294800 non-null  float64\n",
      " 10  btc_sma_30m                     1294800 non-null  float64\n",
      " 11  btc_ema_12m                     1294800 non-null  float64\n",
      " 12  btc_ema_26m                     1294800 non-null  float64\n",
      " 13  btc_rsi                         1294800 non-null  float64\n",
      " 14  distance_to_strike              1294800 non-null  float64\n",
      " 15  time_until_market_close_min     1294800 non-null  float64\n",
      " 16  hour_of_day_utc                 1294800 non-null  int64  \n",
      " 17  day_of_week_utc                 1294800 non-null  int64  \n",
      " 18  hour_of_day_edt                 1294800 non-null  int64  \n",
      " 19  TARGET_btc_diff_from_strike     1294800 non-null  float64\n",
      " 20  kalshi_yes_bid                  836884 non-null   float64\n",
      " 21  kalshi_yes_ask                  836884 non-null   float64\n",
      " 22  kalshi_spread                   836884 non-null   float64\n",
      " 23  kalshi_mid_price                836884 non-null   float64\n",
      " 24  kalshi_volume_t_minus_1         836884 non-null   float64\n",
      " 25  kalshi_open_interest_t_minus_1  836884 non-null   float64\n",
      " 26  kalshi_mid_chg_1m               827712 non-null   float64\n",
      " 27  kalshi_mid_chg_3m               809368 non-null   float64\n",
      " 28  kalshi_mid_chg_5m               794085 non-null   float64\n",
      "dtypes: float64(24), int64(4), object(1)\n",
      "memory usage: 286.5+ MB\n",
      "\n",
      "--- Data Description (Numerical, Raw from CSV) ---\n",
      "       decision_point_ts_utc  kalshi_strike_price  btc_price_t_minus_1    btc_mom_5m   btc_mom_10m   btc_mom_15m   btc_mom_30m   btc_vol_15m   btc_sma_10m   btc_sma_30m   btc_ema_12m   btc_ema_26m       btc_rsi  distance_to_strike  time_until_market_close_min  hour_of_day_utc  day_of_week_utc  hour_of_day_edt  TARGET_btc_diff_from_strike  kalshi_yes_bid  kalshi_yes_ask  kalshi_spread  kalshi_mid_price  kalshi_volume_t_minus_1  kalshi_open_interest_t_minus_1  kalshi_mid_chg_1m  kalshi_mid_chg_3m  kalshi_mid_chg_5m\n",
      "count           1.294800e+06         1.294800e+06         1.294800e+06  1.289175e+06  1.283550e+06  1.277925e+06  1.261050e+06  1.293675e+06  1.294800e+06  1.294800e+06  1.294800e+06  1.294800e+06  1.294800e+06        1.294800e+06                 1.294800e+06     1.294800e+06     1.294800e+06     1.294800e+06                 1.294800e+06   836884.000000   836884.000000  836884.000000     836884.000000            836884.000000                   836884.000000      827712.000000      809368.000000      794085.000000\n",
      "mean            1.745949e+09         9.510212e+04         9.408098e+04  1.941602e+00  3.926268e+00  5.944350e+00  1.144532e+01  6.429325e+01  9.407924e+04  9.407541e+04  9.407885e+04  9.407621e+04  5.052580e+01       -1.021137e+03                 1.706085e+03     1.225158e+01     2.898842e+00     1.320728e+01                 5.495876e+01       40.910939       54.039580      13.128641         47.475259                23.465873                      581.263225           0.006214           0.016046           0.035981\n",
      "std             7.798241e+05         6.636818e+03         6.307015e+03  1.097993e+02  1.533758e+02  1.862648e+02  2.571959e+02  4.693030e+01  6.307088e+03  6.307507e+03  6.306918e+03  6.307023e+03  1.753297e+01        2.802957e+03                 2.691954e+03     7.286352e+00     1.994109e+00     6.388092e+00                 1.410487e+03       37.123268       36.372663      15.347168         35.939810               198.715751                     1906.726984           3.891034           5.258502           6.020547\n",
      "min             1.744402e+09         8.124999e+04         8.280487e+04 -1.188610e+03 -1.376040e+03 -1.320860e+03 -2.029050e+03  1.958686e+00  8.286691e+04  8.292615e+04  8.289461e+04  8.294807e+04  0.000000e+00       -1.251395e+04                 1.000000e+00     0.000000e+00     0.000000e+00     0.000000e+00                -3.932710e+03        0.000000        1.000000       1.000000          0.500000                 0.000000                        0.000000         -79.000000         -92.000000         -93.000000\n",
      "25%             1.745294e+09         9.199999e+04         8.827201e+04 -5.256000e+01 -7.404000e+01 -8.951000e+01 -1.190200e+02  3.539188e+01  8.825410e+04  8.822399e+04  8.824066e+04  8.822397e+04  3.797695e+01       -1.904000e+03                 3.600000e+01     5.000000e+00     1.000000e+00     9.000000e+00                -1.111930e+03        1.000000       16.000000       4.000000         11.000000                 0.000000                        0.000000           0.000000          -0.500000          -1.000000\n",
      "50%             1.745957e+09         9.549999e+04         9.455490e+04  1.060000e+00  2.190000e+00  3.430000e+00  8.210000e+00  5.223952e+01  9.455613e+04  9.456229e+04  9.455684e+04  9.456050e+04  5.041273e+01       -5.322600e+02                 3.900000e+02     1.300000e+01     3.000000e+00     1.400000e+01                 2.232000e+01       35.000000       50.000000       7.000000         41.000000                 0.000000                        0.000000           0.000000           0.000000           0.000000\n",
      "75%             1.746586e+09         1.010000e+05         9.697530e+04  5.582000e+01  8.155000e+01  9.988000e+01  1.367900e+02  7.839257e+01  9.697389e+04  9.698326e+04  9.697901e+04  9.697788e+04  6.325748e+01        8.669400e+02                 1.487000e+03     1.800000e+01     5.000000e+00     1.900000e+01                 1.215835e+03       82.000000       97.000000      16.000000         86.000000                 0.000000                      281.000000           0.000000           0.500000           1.000000\n",
      "max             1.747361e+09         1.072500e+05         1.056790e+05  1.777730e+03  2.026420e+03  2.093720e+03  1.898320e+03  7.430210e+02  1.055105e+05  1.054629e+05  1.054993e+05  1.053845e+05  1.000000e+02        5.929020e+03                 1.014000e+04     2.300000e+01     6.000000e+00     2.300000e+01                 4.250510e+03       99.000000      100.000000     100.000000         99.500000             14727.000000                   319814.000000          91.500000          93.500000          92.500000\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Imports and Load Data for Classification\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from pathlib import Path\n",
    "import datetime as dt\n",
    "from datetime import timezone, timedelta\n",
    "import logging\n",
    "import json # For saving feature_columns_list\n",
    "import joblib # For saving the model and scaler\n",
    "\n",
    "from sklearn.model_selection import train_test_split # We'll do a chronological split manually\n",
    "from sklearn.linear_model import LogisticRegression # CHANGED: For classification\n",
    "from sklearn.preprocessing import StandardScaler # For feature scaling\n",
    "# CHANGED: Classification metrics\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, log_loss, confusion_matrix \n",
    "\n",
    "# --- Logging Setup ---\n",
    "logger_name = f\"model_training_classifier_{dt.datetime.now().strftime('%Y%m%d_%H%M%S')}\" # Updated logger name\n",
    "logger = logging.getLogger(logger_name)\n",
    "if not logger.handlers: # Avoid adding handlers if re-running cell\n",
    "    logger.setLevel(logging.INFO)\n",
    "    formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(name)s.%(funcName)s:%(lineno)d - %(message)s')\n",
    "    ch = logging.StreamHandler()\n",
    "    ch.setFormatter(formatter)\n",
    "    logger.addHandler(ch)\n",
    "else:\n",
    "    logger.setLevel(logging.INFO)\n",
    "\n",
    "# --- Configuration ---\n",
    "current_notebook_dir = Path.cwd() # Assumes notebook is in notebooks/train/\n",
    "# Adjust FEATURES_DIR if your features are not in ../features relative to this notebook's parent\n",
    "# For example, if train.ipynb is in ./notebooks/train and features are in ./notebooks/features:\n",
    "FEATURES_DIR = current_notebook_dir.parent.parent / \"features\" # Assuming features are in project_root/features\n",
    "# If features are in ./notebooks/features:\n",
    "# FEATURES_DIR = current_notebook_dir.parent / \"features\" \n",
    "\n",
    "logger.info(f\"Attempting to find feature files in: {FEATURES_DIR.resolve()}\")\n",
    "\n",
    "try:\n",
    "    if not FEATURES_DIR.exists():\n",
    "        # Let's try another common location if the above doesn't exist, e.g. within notebooks/\n",
    "        alt_features_dir = current_notebook_dir.parent / \"features\"\n",
    "        if alt_features_dir.exists():\n",
    "            FEATURES_DIR = alt_features_dir\n",
    "            logger.info(f\"Primary FEATURES_DIR not found, using alternative: {FEATURES_DIR.resolve()}\")\n",
    "        else:\n",
    "            raise FileNotFoundError(f\"The directory {FEATURES_DIR.resolve()} (and {alt_features_dir.resolve()}) does not exist. Please check the path.\")\n",
    "\n",
    "    # Assuming feature files might still use the 'v1' from previous regression task,\n",
    "    # or you might have new ones. Adjust pattern if needed.\n",
    "    feature_files = sorted(FEATURES_DIR.glob(\"kalshi_btc_features_target_v1_*.csv\"), key=os.path.getctime, reverse=True)\n",
    "    if not feature_files:\n",
    "        raise FileNotFoundError(f\"No feature CSV files found in {FEATURES_DIR.resolve()} matching pattern 'kalshi_btc_features_target_v1_*.csv'\")\n",
    "    FEATURES_CSV_PATH = feature_files[0]\n",
    "    logger.info(f\"Using features CSV: {FEATURES_CSV_PATH.resolve()}\")\n",
    "except FileNotFoundError as e:\n",
    "    logger.critical(str(e))\n",
    "    FEATURES_CSV_PATH = None\n",
    "except Exception as e:\n",
    "    logger.critical(f\"Error finding features CSV: {e}\")\n",
    "    FEATURES_CSV_PATH = None\n",
    "\n",
    "# Output directory for trained classifier models\n",
    "MODEL_OUTPUT_DIR = current_notebook_dir.parent / \"trained_models\" # Keeps trained_models within notebooks/\n",
    "MODEL_OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "logger.info(f\"Trained classifier models will be saved in: {MODEL_OUTPUT_DIR.resolve()}\")\n",
    "\n",
    "\n",
    "# --- Load the Features DataFrame ---\n",
    "df_model_data = pd.DataFrame()\n",
    "\n",
    "if FEATURES_CSV_PATH and FEATURES_CSV_PATH.exists():\n",
    "    try:\n",
    "        df_model_data = pd.read_csv(FEATURES_CSV_PATH)\n",
    "        logger.info(f\"Successfully loaded features data from: {FEATURES_CSV_PATH.resolve()}\")\n",
    "        logger.info(f\"Shape of loaded data: {df_model_data.shape}\")\n",
    "        \n",
    "        print(\"--- Data Head (Raw from CSV) ---\")\n",
    "        print(df_model_data.head())\n",
    "        print(\"\\n--- Data Info (Raw from CSV) ---\")\n",
    "        df_model_data.info()\n",
    "        print(\"\\n--- Data Description (Numerical, Raw from CSV) ---\")\n",
    "        print(df_model_data.describe().to_string())\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.critical(f\"Error loading features CSV {FEATURES_CSV_PATH.resolve()}: {e}\")\n",
    "else:\n",
    "    if FEATURES_CSV_PATH:\n",
    "         logger.critical(f\"Features CSV file not found at the specified path: {FEATURES_CSV_PATH.resolve()}\")\n",
    "    else:\n",
    "         logger.critical(\"FEATURES_CSV_PATH was not set (likely due to an error finding the file). Cannot load data.\")\n",
    "\n",
    "if df_model_data.empty:\n",
    "    logger.warning(\"DataFrame df_model_data is empty. Subsequent cells might fail.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-20 22:47:26,610 - INFO - model_training_classifier_20250520_224713.<module>:6 - Starting preprocessing for df_model_data with shape: (1294800, 29)\n",
      "2025-05-20 22:47:26,698 - INFO - model_training_classifier_20250520_224713.<module>:11 - Data sorted by 'decision_point_ts_utc'.\n",
      "2025-05-20 22:47:26,701 - INFO - model_training_classifier_20250520_224713.<module>:27 - Created binary classification target 'TARGET_market_resolves_yes'.\n",
      "2025-05-20 22:47:26,706 - INFO - model_training_classifier_20250520_224713.<module>:28 - Value counts for 'TARGET_market_resolves_yes':\n",
      "TARGET_market_resolves_yes\n",
      "1    0.518072\n",
      "0    0.481928\n",
      "Name: proportion, dtype: float64\n",
      "2025-05-20 22:47:26,706 - INFO - model_training_classifier_20250520_224713.<module>:39 - Potential feature columns (25): ['btc_price_t_minus_1', 'btc_mom_5m', 'btc_mom_10m', 'btc_mom_15m', 'btc_mom_30m', 'btc_vol_15m', 'btc_sma_10m', 'btc_sma_30m', 'btc_ema_12m', 'btc_ema_26m']...\n",
      "2025-05-20 22:47:26,767 - WARNING - model_training_classifier_20250520_224713.<module>:44 - NaN values found in feature columns:\n",
      "kalshi_mid_chg_5m                 500715\n",
      "kalshi_mid_chg_3m                 485432\n",
      "kalshi_mid_chg_1m                 467088\n",
      "kalshi_yes_bid                    457916\n",
      "kalshi_yes_ask                    457916\n",
      "kalshi_spread                     457916\n",
      "kalshi_mid_price                  457916\n",
      "kalshi_volume_t_minus_1           457916\n",
      "kalshi_open_interest_t_minus_1    457916\n",
      "btc_mom_30m                        33750\n",
      "btc_mom_15m                        16875\n",
      "btc_mom_10m                        11250\n",
      "btc_mom_5m                          5625\n",
      "btc_vol_15m                         1125\n",
      "dtype: int64\n",
      "2025-05-20 22:47:26,770 - INFO - model_training_classifier_20250520_224713.<module>:59 - Filled NaNs in 'kalshi_yes_bid' with 0.\n",
      "2025-05-20 22:47:26,773 - INFO - model_training_classifier_20250520_224713.<module>:62 - Filled NaNs in 'kalshi_yes_ask' with 100.\n",
      "2025-05-20 22:47:26,775 - INFO - model_training_classifier_20250520_224713.<module>:67 - Recalculated 'kalshi_spread' after filling bid/ask.\n",
      "2025-05-20 22:47:26,777 - INFO - model_training_classifier_20250520_224713.<module>:70 - Recalculated 'kalshi_mid_price' after filling bid/ask.\n",
      "2025-05-20 22:47:26,779 - INFO - model_training_classifier_20250520_224713.<module>:75 - Filled NaNs in 'btc_mom_5m' with 0.\n",
      "2025-05-20 22:47:26,782 - INFO - model_training_classifier_20250520_224713.<module>:75 - Filled NaNs in 'btc_mom_10m' with 0.\n",
      "2025-05-20 22:47:26,784 - INFO - model_training_classifier_20250520_224713.<module>:75 - Filled NaNs in 'btc_mom_15m' with 0.\n",
      "2025-05-20 22:47:26,787 - INFO - model_training_classifier_20250520_224713.<module>:75 - Filled NaNs in 'btc_mom_30m' with 0.\n",
      "2025-05-20 22:47:26,789 - INFO - model_training_classifier_20250520_224713.<module>:75 - Filled NaNs in 'kalshi_mid_chg_1m' with 0.\n",
      "2025-05-20 22:47:26,791 - INFO - model_training_classifier_20250520_224713.<module>:75 - Filled NaNs in 'kalshi_mid_chg_3m' with 0.\n",
      "2025-05-20 22:47:26,794 - INFO - model_training_classifier_20250520_224713.<module>:75 - Filled NaNs in 'kalshi_mid_chg_5m' with 0.\n",
      "2025-05-20 22:47:26,802 - INFO - model_training_classifier_20250520_224713.<module>:81 - Filled NaNs in 'btc_vol_15m' with its median (52.2395).\n",
      "2025-05-20 22:47:26,808 - INFO - model_training_classifier_20250520_224713.<module>:81 - Filled NaNs in 'btc_sma_10m' with its median (94556.1280).\n",
      "2025-05-20 22:47:26,814 - INFO - model_training_classifier_20250520_224713.<module>:81 - Filled NaNs in 'btc_sma_30m' with its median (94562.2887).\n",
      "2025-05-20 22:47:26,820 - INFO - model_training_classifier_20250520_224713.<module>:81 - Filled NaNs in 'btc_ema_12m' with its median (94556.8417).\n",
      "2025-05-20 22:47:26,826 - INFO - model_training_classifier_20250520_224713.<module>:81 - Filled NaNs in 'btc_ema_26m' with its median (94560.5028).\n",
      "2025-05-20 22:47:26,828 - INFO - model_training_classifier_20250520_224713.<module>:86 - Filled NaNs in 'btc_rsi' with 50.\n",
      "2025-05-20 22:47:27,036 - INFO - model_training_classifier_20250520_224713.<module>:92 - Dropped 457916 rows due to remaining NaNs in features or target after imputation attempts.\n",
      "2025-05-20 22:47:27,079 - INFO - model_training_classifier_20250520_224713.<module>:99 - Successfully handled NaNs in feature columns.\n",
      "2025-05-20 22:47:27,130 - INFO - model_training_classifier_20250520_224713.<module>:107 - Defined X (features) with shape: (836884, 25)\n",
      "2025-05-20 22:47:27,130 - INFO - model_training_classifier_20250520_224713.<module>:108 - Defined y (binary target) with shape: (836884,)\n",
      "2025-05-20 22:47:27,133 - INFO - model_training_classifier_20250520_224713.<module>:109 - Target y value counts:\n",
      "TARGET_market_resolves_yes\n",
      "1    0.521441\n",
      "0    0.478559\n",
      "Name: proportion, dtype: float64\n",
      "2025-05-20 22:47:27,133 - INFO - model_training_classifier_20250520_224713.<module>:121 - Data split chronologically:\n",
      "2025-05-20 22:47:27,133 - INFO - model_training_classifier_20250520_224713.<module>:122 -   X_train shape: (669507, 25), y_train shape: (669507,)\n",
      "2025-05-20 22:47:27,133 - INFO - model_training_classifier_20250520_224713.<module>:123 -   X_test shape: (167377, 25), y_test shape: (167377,)\n",
      "2025-05-20 22:47:27,134 - INFO - model_training_classifier_20250520_224713.<module>:130 -   Training data from: 2025-04-11T20:02:00+00:00 to 2025-05-10T13:18:00+00:00\n",
      "2025-05-20 22:47:27,134 - INFO - model_training_classifier_20250520_224713.<module>:131 -   Test data from:     2025-05-10T13:18:00+00:00 to 2025-05-16T01:59:00+00:00\n",
      "2025-05-20 22:47:27,256 - INFO - model_training_classifier_20250520_224713.<module>:141 - Features scaled using StandardScaler.\n",
      "2025-05-20 22:47:27,259 - INFO - model_training_classifier_20250520_224713.<module>:148 - Scaler saved to: /Users/omarabul-hassan/Desktop/projects/kalshi/notebooks/trained_models/feature_scaler_classifier_v1.joblib\n",
      "2025-05-20 22:47:27,260 - INFO - model_training_classifier_20250520_224713.<module>:156 - List of feature columns saved to: /Users/omarabul-hassan/Desktop/projects/kalshi/notebooks/trained_models/feature_columns_classifier_v1.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample of scaled training features (X_train_scaled_df head):\n",
      "    btc_price_t_minus_1  btc_mom_5m  btc_mom_10m  btc_mom_15m  btc_mom_30m  \\\n",
      "18            -1.880955   -0.267215    -0.671256    -0.499148      0.23473   \n",
      "19            -1.880955   -0.267215    -0.671256    -0.499148      0.23473   \n",
      "20            -1.880955   -0.267215    -0.671256    -0.499148      0.23473   \n",
      "21            -1.880955   -0.267215    -0.671256    -0.499148      0.23473   \n",
      "22            -1.880955   -0.267215    -0.671256    -0.499148      0.23473   \n",
      "\n",
      "    btc_vol_15m  btc_sma_10m  btc_sma_30m  btc_ema_12m  btc_ema_26m  ...  \\\n",
      "18    -0.365124     -1.86631    -1.870939    -1.867321    -1.868163  ...   \n",
      "19    -0.365124     -1.86631    -1.870939    -1.867321    -1.868163  ...   \n",
      "20    -0.365124     -1.86631    -1.870939    -1.867321    -1.868163  ...   \n",
      "21    -0.365124     -1.86631    -1.870939    -1.867321    -1.868163  ...   \n",
      "22    -0.365124     -1.86631    -1.870939    -1.867321    -1.868163  ...   \n",
      "\n",
      "    hour_of_day_edt  kalshi_yes_bid  kalshi_yes_ask  kalshi_spread  \\\n",
      "18         0.335034        0.208052       -0.013834      -0.503196   \n",
      "19         0.335034        0.126367       -0.097936      -0.503196   \n",
      "20         0.335034        0.371422        0.182403      -0.441336   \n",
      "21         0.335034        0.262509        0.070267      -0.441336   \n",
      "22         0.335034       -0.173146       -0.378274      -0.441336   \n",
      "\n",
      "    kalshi_mid_price  kalshi_volume_t_minus_1  kalshi_open_interest_t_minus_1  \\\n",
      "18          0.101272                -0.118801                       -0.304479   \n",
      "19          0.016259                -0.118801                       -0.304479   \n",
      "20          0.285466                -0.118801                       -0.304479   \n",
      "21          0.172116                -0.118801                       -0.304479   \n",
      "22         -0.281286                -0.118801                       -0.304479   \n",
      "\n",
      "    kalshi_mid_chg_1m  kalshi_mid_chg_3m  kalshi_mid_chg_5m  \n",
      "18          -0.002132          -0.004412          -0.008278  \n",
      "19          -0.002132          -0.004412          -0.008278  \n",
      "20          -0.002132          -0.004412          -0.008278  \n",
      "21          -0.002132          -0.004412          -0.008278  \n",
      "22          -0.002132          -0.004412          -0.008278  \n",
      "\n",
      "[5 rows x 25 columns]\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Data Preprocessing, Target Transformation, Feature Selection, and Splitting\n",
    "\n",
    "if df_model_data.empty:\n",
    "    logger.error(\"df_model_data is empty. Cannot proceed with preprocessing and splitting. Please ensure Cell 1 ran correctly and loaded data.\")\n",
    "else:\n",
    "    logger.info(f\"Starting preprocessing for df_model_data with shape: {df_model_data.shape}\")\n",
    "\n",
    "    # --- 1. Ensure Chronological Order ---\n",
    "    df_model_data.sort_values(by='decision_point_ts_utc', inplace=True)\n",
    "    df_model_data.reset_index(drop=True, inplace=True)\n",
    "    logger.info(\"Data sorted by 'decision_point_ts_utc'.\")\n",
    "\n",
    "    # --- 2. Define NEW Target Variable for Classification ---\n",
    "    # Original target: 'TARGET_btc_diff_from_strike'\n",
    "    # New target: 1 if (BTC price at resolution > strike price), 0 otherwise.\n",
    "    # This means the Kalshi market for \"YES\" would win.\n",
    "    original_target_col = 'TARGET_btc_diff_from_strike'\n",
    "    classification_target_col = 'TARGET_market_resolves_yes' # New binary target\n",
    "\n",
    "    if original_target_col not in df_model_data.columns:\n",
    "        logger.critical(f\"Original target column '{original_target_col}' not found in DataFrame. Cannot create classification target.\")\n",
    "        # Stop execution or handle error appropriately\n",
    "        raise ValueError(f\"Missing required column: {original_target_col}\")\n",
    "    \n",
    "    # Create the binary target: 1 if positive difference (YES wins), 0 if non-positive (NO wins or ties)\n",
    "    df_model_data[classification_target_col] = (df_model_data[original_target_col] > 0).astype(int)\n",
    "    logger.info(f\"Created binary classification target '{classification_target_col}'.\")\n",
    "    logger.info(f\"Value counts for '{classification_target_col}':\\n{df_model_data[classification_target_col].value_counts(normalize=True)}\")\n",
    "\n",
    "\n",
    "    # --- 3. Handle Missing Values (NaNs) in Features ---\n",
    "    identifier_cols = ['kalshi_market_ticker', 'decision_point_ts_utc', 'kalshi_strike_price']\n",
    "    # Feature columns: exclude identifiers, original regression target, and new classification target\n",
    "    feature_columns = [\n",
    "        col for col in df_model_data.columns \n",
    "        if col not in identifier_cols + [original_target_col, classification_target_col]\n",
    "    ]\n",
    "    \n",
    "    logger.info(f\"Potential feature columns ({len(feature_columns)}): {feature_columns[:10]}...\") # Log first 10\n",
    "\n",
    "    nan_summary = df_model_data[feature_columns].isnull().sum()\n",
    "    nan_summary = nan_summary[nan_summary > 0].sort_values(ascending=False)\n",
    "    if not nan_summary.empty:\n",
    "        logger.warning(f\"NaN values found in feature columns:\\n{nan_summary}\")\n",
    "        \n",
    "        # --- Imputation Strategy (Same as before, review if needed for classification) ---\n",
    "        cols_to_fill_zero = [\n",
    "            col for col in feature_columns if 'kalshi_mid_chg' in col or \\\n",
    "            'btc_mom' in col \n",
    "        ]\n",
    "        cols_to_fill_median = [ \n",
    "            col for col in feature_columns if 'btc_vol' in col or \\\n",
    "            'btc_sma' in col or 'btc_ema' in col \n",
    "        ]\n",
    "        cols_to_fill_rsi_neutral = [col for col in feature_columns if 'btc_rsi' in col]\n",
    "        \n",
    "        if 'kalshi_yes_bid' in df_model_data.columns and 'kalshi_yes_bid' in feature_columns: # Check if it's a feature\n",
    "            df_model_data['kalshi_yes_bid'] = df_model_data['kalshi_yes_bid'].fillna(0)\n",
    "            logger.info(\"Filled NaNs in 'kalshi_yes_bid' with 0.\")\n",
    "        if 'kalshi_yes_ask' in df_model_data.columns and 'kalshi_yes_ask' in feature_columns:\n",
    "            df_model_data['kalshi_yes_ask'] = df_model_data['kalshi_yes_ask'].fillna(100)\n",
    "            logger.info(\"Filled NaNs in 'kalshi_yes_ask' with 100.\")\n",
    "        \n",
    "        if 'kalshi_yes_bid' in feature_columns and 'kalshi_yes_ask' in feature_columns:\n",
    "            if 'kalshi_spread' in feature_columns:\n",
    "                df_model_data['kalshi_spread'] = df_model_data['kalshi_yes_ask'] - df_model_data['kalshi_yes_bid']\n",
    "                logger.info(\"Recalculated 'kalshi_spread' after filling bid/ask.\")\n",
    "            if 'kalshi_mid_price' in feature_columns:\n",
    "                 df_model_data['kalshi_mid_price'] = (df_model_data['kalshi_yes_bid'] + df_model_data['kalshi_yes_ask']) / 2\n",
    "                 logger.info(\"Recalculated 'kalshi_mid_price' after filling bid/ask.\")\n",
    "        \n",
    "        for col in cols_to_fill_zero:\n",
    "            if col in df_model_data.columns and col in feature_columns:\n",
    "                df_model_data[col] = df_model_data[col].fillna(0)\n",
    "                logger.info(f\"Filled NaNs in '{col}' with 0.\")\n",
    "\n",
    "        for col in cols_to_fill_median:\n",
    "            if col in df_model_data.columns and col in feature_columns:\n",
    "                median_val = df_model_data[col].median()\n",
    "                df_model_data[col] = df_model_data[col].fillna(median_val)\n",
    "                logger.info(f\"Filled NaNs in '{col}' with its median ({median_val:.4f}).\")\n",
    "\n",
    "        for col in cols_to_fill_rsi_neutral:\n",
    "            if col in df_model_data.columns and col in feature_columns:\n",
    "                df_model_data[col] = df_model_data[col].fillna(50)\n",
    "                logger.info(f\"Filled NaNs in '{col}' with 50.\")\n",
    "\n",
    "        original_row_count = len(df_model_data)\n",
    "        df_model_data.dropna(subset=feature_columns, inplace=True) # Drop rows with NaNs in any *feature* column\n",
    "        # Also drop rows where the classification target might be NaN (though astype(int) should handle it from boolean)\n",
    "        df_model_data.dropna(subset=[classification_target_col], inplace=True) \n",
    "        logger.info(f\"Dropped {original_row_count - len(df_model_data)} rows due to remaining NaNs in features or target after imputation attempts.\")\n",
    "        \n",
    "        final_nan_summary = df_model_data[feature_columns].isnull().sum()\n",
    "        final_nan_summary = final_nan_summary[final_nan_summary > 0]\n",
    "        if not final_nan_summary.empty:\n",
    "            logger.error(f\"Still have NaNs after processing feature columns! Columns:\\n{final_nan_summary}\")\n",
    "        else:\n",
    "            logger.info(\"Successfully handled NaNs in feature columns.\")\n",
    "    else:\n",
    "        logger.info(\"No NaNs found in the selected feature columns.\")\n",
    "        \n",
    "    # --- 4. Define Features (X) and New Target (y) ---\n",
    "    if not df_model_data.empty:\n",
    "        X = df_model_data[feature_columns].copy()\n",
    "        y = df_model_data[classification_target_col].copy() # Use the new binary target\n",
    "        logger.info(f\"Defined X (features) with shape: {X.shape}\")\n",
    "        logger.info(f\"Defined y (binary target) with shape: {y.shape}\")\n",
    "        logger.info(f\"Target y value counts:\\n{y.value_counts(normalize=True)}\")\n",
    "\n",
    "\n",
    "        # --- 5. Split Data (Chronological) ---\n",
    "        split_ratio = 0.8\n",
    "        split_index = int(len(X) * split_ratio)\n",
    "\n",
    "        X_train = X.iloc[:split_index]\n",
    "        y_train = y.iloc[:split_index] # y_train is now binary\n",
    "        X_test = X.iloc[split_index:]\n",
    "        y_test = y.iloc[split_index:]   # y_test is now binary\n",
    "\n",
    "        logger.info(f\"Data split chronologically:\")\n",
    "        logger.info(f\"  X_train shape: {X_train.shape}, y_train shape: {y_train.shape}\")\n",
    "        logger.info(f\"  X_test shape: {X_test.shape}, y_test shape: {y_test.shape}\")\n",
    "        \n",
    "        train_start_ts = df_model_data['decision_point_ts_utc'].iloc[0]\n",
    "        train_end_ts = df_model_data['decision_point_ts_utc'].iloc[split_index - 1]\n",
    "        test_start_ts = df_model_data['decision_point_ts_utc'].iloc[split_index]\n",
    "        test_end_ts = df_model_data['decision_point_ts_utc'].iloc[-1]\n",
    "\n",
    "        logger.info(f\"  Training data from: {dt.datetime.fromtimestamp(train_start_ts, tz=timezone.utc).isoformat()} to {dt.datetime.fromtimestamp(train_end_ts, tz=timezone.utc).isoformat()}\")\n",
    "        logger.info(f\"  Test data from:     {dt.datetime.fromtimestamp(test_start_ts, tz=timezone.utc).isoformat()} to {dt.datetime.fromtimestamp(test_end_ts, tz=timezone.utc).isoformat()}\")\n",
    "        \n",
    "        # --- 6. Feature Scaling ---\n",
    "        scaler = StandardScaler()\n",
    "        X_train_scaled = scaler.fit_transform(X_train)\n",
    "        X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "        X_train_scaled_df = pd.DataFrame(X_train_scaled, columns=X_train.columns, index=X_train.index)\n",
    "        X_test_scaled_df = pd.DataFrame(X_test_scaled, columns=X_test.columns, index=X_test.index)\n",
    "\n",
    "        logger.info(\"Features scaled using StandardScaler.\")\n",
    "        print(\"\\nSample of scaled training features (X_train_scaled_df head):\")\n",
    "        print(X_train_scaled_df.head())\n",
    "        \n",
    "        # Save the scaler (filename indicates it's for classifier v1)\n",
    "        scaler_path = MODEL_OUTPUT_DIR / \"feature_scaler_classifier_v1.joblib\"\n",
    "        joblib.dump(scaler, scaler_path)\n",
    "        logger.info(f\"Scaler saved to: {scaler_path}\")\n",
    "        \n",
    "        # Save the list of feature columns (filename indicates it's for classifier v1)\n",
    "        # This list *should* be the same as for regression if using same features,\n",
    "        # but good to save it associated with this model run.\n",
    "        feature_columns_list_path = MODEL_OUTPUT_DIR / \"feature_columns_classifier_v1.json\"\n",
    "        with open(feature_columns_list_path, 'w') as f:\n",
    "            json.dump(feature_columns, f) # feature_columns is already a list here\n",
    "        logger.info(f\"List of feature columns saved to: {feature_columns_list_path}\")\n",
    "\n",
    "    else:\n",
    "        logger.error(\"df_model_data is empty after NaN handling. Cannot proceed to define X, y, or split.\")\n",
    "        X, y, X_train, y_train, X_test, y_test, X_train_scaled_df, X_test_scaled_df = [pd.DataFrame()]*8 \n",
    "        scaler = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-20 22:48:49,136 - INFO - model_training_classifier_20250520_224713.<module>:7 - --- Starting Classification Model Training (Logistic Regression) ---\n",
      "2025-05-20 22:48:49,137 - INFO - model_training_classifier_20250520_224713.<module>:21 - Training LogisticRegression model on 669507 samples...\n",
      "2025-05-20 22:48:49,584 - INFO - model_training_classifier_20250520_224713.<module>:28 - LogisticRegression model training complete.\n",
      "2025-05-20 22:48:49,584 - INFO - model_training_classifier_20250520_224713.<module>:31 - Making predictions on the test set (167377 samples)...\n",
      "2025-05-20 22:48:49,643 - INFO - model_training_classifier_20250520_224713.<module>:50 - \n",
      "--- Classification Model Evaluation Metrics (Test Set) ---\n",
      "2025-05-20 22:48:49,643 - INFO - model_training_classifier_20250520_224713.<module>:51 -   Accuracy:          0.9129\n",
      "2025-05-20 22:48:49,644 - INFO - model_training_classifier_20250520_224713.<module>:52 -   Precision:         0.8872 (Portion of predicted YES that were actually YES)\n",
      "2025-05-20 22:48:49,644 - INFO - model_training_classifier_20250520_224713.<module>:53 -   Recall (TPR):      0.9475 (Portion of actual YES that were correctly identified)\n",
      "2025-05-20 22:48:49,644 - INFO - model_training_classifier_20250520_224713.<module>:54 -   F1-Score:          0.9164\n",
      "2025-05-20 22:48:49,644 - INFO - model_training_classifier_20250520_224713.<module>:55 -   ROC AUC:           0.9761\n",
      "2025-05-20 22:48:49,644 - INFO - model_training_classifier_20250520_224713.<module>:56 -   Log Loss:          0.2246\n",
      "2025-05-20 22:48:49,645 - INFO - model_training_classifier_20250520_224713.<module>:58 - \n",
      "--- Confusion Matrix (Test Set) ---\n",
      "2025-05-20 22:48:49,648 - INFO - model_training_classifier_20250520_224713.<module>:63 - \n",
      "[[72883 10155]\n",
      " [ 4431 79908]]\n",
      "2025-05-20 22:48:49,648 - INFO - model_training_classifier_20250520_224713.<module>:66 -   True Negatives (TN) - Actual NO, Predicted NO:  72883\n",
      "2025-05-20 22:48:49,649 - INFO - model_training_classifier_20250520_224713.<module>:67 -   False Positives (FP) - Actual NO, Predicted YES: 10155 (Type I Error)\n",
      "2025-05-20 22:48:49,649 - INFO - model_training_classifier_20250520_224713.<module>:68 -   False Negatives (FN) - Actual YES, Predicted NO: 4431 (Type II Error)\n",
      "2025-05-20 22:48:49,649 - INFO - model_training_classifier_20250520_224713.<module>:69 -   True Positives (TP) - Actual YES, Predicted YES: 79908\n",
      "2025-05-20 22:48:49,665 - INFO - model_training_classifier_20250520_224713.<module>:88 - \n",
      "--- Logistic Regression Model Coefficients ---\n",
      "2025-05-20 22:48:49,666 - INFO - model_training_classifier_20250520_224713.<module>:92 - Intercept: 0.2499\n",
      "2025-05-20 22:48:49,668 - INFO - model_training_classifier_20250520_224713.<module>:118 - Trained Logistic Regression model saved to: /Users/omarabul-hassan/Desktop/projects/kalshi/notebooks/trained_models/logistic_regression_btc_classifier_v1.joblib\n",
      "2025-05-20 22:48:49,669 - INFO - model_training_classifier_20250520_224713.<module>:133 - Logistic Regression model parameters saved to: /Users/omarabul-hassan/Desktop/projects/kalshi/notebooks/trained_models/logreg_model_params_v1.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Sample of Test Set Predictions vs Actuals (Classification) ---\n",
      "         actual_target_resolves_yes  predicted_class_resolves_yes  predicted_proba_resolves_yes  original_target_diff\n",
      "1105142                           0                             0                      0.071834               -608.82\n",
      "1105143                           0                             0                      0.100146              -2053.99\n",
      "1105144                           0                             0                      0.061299               -858.82\n",
      "1105145                           0                             1                      0.925200                -53.99\n",
      "1105146                           1                             1                      0.982893               1446.01\n",
      "1105147                           0                             0                      0.057713              -1858.82\n",
      "1105148                           1                             1                      0.980323                891.18\n",
      "1105149                           0                             0                      0.071212               -608.82\n",
      "1105150                           0                             0                      0.056348              -2108.82\n",
      "1105151                           1                             1                      0.980011                641.18\n",
      "\n",
      "Top Coefficients (by absolute value) for P(TARGET_market_resolves_yes = 1):\n",
      "                           feature  coefficient  abs_coefficient\n",
      "16                  kalshi_yes_bid     0.955077         0.955077\n",
      "19                kalshi_mid_price     0.946866         0.946866\n",
      "17                  kalshi_yes_ask     0.890102         0.890102\n",
      "12     time_until_market_close_min     0.599907         0.599907\n",
      "18                   kalshi_spread    -0.205719         0.205719\n",
      "14                 day_of_week_utc    -0.185145         0.185145\n",
      "11              distance_to_strike     0.152418         0.152418\n",
      "21  kalshi_open_interest_t_minus_1    -0.118324         0.118324\n",
      "24               kalshi_mid_chg_5m    -0.098316         0.098316\n",
      "1                       btc_mom_5m     0.097825         0.097825\n",
      "0              btc_price_t_minus_1     0.061199         0.061199\n",
      "7                      btc_sma_30m     0.059381         0.059381\n",
      "9                      btc_ema_26m     0.058948         0.058948\n",
      "15                 hour_of_day_edt    -0.058425         0.058425\n",
      "8                      btc_ema_12m     0.057842         0.057842\n",
      "6                      btc_sma_10m     0.057513         0.057513\n",
      "23               kalshi_mid_chg_3m    -0.053308         0.053308\n",
      "20         kalshi_volume_t_minus_1    -0.044730         0.044730\n",
      "22               kalshi_mid_chg_1m    -0.039722         0.039722\n",
      "2                      btc_mom_10m     0.024034         0.024034\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Classification Model Training and Evaluation\n",
    "\n",
    "if 'X_train_scaled_df' not in globals() or X_train_scaled_df.empty:\n",
    "    logger.error(\"Scaled training data (X_train_scaled_df) not found or is empty. Please ensure Cell 2 ran successfully.\")\n",
    "    # Optionally, raise an error or stop notebook execution\n",
    "else:\n",
    "    logger.info(\"--- Starting Classification Model Training (Logistic Regression) ---\")\n",
    "\n",
    "    # --- 1. Initialize and Train Logistic Regression Model ---\n",
    "    # You can adjust parameters like C (inverse of regularization strength) or solver.\n",
    "    # Using class_weight='balanced' can be helpful if classes are imbalanced, though ours are fairly balanced.\n",
    "    # sag solver is good for large datasets, liblinear for smaller. lbfgs is a good default.\n",
    "    classifier_model = LogisticRegression(\n",
    "        solver='lbfgs', # A good default solver\n",
    "        max_iter=1000,  # Increased for convergence with potentially many features\n",
    "        random_state=42,\n",
    "        C=1.0, # Regularization strength\n",
    "        class_weight='balanced' # Optional: helps if classes are imbalanced\n",
    "    )\n",
    "    \n",
    "    logger.info(f\"Training LogisticRegression model on {X_train_scaled_df.shape[0]} samples...\")\n",
    "    \n",
    "    if 'y_train' not in globals() or y_train.empty:\n",
    "        logger.error(\"y_train (binary target) is not available. Cannot train model.\")\n",
    "    else:\n",
    "        try:\n",
    "            classifier_model.fit(X_train_scaled_df, y_train)\n",
    "            logger.info(\"LogisticRegression model training complete.\")\n",
    "\n",
    "            # --- 2. Make Predictions on the Test Set ---\n",
    "            logger.info(f\"Making predictions on the test set ({X_test_scaled_df.shape[0]} samples)...\")\n",
    "            y_pred_test_class = classifier_model.predict(X_test_scaled_df) # Predicts class labels (0 or 1)\n",
    "            y_pred_test_proba = classifier_model.predict_proba(X_test_scaled_df)[:, 1] # Probabilities for the positive class (class 1)\n",
    "\n",
    "            # --- 3. Evaluate Model Performance (Classification Metrics) ---\n",
    "            if 'y_test' not in globals() or y_test.empty:\n",
    "                logger.error(\"y_test (binary target) is not available. Cannot evaluate model.\")\n",
    "            else:\n",
    "                accuracy = accuracy_score(y_test, y_pred_test_class)\n",
    "                precision = precision_score(y_test, y_pred_test_class, zero_division=0)\n",
    "                recall = recall_score(y_test, y_pred_test_class, zero_division=0)\n",
    "                f1 = f1_score(y_test, y_pred_test_class, zero_division=0)\n",
    "                try:\n",
    "                    roc_auc = roc_auc_score(y_test, y_pred_test_proba) # Use probabilities for AUC\n",
    "                except ValueError as e:\n",
    "                    logger.warning(f\"Could not calculate ROC AUC, possibly due to only one class present in y_test or y_pred_test_proba. Error: {e}\")\n",
    "                    roc_auc = np.nan\n",
    "                logloss = log_loss(y_test, y_pred_test_proba) # Use probabilities for log loss\n",
    "\n",
    "                logger.info(\"\\n--- Classification Model Evaluation Metrics (Test Set) ---\")\n",
    "                logger.info(f\"  Accuracy:          {accuracy:.4f}\")\n",
    "                logger.info(f\"  Precision:         {precision:.4f} (Portion of predicted YES that were actually YES)\")\n",
    "                logger.info(f\"  Recall (TPR):      {recall:.4f} (Portion of actual YES that were correctly identified)\")\n",
    "                logger.info(f\"  F1-Score:          {f1:.4f}\")\n",
    "                logger.info(f\"  ROC AUC:           {roc_auc:.4f}\")\n",
    "                logger.info(f\"  Log Loss:          {logloss:.4f}\")\n",
    "\n",
    "                logger.info(\"\\n--- Confusion Matrix (Test Set) ---\")\n",
    "                # Rows: Actual, Columns: Predicted\n",
    "                # [[TN, FP],\n",
    "                #  [FN, TP]]\n",
    "                cm = confusion_matrix(y_test, y_pred_test_class)\n",
    "                logger.info(f\"\\n{cm}\")\n",
    "                try:\n",
    "                    tn, fp, fn, tp = cm.ravel()\n",
    "                    logger.info(f\"  True Negatives (TN) - Actual NO, Predicted NO:  {tn}\")\n",
    "                    logger.info(f\"  False Positives (FP) - Actual NO, Predicted YES: {fp} (Type I Error)\")\n",
    "                    logger.info(f\"  False Negatives (FN) - Actual YES, Predicted NO: {fn} (Type II Error)\")\n",
    "                    logger.info(f\"  True Positives (TP) - Actual YES, Predicted YES: {tp}\")\n",
    "                except ValueError: # If cm doesn't have 4 values (e.g. predicts only one class)\n",
    "                    logger.warning(\"Could not unpack full confusion matrix (TN,FP,FN,TP).\")\n",
    "\n",
    "\n",
    "                # Create a DataFrame for easier analysis of predictions vs actuals\n",
    "                df_results_class = pd.DataFrame({\n",
    "                    'actual_target_resolves_yes': y_test,\n",
    "                    'predicted_class_resolves_yes': y_pred_test_class,\n",
    "                    'predicted_proba_resolves_yes': y_pred_test_proba\n",
    "                })\n",
    "                # Add back the original regression target for context if needed\n",
    "                if original_target_col in df_model_data.columns: # From Cell 2\n",
    "                    df_results_class['original_target_diff'] = df_model_data.loc[y_test.index, original_target_col]\n",
    "\n",
    "                print(\"\\n--- Sample of Test Set Predictions vs Actuals (Classification) ---\")\n",
    "                print(df_results_class.head(10).to_string())\n",
    "\n",
    "                # --- 4. Inspect Model Coefficients (for Logistic Regression) ---\n",
    "                logger.info(\"\\n--- Logistic Regression Model Coefficients ---\")\n",
    "                # For Logistic Regression, intercept is an array if multi-class, or a float if binary.\n",
    "                # coef_ is also 2D for multi-class, (1, n_features) for binary.\n",
    "                if hasattr(classifier_model, 'intercept_') and hasattr(classifier_model, 'coef_'):\n",
    "                    logger.info(f\"Intercept: {classifier_model.intercept_[0]:.4f}\") # Assuming binary classification, intercept_ is array of one\n",
    "                    \n",
    "                    # Ensure feature_columns is available\n",
    "                    if 'feature_columns' not in globals(): # Should be defined in Cell 2\n",
    "                        feature_columns_list_path = MODEL_OUTPUT_DIR / \"feature_columns_classifier_v1.json\"\n",
    "                        if feature_columns_list_path.exists():\n",
    "                            with open(feature_columns_list_path, 'r') as f:\n",
    "                                feature_columns = json.load(f)\n",
    "                            logger.info(f\"Loaded feature_columns list from {feature_columns_list_path}\")\n",
    "                        else:\n",
    "                            logger.warning(\"feature_columns list not found. Cannot display coefficient names.\")\n",
    "                            feature_columns = [f\"feature_{i}\" for i in range(classifier_model.coef_.shape[1])]\n",
    "                    \n",
    "                    # Coefficients are for the positive class (class 1) in binary classification\n",
    "                    coefficients = pd.DataFrame({'feature': feature_columns, 'coefficient': classifier_model.coef_[0]})\n",
    "                    coefficients['abs_coefficient'] = np.abs(coefficients['coefficient'])\n",
    "                    coefficients.sort_values(by='abs_coefficient', ascending=False, inplace=True)\n",
    "                    \n",
    "                    print(\"\\nTop Coefficients (by absolute value) for P(TARGET_market_resolves_yes = 1):\")\n",
    "                    print(coefficients.head(20).to_string())\n",
    "                else:\n",
    "                    logger.warning(\"Could not retrieve coefficients from the trained classifier model.\")\n",
    "\n",
    "                # --- 5. Save the Trained Model ---\n",
    "                model_path = MODEL_OUTPUT_DIR / \"logistic_regression_btc_classifier_v1.joblib\" # New name\n",
    "                joblib.dump(classifier_model, model_path)\n",
    "                logger.info(f\"Trained Logistic Regression model saved to: {model_path}\")\n",
    "\n",
    "                # Save model parameters for potential use in a strategy that doesn't load the full joblib\n",
    "                # For Logistic Regression, this includes coefficients and intercept.\n",
    "                # The strategy will need to apply the sigmoid function to the raw score if using these.\n",
    "                model_params_for_backtest = {\n",
    "                    'model_type': 'logistic_regression',\n",
    "                    'intercept': classifier_model.intercept_[0].tolist() if isinstance(classifier_model.intercept_, np.ndarray) else classifier_model.intercept_,\n",
    "                    'coefficients': dict(zip(feature_columns, classifier_model.coef_[0])),\n",
    "                    'feature_order': feature_columns, # From Cell 2\n",
    "                    'classes': classifier_model.classes_.tolist() # [0, 1] for binary\n",
    "                }\n",
    "                params_path = MODEL_OUTPUT_DIR / \"logreg_model_params_v1.json\" # New name\n",
    "                with open(params_path, 'w') as f:\n",
    "                    json.dump(model_params_for_backtest, f, indent=4)\n",
    "                logger.info(f\"Logistic Regression model parameters saved to: {params_path}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.critical(f\"An error occurred during classification model training or evaluation: {e}\", exc_info=True)\n",
    "            if 'classifier_model' in locals():\n",
    "                 logger.info(\"Model training might have partially completed or failed during evaluation.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
