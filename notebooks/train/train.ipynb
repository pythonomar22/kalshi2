{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-19 12:26:10,265 - INFO - model_training_20250519_122610.<module>:35 - Attempting to find feature files in: /Users/omarabul-hassan/Desktop/projects/kalshi/notebooks/features\n",
      "2025-05-19 12:26:10,267 - INFO - model_training_20250519_122610.<module>:44 - Using features CSV: /Users/omarabul-hassan/Desktop/projects/kalshi/notebooks/features/kalshi_btc_features_target_v1_20250519_121558.csv\n",
      "2025-05-19 12:26:10,267 - INFO - model_training_20250519_122610.<module>:54 - Trained models will be saved in: /Users/omarabul-hassan/Desktop/projects/kalshi/notebooks/trained_models\n",
      "2025-05-19 12:26:12,299 - INFO - model_training_20250519_122610.<module>:64 - Successfully loaded features data from: /Users/omarabul-hassan/Desktop/projects/kalshi/notebooks/features/kalshi_btc_features_target_v1_20250519_121558.csv\n",
      "2025-05-19 12:26:12,299 - INFO - model_training_20250519_122610.<module>:65 - Shape of loaded data: (1294800, 29)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Data Head ---\n",
      "          kalshi_market_ticker  decision_point_ts_utc  kalshi_strike_price  \\\n",
      "0  KXBTCD-25MAY1522-T106249.99             1747357200            106249.99   \n",
      "1  KXBTCD-25MAY1522-T106249.99             1747357260            106249.99   \n",
      "2  KXBTCD-25MAY1522-T106249.99             1747357320            106249.99   \n",
      "3  KXBTCD-25MAY1522-T106249.99             1747357380            106249.99   \n",
      "4  KXBTCD-25MAY1522-T106249.99             1747357440            106249.99   \n",
      "\n",
      "   btc_price_t_minus_1  btc_mom_5m  btc_mom_10m  btc_mom_15m  btc_mom_30m  \\\n",
      "0            103764.81       73.29       -69.79      -182.17        22.80   \n",
      "1            103709.10       17.67      -111.60      -246.90       -68.90   \n",
      "2            103785.66       83.21         7.89      -114.10      -109.26   \n",
      "3            103691.25      -34.40         5.91      -227.89      -285.74   \n",
      "4            103629.36     -110.19       -98.42      -303.61      -299.95   \n",
      "\n",
      "   btc_vol_15m  btc_sma_10m  ...  TARGET_btc_diff_from_strike  kalshi_yes_bid  \\\n",
      "0    95.991753   103732.700  ...                     -2011.89             NaN   \n",
      "1    86.424046   103721.540  ...                     -2011.89             NaN   \n",
      "2    79.377628   103722.329  ...                     -2011.89             0.0   \n",
      "3    69.408713   103722.920  ...                     -2011.89             0.0   \n",
      "4    55.815136   103713.078  ...                     -2011.89             0.0   \n",
      "\n",
      "   kalshi_yes_ask  kalshi_spread  kalshi_mid_price  kalshi_volume_t_minus_1  \\\n",
      "0             NaN            NaN               NaN                      NaN   \n",
      "1             NaN            NaN               NaN                      NaN   \n",
      "2            30.0           30.0              15.0                      0.0   \n",
      "3            30.0           30.0              15.0                      0.0   \n",
      "4            30.0           30.0              15.0                      0.0   \n",
      "\n",
      "   kalshi_open_interest_t_minus_1  kalshi_mid_chg_1m  kalshi_mid_chg_3m  \\\n",
      "0                             NaN                NaN                NaN   \n",
      "1                             NaN                NaN                NaN   \n",
      "2                             0.0                NaN                NaN   \n",
      "3                             0.0                0.0                NaN   \n",
      "4                             0.0                0.0                NaN   \n",
      "\n",
      "   kalshi_mid_chg_5m  \n",
      "0                NaN  \n",
      "1                NaN  \n",
      "2                NaN  \n",
      "3                NaN  \n",
      "4                NaN  \n",
      "\n",
      "[5 rows x 29 columns]\n",
      "\n",
      "--- Data Info ---\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1294800 entries, 0 to 1294799\n",
      "Data columns (total 29 columns):\n",
      " #   Column                          Non-Null Count    Dtype  \n",
      "---  ------                          --------------    -----  \n",
      " 0   kalshi_market_ticker            1294800 non-null  object \n",
      " 1   decision_point_ts_utc           1294800 non-null  int64  \n",
      " 2   kalshi_strike_price             1294800 non-null  float64\n",
      " 3   btc_price_t_minus_1             1294800 non-null  float64\n",
      " 4   btc_mom_5m                      1289175 non-null  float64\n",
      " 5   btc_mom_10m                     1283550 non-null  float64\n",
      " 6   btc_mom_15m                     1277925 non-null  float64\n",
      " 7   btc_mom_30m                     1261050 non-null  float64\n",
      " 8   btc_vol_15m                     1293675 non-null  float64\n",
      " 9   btc_sma_10m                     1294800 non-null  float64\n",
      " 10  btc_sma_30m                     1294800 non-null  float64\n",
      " 11  btc_ema_12m                     1294800 non-null  float64\n",
      " 12  btc_ema_26m                     1294800 non-null  float64\n",
      " 13  btc_rsi                         1294800 non-null  float64\n",
      " 14  distance_to_strike              1294800 non-null  float64\n",
      " 15  time_until_market_close_min     1294800 non-null  float64\n",
      " 16  hour_of_day_utc                 1294800 non-null  int64  \n",
      " 17  day_of_week_utc                 1294800 non-null  int64  \n",
      " 18  hour_of_day_edt                 1294800 non-null  int64  \n",
      " 19  TARGET_btc_diff_from_strike     1294800 non-null  float64\n",
      " 20  kalshi_yes_bid                  836884 non-null   float64\n",
      " 21  kalshi_yes_ask                  836884 non-null   float64\n",
      " 22  kalshi_spread                   836884 non-null   float64\n",
      " 23  kalshi_mid_price                836884 non-null   float64\n",
      " 24  kalshi_volume_t_minus_1         836884 non-null   float64\n",
      " 25  kalshi_open_interest_t_minus_1  836884 non-null   float64\n",
      " 26  kalshi_mid_chg_1m               827712 non-null   float64\n",
      " 27  kalshi_mid_chg_3m               809368 non-null   float64\n",
      " 28  kalshi_mid_chg_5m               794085 non-null   float64\n",
      "dtypes: float64(24), int64(4), object(1)\n",
      "memory usage: 286.5+ MB\n",
      "\n",
      "--- Data Description (Numerical) ---\n",
      "       decision_point_ts_utc  kalshi_strike_price  btc_price_t_minus_1    btc_mom_5m   btc_mom_10m   btc_mom_15m   btc_mom_30m   btc_vol_15m   btc_sma_10m   btc_sma_30m   btc_ema_12m   btc_ema_26m       btc_rsi  distance_to_strike  time_until_market_close_min  hour_of_day_utc  day_of_week_utc  hour_of_day_edt  TARGET_btc_diff_from_strike  kalshi_yes_bid  kalshi_yes_ask  kalshi_spread  kalshi_mid_price  kalshi_volume_t_minus_1  kalshi_open_interest_t_minus_1  kalshi_mid_chg_1m  kalshi_mid_chg_3m  kalshi_mid_chg_5m\n",
      "count           1.294800e+06         1.294800e+06         1.294800e+06  1.289175e+06  1.283550e+06  1.277925e+06  1.261050e+06  1.293675e+06  1.294800e+06  1.294800e+06  1.294800e+06  1.294800e+06  1.294800e+06        1.294800e+06                 1.294800e+06     1.294800e+06     1.294800e+06     1.294800e+06                 1.294800e+06   836884.000000   836884.000000  836884.000000     836884.000000            836884.000000                   836884.000000      827712.000000      809368.000000      794085.000000\n",
      "mean            1.745949e+09         9.510212e+04         9.408098e+04  1.941602e+00  3.926268e+00  5.944350e+00  1.144532e+01  6.429325e+01  9.407924e+04  9.407541e+04  9.407885e+04  9.407621e+04  5.052580e+01       -1.021137e+03                 1.706085e+03     1.225158e+01     2.898842e+00     1.320728e+01                 5.495876e+01       40.910939       54.039580      13.128641         47.475259                23.465873                      581.263225           0.006214           0.016046           0.035981\n",
      "std             7.798241e+05         6.636818e+03         6.307015e+03  1.097993e+02  1.533758e+02  1.862648e+02  2.571959e+02  4.693030e+01  6.307088e+03  6.307507e+03  6.306918e+03  6.307023e+03  1.753297e+01        2.802957e+03                 2.691954e+03     7.286352e+00     1.994109e+00     6.388092e+00                 1.410487e+03       37.123268       36.372663      15.347168         35.939810               198.715751                     1906.726984           3.891034           5.258502           6.020547\n",
      "min             1.744402e+09         8.124999e+04         8.280487e+04 -1.188610e+03 -1.376040e+03 -1.320860e+03 -2.029050e+03  1.958686e+00  8.286691e+04  8.292615e+04  8.289461e+04  8.294807e+04  0.000000e+00       -1.251395e+04                 1.000000e+00     0.000000e+00     0.000000e+00     0.000000e+00                -3.932710e+03        0.000000        1.000000       1.000000          0.500000                 0.000000                        0.000000         -79.000000         -92.000000         -93.000000\n",
      "25%             1.745294e+09         9.199999e+04         8.827201e+04 -5.256000e+01 -7.404000e+01 -8.951000e+01 -1.190200e+02  3.539188e+01  8.825410e+04  8.822399e+04  8.824066e+04  8.822397e+04  3.797695e+01       -1.904000e+03                 3.600000e+01     5.000000e+00     1.000000e+00     9.000000e+00                -1.111930e+03        1.000000       16.000000       4.000000         11.000000                 0.000000                        0.000000           0.000000          -0.500000          -1.000000\n",
      "50%             1.745957e+09         9.549999e+04         9.455490e+04  1.060000e+00  2.190000e+00  3.430000e+00  8.210000e+00  5.223952e+01  9.455613e+04  9.456229e+04  9.455684e+04  9.456050e+04  5.041273e+01       -5.322600e+02                 3.900000e+02     1.300000e+01     3.000000e+00     1.400000e+01                 2.232000e+01       35.000000       50.000000       7.000000         41.000000                 0.000000                        0.000000           0.000000           0.000000           0.000000\n",
      "75%             1.746586e+09         1.010000e+05         9.697530e+04  5.582000e+01  8.155000e+01  9.988000e+01  1.367900e+02  7.839257e+01  9.697389e+04  9.698326e+04  9.697901e+04  9.697788e+04  6.325748e+01        8.669400e+02                 1.487000e+03     1.800000e+01     5.000000e+00     1.900000e+01                 1.215835e+03       82.000000       97.000000      16.000000         86.000000                 0.000000                      281.000000           0.000000           0.500000           1.000000\n",
      "max             1.747361e+09         1.072500e+05         1.056790e+05  1.777730e+03  2.026420e+03  2.093720e+03  1.898320e+03  7.430210e+02  1.055105e+05  1.054629e+05  1.054993e+05  1.053845e+05  1.000000e+02        5.929020e+03                 1.014000e+04     2.300000e+01     6.000000e+00     2.300000e+01                 4.250510e+03       99.000000      100.000000     100.000000         99.500000             14727.000000                   319814.000000          91.500000          93.500000          92.500000\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Imports and Load Data\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from pathlib import Path\n",
    "import datetime as dt\n",
    "from datetime import timezone, timedelta # <<<<<<<<<<<< ADD timezone HERE\n",
    "import logging\n",
    "import json # For saving feature_columns_list\n",
    "import joblib # For saving the model and scaler\n",
    "\n",
    "from sklearn.model_selection import train_test_split # We'll do a chronological split manually\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler # For feature scaling\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# --- Logging Setup ---\n",
    "# ... (rest of logging setup as before) ...\n",
    "logger_name = f\"model_training_{dt.datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
    "logger = logging.getLogger(logger_name)\n",
    "if not logger.handlers: # Avoid adding handlers if re-running cell\n",
    "    logger.setLevel(logging.INFO)\n",
    "    formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(name)s.%(funcName)s:%(lineno)d - %(message)s')\n",
    "    ch = logging.StreamHandler()\n",
    "    ch.setFormatter(formatter)\n",
    "    logger.addHandler(ch)\n",
    "else:\n",
    "    logger.setLevel(logging.INFO)\n",
    "\n",
    "# --- Configuration ---\n",
    "# ... (rest of configuration as before) ...\n",
    "current_notebook_dir = Path.cwd()\n",
    "FEATURES_DIR = current_notebook_dir.parent / \"features\"\n",
    "logger.info(f\"Attempting to find feature files in: {FEATURES_DIR.resolve()}\")\n",
    "\n",
    "try:\n",
    "    if not FEATURES_DIR.exists():\n",
    "        raise FileNotFoundError(f\"The directory {FEATURES_DIR.resolve()} does not exist. Please check the path.\")\n",
    "    feature_files = sorted(FEATURES_DIR.glob(\"kalshi_btc_features_target_v1_*.csv\"), key=os.path.getctime, reverse=True)\n",
    "    if not feature_files:\n",
    "        raise FileNotFoundError(f\"No feature CSV files found in {FEATURES_DIR.resolve()} matching pattern 'kalshi_btc_features_target_v1_*.csv'\")\n",
    "    FEATURES_CSV_PATH = feature_files[0]\n",
    "    logger.info(f\"Using features CSV: {FEATURES_CSV_PATH.resolve()}\")\n",
    "except FileNotFoundError as e:\n",
    "    logger.critical(str(e))\n",
    "    FEATURES_CSV_PATH = None\n",
    "except Exception as e:\n",
    "    logger.critical(f\"Error finding features CSV: {e}\")\n",
    "    FEATURES_CSV_PATH = None\n",
    "\n",
    "MODEL_OUTPUT_DIR = current_notebook_dir.parent / \"trained_models\"\n",
    "MODEL_OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "logger.info(f\"Trained models will be saved in: {MODEL_OUTPUT_DIR.resolve()}\")\n",
    "\n",
    "\n",
    "# --- Load the Features DataFrame ---\n",
    "# ... (rest of data loading as before) ...\n",
    "df_model_data = pd.DataFrame()\n",
    "\n",
    "if FEATURES_CSV_PATH and FEATURES_CSV_PATH.exists():\n",
    "    try:\n",
    "        df_model_data = pd.read_csv(FEATURES_CSV_PATH)\n",
    "        logger.info(f\"Successfully loaded features data from: {FEATURES_CSV_PATH.resolve()}\")\n",
    "        logger.info(f\"Shape of loaded data: {df_model_data.shape}\")\n",
    "        \n",
    "        print(\"--- Data Head ---\")\n",
    "        print(df_model_data.head())\n",
    "        print(\"\\n--- Data Info ---\")\n",
    "        df_model_data.info()\n",
    "        print(\"\\n--- Data Description (Numerical) ---\")\n",
    "        print(df_model_data.describe().to_string())\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.critical(f\"Error loading features CSV {FEATURES_CSV_PATH.resolve()}: {e}\")\n",
    "else:\n",
    "    if FEATURES_CSV_PATH:\n",
    "         logger.critical(f\"Features CSV file not found at the specified path: {FEATURES_CSV_PATH.resolve()}\")\n",
    "    else:\n",
    "         logger.critical(\"FEATURES_CSV_PATH was not set (likely due to an error finding the file). Cannot load data.\")\n",
    "\n",
    "if df_model_data.empty:\n",
    "    logger.warning(\"DataFrame df_model_data is empty. Subsequent cells might fail.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-19 12:27:20,651 - INFO - model_training_20250519_122610.<module>:8 - Starting preprocessing for df_model_data with shape: (1294800, 29)\n",
      "2025-05-19 12:27:20,762 - INFO - model_training_20250519_122610.<module>:14 - Data sorted by 'decision_point_ts_utc'.\n",
      "2025-05-19 12:27:20,763 - INFO - model_training_20250519_122610.<module>:28 - Potential feature columns (25): ['btc_price_t_minus_1', 'btc_mom_5m', 'btc_mom_10m', 'btc_mom_15m', 'btc_mom_30m', 'btc_vol_15m', 'btc_sma_10m', 'btc_sma_30m', 'btc_ema_12m', 'btc_ema_26m', 'btc_rsi', 'distance_to_strike', 'time_until_market_close_min', 'hour_of_day_utc', 'day_of_week_utc', 'hour_of_day_edt', 'kalshi_yes_bid', 'kalshi_yes_ask', 'kalshi_spread', 'kalshi_mid_price', 'kalshi_volume_t_minus_1', 'kalshi_open_interest_t_minus_1', 'kalshi_mid_chg_1m', 'kalshi_mid_chg_3m', 'kalshi_mid_chg_5m']\n",
      "2025-05-19 12:27:20,821 - WARNING - model_training_20250519_122610.<module>:39 - NaN values found in feature columns:\n",
      "kalshi_mid_chg_5m                 500715\n",
      "kalshi_mid_chg_3m                 485432\n",
      "kalshi_mid_chg_1m                 467088\n",
      "kalshi_yes_bid                    457916\n",
      "kalshi_yes_ask                    457916\n",
      "kalshi_spread                     457916\n",
      "kalshi_mid_price                  457916\n",
      "kalshi_volume_t_minus_1           457916\n",
      "kalshi_open_interest_t_minus_1    457916\n",
      "btc_mom_30m                        33750\n",
      "btc_mom_15m                        16875\n",
      "btc_mom_10m                        11250\n",
      "btc_mom_5m                          5625\n",
      "btc_vol_15m                         1125\n",
      "dtype: int64\n",
      "2025-05-19 12:27:20,824 - INFO - model_training_20250519_122610.<module>:65 - Filled NaNs in 'kalshi_yes_bid' with 0.\n",
      "2025-05-19 12:27:20,827 - INFO - model_training_20250519_122610.<module>:68 - Filled NaNs in 'kalshi_yes_ask' with 100.\n",
      "2025-05-19 12:27:20,830 - INFO - model_training_20250519_122610.<module>:74 - Recalculated 'kalshi_spread' after filling bid/ask.\n",
      "2025-05-19 12:27:20,831 - INFO - model_training_20250519_122610.<module>:77 - Recalculated 'kalshi_mid_price' after filling bid/ask.\n",
      "2025-05-19 12:27:20,834 - INFO - model_training_20250519_122610.<module>:82 - Filled NaNs in 'btc_mom_5m' with 0.\n",
      "2025-05-19 12:27:20,836 - INFO - model_training_20250519_122610.<module>:82 - Filled NaNs in 'btc_mom_10m' with 0.\n",
      "2025-05-19 12:27:20,838 - INFO - model_training_20250519_122610.<module>:82 - Filled NaNs in 'btc_mom_15m' with 0.\n",
      "2025-05-19 12:27:20,841 - INFO - model_training_20250519_122610.<module>:82 - Filled NaNs in 'btc_mom_30m' with 0.\n",
      "2025-05-19 12:27:20,844 - INFO - model_training_20250519_122610.<module>:82 - Filled NaNs in 'kalshi_mid_chg_1m' with 0.\n",
      "2025-05-19 12:27:20,846 - INFO - model_training_20250519_122610.<module>:82 - Filled NaNs in 'kalshi_mid_chg_3m' with 0.\n",
      "2025-05-19 12:27:20,849 - INFO - model_training_20250519_122610.<module>:82 - Filled NaNs in 'kalshi_mid_chg_5m' with 0.\n",
      "2025-05-19 12:27:20,856 - INFO - model_training_20250519_122610.<module>:88 - Filled NaNs in 'btc_vol_15m' with its median (52.2395).\n",
      "2025-05-19 12:27:20,862 - INFO - model_training_20250519_122610.<module>:88 - Filled NaNs in 'btc_sma_10m' with its median (94556.1280).\n",
      "2025-05-19 12:27:20,868 - INFO - model_training_20250519_122610.<module>:88 - Filled NaNs in 'btc_sma_30m' with its median (94562.2887).\n",
      "2025-05-19 12:27:20,875 - INFO - model_training_20250519_122610.<module>:88 - Filled NaNs in 'btc_ema_12m' with its median (94556.8417).\n",
      "2025-05-19 12:27:20,880 - INFO - model_training_20250519_122610.<module>:88 - Filled NaNs in 'btc_ema_26m' with its median (94560.5028).\n",
      "2025-05-19 12:27:20,882 - INFO - model_training_20250519_122610.<module>:93 - Filled NaNs in 'btc_rsi' with 50.\n",
      "2025-05-19 12:27:21,010 - INFO - model_training_20250519_122610.<module>:98 - Dropped 457916 rows due to remaining NaNs in feature columns after imputation attempts.\n",
      "2025-05-19 12:27:21,187 - INFO - model_training_20250519_122610.<module>:105 - Successfully handled NaNs in feature columns.\n",
      "2025-05-19 12:27:21,251 - INFO - model_training_20250519_122610.<module>:114 - Defined X (features) with shape: (836884, 25)\n",
      "2025-05-19 12:27:21,251 - INFO - model_training_20250519_122610.<module>:115 - Defined y (target) with shape: (836884,)\n",
      "2025-05-19 12:27:21,257 - INFO - model_training_20250519_122610.<module>:128 - Data split chronologically:\n",
      "2025-05-19 12:27:21,257 - INFO - model_training_20250519_122610.<module>:129 -   X_train shape: (669507, 25), y_train shape: (669507,)\n",
      "2025-05-19 12:27:21,258 - INFO - model_training_20250519_122610.<module>:130 -   X_test shape: (167377, 25), y_test shape: (167377,)\n",
      "2025-05-19 12:27:21,258 - INFO - model_training_20250519_122610.<module>:138 -   Training data from: 2025-04-11T20:02:00+00:00 to 2025-05-10T13:18:00+00:00\n",
      "2025-05-19 12:27:21,258 - INFO - model_training_20250519_122610.<module>:139 -   Test data from:     2025-05-10T13:18:00+00:00 to 2025-05-16T01:59:00+00:00\n",
      "2025-05-19 12:27:21,361 - INFO - model_training_20250519_122610.<module>:151 - Features scaled using StandardScaler.\n",
      "2025-05-19 12:27:21,364 - INFO - model_training_20250519_122610.<module>:158 - Scaler saved to: /Users/omarabul-hassan/Desktop/projects/kalshi/notebooks/trained_models/feature_scaler_v1.joblib\n",
      "2025-05-19 12:27:21,365 - INFO - model_training_20250519_122610.<module>:165 - List of feature columns saved to: /Users/omarabul-hassan/Desktop/projects/kalshi/notebooks/trained_models/feature_columns_v1.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample of scaled training features (X_train_scaled_df head):\n",
      "    btc_price_t_minus_1  btc_mom_5m  btc_mom_10m  btc_mom_15m  btc_mom_30m  \\\n",
      "18            -1.880955   -0.267215    -0.671256    -0.499148      0.23473   \n",
      "19            -1.880955   -0.267215    -0.671256    -0.499148      0.23473   \n",
      "20            -1.880955   -0.267215    -0.671256    -0.499148      0.23473   \n",
      "21            -1.880955   -0.267215    -0.671256    -0.499148      0.23473   \n",
      "22            -1.880955   -0.267215    -0.671256    -0.499148      0.23473   \n",
      "\n",
      "    btc_vol_15m  btc_sma_10m  btc_sma_30m  btc_ema_12m  btc_ema_26m  ...  \\\n",
      "18    -0.365124     -1.86631    -1.870939    -1.867321    -1.868163  ...   \n",
      "19    -0.365124     -1.86631    -1.870939    -1.867321    -1.868163  ...   \n",
      "20    -0.365124     -1.86631    -1.870939    -1.867321    -1.868163  ...   \n",
      "21    -0.365124     -1.86631    -1.870939    -1.867321    -1.868163  ...   \n",
      "22    -0.365124     -1.86631    -1.870939    -1.867321    -1.868163  ...   \n",
      "\n",
      "    hour_of_day_edt  kalshi_yes_bid  kalshi_yes_ask  kalshi_spread  \\\n",
      "18         0.335034        0.208052       -0.013834      -0.503196   \n",
      "19         0.335034        0.126367       -0.097936      -0.503196   \n",
      "20         0.335034        0.371422        0.182403      -0.441336   \n",
      "21         0.335034        0.262509        0.070267      -0.441336   \n",
      "22         0.335034       -0.173146       -0.378274      -0.441336   \n",
      "\n",
      "    kalshi_mid_price  kalshi_volume_t_minus_1  kalshi_open_interest_t_minus_1  \\\n",
      "18          0.101272                -0.118801                       -0.304479   \n",
      "19          0.016259                -0.118801                       -0.304479   \n",
      "20          0.285466                -0.118801                       -0.304479   \n",
      "21          0.172116                -0.118801                       -0.304479   \n",
      "22         -0.281286                -0.118801                       -0.304479   \n",
      "\n",
      "    kalshi_mid_chg_1m  kalshi_mid_chg_3m  kalshi_mid_chg_5m  \n",
      "18          -0.002132          -0.004412          -0.008278  \n",
      "19          -0.002132          -0.004412          -0.008278  \n",
      "20          -0.002132          -0.004412          -0.008278  \n",
      "21          -0.002132          -0.004412          -0.008278  \n",
      "22          -0.002132          -0.004412          -0.008278  \n",
      "\n",
      "[5 rows x 25 columns]\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Data Preprocessing, Feature Selection, and Splitting\n",
    "\n",
    "if df_model_data.empty:\n",
    "    logger.error(\"df_model_data is empty. Cannot proceed with preprocessing and splitting. Please ensure Cell 1 ran correctly and loaded data.\")\n",
    "    # Depending on your workflow, you might want to raise an error or stop execution here\n",
    "    # For now, we'll let it proceed, but subsequent steps will likely fail or do nothing.\n",
    "else:\n",
    "    logger.info(f\"Starting preprocessing for df_model_data with shape: {df_model_data.shape}\")\n",
    "\n",
    "    # --- 1. Ensure Chronological Order ---\n",
    "    # This should have been done when saving, but good to double-check or re-apply\n",
    "    df_model_data.sort_values(by='decision_point_ts_utc', inplace=True)\n",
    "    df_model_data.reset_index(drop=True, inplace=True)\n",
    "    logger.info(\"Data sorted by 'decision_point_ts_utc'.\")\n",
    "\n",
    "    # --- 2. Handle Missing Values (NaNs) ---\n",
    "    # Review NaN counts from Cell 1's output (df_model_data.info() and describe())\n",
    "    # and the feature generation process.\n",
    "\n",
    "    # Let's list the columns we expect to be features\n",
    "    # Exclude identifiers and the target variable itself\n",
    "    identifier_cols = ['kalshi_market_ticker', 'decision_point_ts_utc', 'kalshi_strike_price']\n",
    "    target_col = 'TARGET_btc_diff_from_strike'\n",
    "    \n",
    "    # All other columns are potential features\n",
    "    feature_columns = [col for col in df_model_data.columns if col not in identifier_cols + [target_col]]\n",
    "    \n",
    "    logger.info(f\"Potential feature columns ({len(feature_columns)}): {feature_columns}\")\n",
    "\n",
    "    # NaN Handling Strategy:\n",
    "    # For a first pass with Linear Regression, we typically need complete data.\n",
    "    # Option A: Drop rows with any NaNs in the selected feature_columns.\n",
    "    # Option B: Impute.\n",
    "    \n",
    "    # Let's check NaN counts for our selected feature_columns\n",
    "    nan_summary = df_model_data[feature_columns].isnull().sum()\n",
    "    nan_summary = nan_summary[nan_summary > 0].sort_values(ascending=False)\n",
    "    if not nan_summary.empty:\n",
    "        logger.warning(f\"NaN values found in feature columns:\\n{nan_summary}\")\n",
    "        \n",
    "        # --- Imputation Strategy (Example - can be refined) ---\n",
    "        # For Kalshi price features (bid, ask, spread, mid, changes), NaNs often mean no market activity.\n",
    "        # Imputing with 0 or a special value might be an option.\n",
    "        # For TA indicators, initial NaNs are expected.\n",
    "        \n",
    "        cols_to_fill_zero = [\n",
    "            col for col in feature_columns if 'kalshi_mid_chg' in col or \\\n",
    "            'btc_mom' in col # Momentum can be zero if no change or at start\n",
    "        ]\n",
    "        cols_to_fill_median = [ # Median is often more robust to outliers than mean\n",
    "            col for col in feature_columns if 'btc_vol' in col or \\\n",
    "            'btc_sma' in col or 'btc_ema' in col \n",
    "        ]\n",
    "        cols_to_fill_rsi_neutral = [col for col in feature_columns if 'btc_rsi' in col]\n",
    "\n",
    "        # Kalshi bid/ask/spread/mid_price NaNs are tricky.\n",
    "        # If NaN, it means no quote. For now, let's fill with a value that might indicate this.\n",
    "        # Or, consider creating a binary feature \"kalshi_quotes_available\".\n",
    "        # For simplicity, let's fill yes_bid with 0, yes_ask with 100 (max spread, low confidence)\n",
    "        # and mid_price with 50. Spread would then be 100.\n",
    "        # This is a very basic strategy and might introduce bias or noise.\n",
    "        \n",
    "        if 'kalshi_yes_bid' in df_model_data.columns:\n",
    "            df_model_data['kalshi_yes_bid'] = df_model_data['kalshi_yes_bid'].fillna(0) # Assign back\n",
    "            logger.info(\"Filled NaNs in 'kalshi_yes_bid' with 0.\")\n",
    "        if 'kalshi_yes_ask' in df_model_data.columns:\n",
    "            df_model_data['kalshi_yes_ask'] = df_model_data['kalshi_yes_ask'].fillna(100) # Assign back\n",
    "            logger.info(\"Filled NaNs in 'kalshi_yes_ask' with 100.\")\n",
    "        \n",
    "        # Re-calculate spread and mid_price if they existed and bids/asks were filled\n",
    "        if 'kalshi_yes_bid' in df_model_data.columns and 'kalshi_yes_ask' in df_model_data.columns:\n",
    "            if 'kalshi_spread' in df_model_data.columns:\n",
    "                df_model_data['kalshi_spread'] = df_model_data['kalshi_yes_ask'] - df_model_data['kalshi_yes_bid']\n",
    "                logger.info(\"Recalculated 'kalshi_spread' after filling bid/ask.\")\n",
    "            if 'kalshi_mid_price' in df_model_data.columns:\n",
    "                 df_model_data['kalshi_mid_price'] = (df_model_data['kalshi_yes_bid'] + df_model_data['kalshi_yes_ask']) / 2\n",
    "                 logger.info(\"Recalculated 'kalshi_mid_price' after filling bid/ask.\")\n",
    "        \n",
    "        for col in cols_to_fill_zero:\n",
    "            if col in df_model_data.columns:\n",
    "                df_model_data[col] = df_model_data[col].fillna(0) # Assign back\n",
    "                logger.info(f\"Filled NaNs in '{col}' with 0.\")\n",
    "\n",
    "        for col in cols_to_fill_median:\n",
    "            if col in df_model_data.columns:\n",
    "                median_val = df_model_data[col].median()\n",
    "                df_model_data[col] = df_model_data[col].fillna(median_val) # Assign back\n",
    "                logger.info(f\"Filled NaNs in '{col}' with its median ({median_val:.4f}).\")\n",
    "\n",
    "        for col in cols_to_fill_rsi_neutral:\n",
    "            if col in df_model_data.columns:\n",
    "                df_model_data[col] = df_model_data[col].fillna(50) # Assign back\n",
    "                logger.info(f\"Filled NaNs in '{col}' with 50.\")\n",
    "\n",
    "        # For remaining NaNs in features (e.g., volume, open interest if sparse), drop rows\n",
    "        original_row_count = len(df_model_data)\n",
    "        df_model_data.dropna(subset=feature_columns, inplace=True)\n",
    "        logger.info(f\"Dropped {original_row_count - len(df_model_data)} rows due to remaining NaNs in feature columns after imputation attempts.\")\n",
    "        \n",
    "        final_nan_summary = df_model_data[feature_columns].isnull().sum()\n",
    "        final_nan_summary = final_nan_summary[final_nan_summary > 0]\n",
    "        if not final_nan_summary.empty:\n",
    "            logger.error(f\"Still have NaNs after processing! Columns:\\n{final_nan_summary}\")\n",
    "        else:\n",
    "            logger.info(\"Successfully handled NaNs in feature columns.\")\n",
    "\n",
    "    else:\n",
    "        logger.info(\"No NaNs found in the selected feature columns.\")\n",
    "        \n",
    "    # --- 3. Define Features (X) and Target (y) ---\n",
    "    if not df_model_data.empty:\n",
    "        X = df_model_data[feature_columns].copy() # Ensure we use the cleaned feature_columns\n",
    "        y = df_model_data[target_col].copy()\n",
    "        logger.info(f\"Defined X (features) with shape: {X.shape}\")\n",
    "        logger.info(f\"Defined y (target) with shape: {y.shape}\")\n",
    "\n",
    "        # --- 4. Split Data (Chronological) ---\n",
    "        # We'll use roughly 80% for training, 20% for testing.\n",
    "        # The data is already sorted by 'decision_point_ts_utc'.\n",
    "        split_ratio = 0.8\n",
    "        split_index = int(len(X) * split_ratio)\n",
    "\n",
    "        X_train = X.iloc[:split_index]\n",
    "        y_train = y.iloc[:split_index]\n",
    "        X_test = X.iloc[split_index:]\n",
    "        y_test = y.iloc[split_index:]\n",
    "\n",
    "        logger.info(f\"Data split chronologically:\")\n",
    "        logger.info(f\"  X_train shape: {X_train.shape}, y_train shape: {y_train.shape}\")\n",
    "        logger.info(f\"  X_test shape: {X_test.shape}, y_test shape: {y_test.shape}\")\n",
    "        \n",
    "        # Log the time range for train and test sets\n",
    "        train_start_ts = df_model_data['decision_point_ts_utc'].iloc[0]\n",
    "        train_end_ts = df_model_data['decision_point_ts_utc'].iloc[split_index - 1]\n",
    "        test_start_ts = df_model_data['decision_point_ts_utc'].iloc[split_index]\n",
    "        test_end_ts = df_model_data['decision_point_ts_utc'].iloc[-1]\n",
    "\n",
    "        logger.info(f\"  Training data from: {dt.datetime.fromtimestamp(train_start_ts, tz=timezone.utc).isoformat()} to {dt.datetime.fromtimestamp(train_end_ts, tz=timezone.utc).isoformat()}\")\n",
    "        logger.info(f\"  Test data from:     {dt.datetime.fromtimestamp(test_start_ts, tz=timezone.utc).isoformat()} to {dt.datetime.fromtimestamp(test_end_ts, tz=timezone.utc).isoformat()}\")\n",
    "        \n",
    "        # --- 5. Feature Scaling ---\n",
    "        # Linear models often benefit from scaling.\n",
    "        scaler = StandardScaler()\n",
    "        X_train_scaled = scaler.fit_transform(X_train)\n",
    "        X_test_scaled = scaler.transform(X_test) # Use the scaler fitted on training data\n",
    "\n",
    "        # Convert scaled arrays back to DataFrames with original column names for easier inspection (optional)\n",
    "        X_train_scaled_df = pd.DataFrame(X_train_scaled, columns=X_train.columns, index=X_train.index)\n",
    "        X_test_scaled_df = pd.DataFrame(X_test_scaled, columns=X_test.columns, index=X_test.index)\n",
    "\n",
    "        logger.info(\"Features scaled using StandardScaler.\")\n",
    "        print(\"\\nSample of scaled training features (X_train_scaled_df head):\")\n",
    "        print(X_train_scaled_df.head())\n",
    "        \n",
    "        # Save the scaler\n",
    "        scaler_path = MODEL_OUTPUT_DIR / \"feature_scaler_v1.joblib\"\n",
    "        joblib.dump(scaler, scaler_path)\n",
    "        logger.info(f\"Scaler saved to: {scaler_path}\")\n",
    "        \n",
    "        # Also save the list of feature columns used for training (in order)\n",
    "        # This is CRITICAL for the backtester to use the same features.\n",
    "        feature_columns_list_path = MODEL_OUTPUT_DIR / \"feature_columns_v1.json\"\n",
    "        with open(feature_columns_list_path, 'w') as f:\n",
    "            json.dump(feature_columns.tolist() if isinstance(feature_columns, pd.Index) else feature_columns, f)\n",
    "        logger.info(f\"List of feature columns saved to: {feature_columns_list_path}\")\n",
    "\n",
    "    else:\n",
    "        logger.error(\"df_model_data is empty after NaN handling. Cannot proceed to define X, y, or split.\")\n",
    "        # Initialize X, y, etc. as empty or None to prevent errors in later cells if run out of order\n",
    "        X, y, X_train, y_train, X_test, y_test, X_train_scaled_df, X_test_scaled_df = [pd.DataFrame()]*8 \n",
    "        scaler = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-19 12:45:29,800 - INFO - model_training_20250519_122610.<module>:8 - --- Starting Model Training ---\n",
      "2025-05-19 12:45:29,801 - INFO - model_training_20250519_122610.<module>:12 - Training LinearRegression model on 669507 samples...\n",
      "2025-05-19 12:45:29,956 - INFO - model_training_20250519_122610.<module>:20 - LinearRegression model training complete.\n",
      "2025-05-19 12:45:29,956 - INFO - model_training_20250519_122610.<module>:23 - Making predictions on the test set (167377 samples)...\n",
      "2025-05-19 12:45:29,964 - INFO - model_training_20250519_122610.<module>:35 - \n",
      "--- Regression Model Evaluation Metrics (Test Set) ---\n",
      "2025-05-19 12:45:29,964 - INFO - model_training_20250519_122610.<module>:36 -   Mean Absolute Error (MAE):      628.1029\n",
      "2025-05-19 12:45:29,964 - INFO - model_training_20250519_122610.<module>:37 -   Mean Squared Error (MSE):       612007.2330\n",
      "2025-05-19 12:45:29,965 - INFO - model_training_20250519_122610.<module>:38 -   Root Mean Squared Error (RMSE): 782.3089\n",
      "2025-05-19 12:45:29,965 - INFO - model_training_20250519_122610.<module>:39 -   R-squared (R2 Score):           0.7392\n",
      "2025-05-19 12:45:29,968 - INFO - model_training_20250519_122610.<module>:60 -   Accuracy (Predicting Side of Strike): 0.9095 (on 167319 non-zero outcome samples)\n",
      "2025-05-19 12:45:29,970 - INFO - model_training_20250519_122610.<module>:75 - \n",
      "--- Model Coefficients ---\n",
      "2025-05-19 12:45:29,970 - INFO - model_training_20250519_122610.<module>:76 - Intercept: 79.4702\n",
      "2025-05-19 12:45:29,973 - INFO - model_training_20250519_122610.<module>:99 - Trained Linear Regression model saved to: /Users/omarabul-hassan/Desktop/projects/kalshi/notebooks/trained_models/linear_regression_btc_predictor_v1.joblib\n",
      "2025-05-19 12:45:29,973 - INFO - model_training_20250519_122610.<module>:112 - Model parameters (intercept, coefs, feature_order) saved to: /Users/omarabul-hassan/Desktop/projects/kalshi/notebooks/trained_models/lr_model_params_v1.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Sample of Test Set Predictions vs Actuals ---\n",
      "         actual_target  predicted_target  actual_sign  predicted_sign\n",
      "1105142        -608.82       -692.555904         -1.0            -1.0\n",
      "1105143       -2053.99       -708.475295         -1.0            -1.0\n",
      "1105144        -858.82       -827.559232         -1.0            -1.0\n",
      "1105145         -53.99        880.466277         -1.0             1.0\n",
      "1105146        1446.01       1423.703398          1.0             1.0\n",
      "1105147       -1858.82      -1058.190248         -1.0            -1.0\n",
      "1105148         891.18       1294.841098          1.0             1.0\n",
      "1105149        -608.82       -697.171473         -1.0            -1.0\n",
      "1105150       -2108.82      -1120.463571         -1.0            -1.0\n",
      "1105151         641.18       1237.183344          1.0             1.0\n",
      "\n",
      "Top Coefficients (by absolute value):\n",
      "                           feature  coefficient  abs_coefficient\n",
      "0              btc_price_t_minus_1  3084.456147      3084.456147\n",
      "9                      btc_ema_26m -2640.213532      2640.213532\n",
      "6                      btc_sma_10m -1256.751362      1256.751362\n",
      "7                      btc_sma_30m   554.006069       554.006069\n",
      "11              distance_to_strike   548.461282       548.461282\n",
      "12     time_until_market_close_min   449.773223       449.773223\n",
      "8                      btc_ema_12m   390.314754       390.314754\n",
      "17                  kalshi_yes_ask   254.780672       254.780672\n",
      "19                kalshi_mid_price   249.337702       249.337702\n",
      "16                  kalshi_yes_bid   231.695093       231.695093\n",
      "14                 day_of_week_utc   -80.989431        80.989431\n",
      "24               kalshi_mid_chg_5m   -66.068346        66.068346\n",
      "18                   kalshi_spread    35.816942        35.816942\n",
      "23               kalshi_mid_chg_3m   -21.662409        21.662409\n",
      "15                 hour_of_day_edt   -19.141077        19.141077\n",
      "10                         btc_rsi   -13.302474        13.302474\n",
      "22               kalshi_mid_chg_1m   -13.152042        13.152042\n",
      "2                      btc_mom_10m    -5.175636         5.175636\n",
      "21  kalshi_open_interest_t_minus_1    -4.217239         4.217239\n",
      "13                 hour_of_day_utc    -3.634346         3.634346\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Model Training and Evaluation\n",
    "\n",
    "if 'X_train_scaled_df' not in globals() or X_train_scaled_df.empty:\n",
    "    logger.error(\"Scaled training data (X_train_scaled_df) not found or is empty. Please ensure Cell 2 ran successfully.\")\n",
    "    # Optionally, raise an error or stop notebook execution\n",
    "    # For now, this cell will likely fail if data is missing.\n",
    "else:\n",
    "    logger.info(\"--- Starting Model Training ---\")\n",
    "\n",
    "    # --- 1. Initialize and Train Linear Regression Model ---\n",
    "    linear_model = LinearRegression()\n",
    "    logger.info(f\"Training LinearRegression model on {X_train_scaled_df.shape[0]} samples...\")\n",
    "    \n",
    "    # Ensure y_train is available\n",
    "    if 'y_train' not in globals() or y_train.empty:\n",
    "        logger.error(\"y_train is not available. Cannot train model.\")\n",
    "    else:\n",
    "        try:\n",
    "            linear_model.fit(X_train_scaled_df, y_train)\n",
    "            logger.info(\"LinearRegression model training complete.\")\n",
    "\n",
    "            # --- 2. Make Predictions on the Test Set ---\n",
    "            logger.info(f\"Making predictions on the test set ({X_test_scaled_df.shape[0]} samples)...\")\n",
    "            y_pred_test = linear_model.predict(X_test_scaled_df)\n",
    "\n",
    "            # --- 3. Evaluate Model Performance (Regression Metrics) ---\n",
    "            if 'y_test' not in globals() or y_test.empty:\n",
    "                logger.error(\"y_test is not available. Cannot evaluate model.\")\n",
    "            else:\n",
    "                mae = mean_absolute_error(y_test, y_pred_test)\n",
    "                mse = mean_squared_error(y_test, y_pred_test)\n",
    "                rmse = np.sqrt(mse)\n",
    "                r2 = r2_score(y_test, y_pred_test)\n",
    "\n",
    "                logger.info(\"\\n--- Regression Model Evaluation Metrics (Test Set) ---\")\n",
    "                logger.info(f\"  Mean Absolute Error (MAE):      {mae:.4f}\")\n",
    "                logger.info(f\"  Mean Squared Error (MSE):       {mse:.4f}\")\n",
    "                logger.info(f\"  Root Mean Squared Error (RMSE): {rmse:.4f}\")\n",
    "                logger.info(f\"  R-squared (R2 Score):           {r2:.4f}\")\n",
    "\n",
    "                # --- 4. Custom Evaluation (Trading-Oriented) ---\n",
    "                # The target is BTC_price_at_resolution - kalshi_strike_price\n",
    "                # Prediction > 0 implies model thinks BTC will be above strike (favors Kalshi YES)\n",
    "                # Prediction < 0 implies model thinks BTC will be below strike (favors Kalshi NO)\n",
    "\n",
    "                # Actual outcome sign:\n",
    "                actual_outcome_sign = np.sign(y_test) # 1 if >0 (YES), -1 if <0 (NO), 0 if exactly on strike\n",
    "\n",
    "                # Predicted outcome sign:\n",
    "                predicted_outcome_sign = np.sign(y_pred_test)\n",
    "\n",
    "                # Accuracy of predicting the correct side of the strike\n",
    "                correct_side_predictions = np.sum(actual_outcome_sign == predicted_outcome_sign)\n",
    "                # Exclude cases where actual_outcome_sign is 0 (BTC landed exactly on strike) for a clearer accuracy\n",
    "                valid_outcomes_for_sign_accuracy = actual_outcome_sign[actual_outcome_sign != 0]\n",
    "                valid_predictions_for_sign_accuracy = predicted_outcome_sign[actual_outcome_sign != 0]\n",
    "                \n",
    "                if len(valid_outcomes_for_sign_accuracy) > 0:\n",
    "                    sign_accuracy = np.sum(valid_outcomes_for_sign_accuracy == valid_predictions_for_sign_accuracy) / len(valid_outcomes_for_sign_accuracy)\n",
    "                    logger.info(f\"  Accuracy (Predicting Side of Strike): {sign_accuracy:.4f} (on {len(valid_outcomes_for_sign_accuracy)} non-zero outcome samples)\")\n",
    "                else:\n",
    "                    logger.info(\"  Accuracy (Predicting Side of Strike): N/A (no non-zero actual outcomes)\")\n",
    "\n",
    "                # Create a DataFrame for easier analysis of predictions vs actuals\n",
    "                df_results = pd.DataFrame({\n",
    "                    'actual_target': y_test,\n",
    "                    'predicted_target': y_pred_test,\n",
    "                    'actual_sign': actual_outcome_sign,\n",
    "                    'predicted_sign': predicted_outcome_sign\n",
    "                })\n",
    "                print(\"\\n--- Sample of Test Set Predictions vs Actuals ---\")\n",
    "                print(df_results.head(10).to_string())\n",
    "\n",
    "                # --- 5. Inspect Model Coefficients ---\n",
    "                logger.info(\"\\n--- Model Coefficients ---\")\n",
    "                logger.info(f\"Intercept: {linear_model.intercept_:.4f}\")\n",
    "                \n",
    "                # Ensure feature_columns is available (should be from Cell 2, or loaded from JSON)\n",
    "                if 'feature_columns' not in globals():\n",
    "                    feature_columns_list_path = MODEL_OUTPUT_DIR / \"feature_columns_v1.json\"\n",
    "                    if feature_columns_list_path.exists():\n",
    "                        with open(feature_columns_list_path, 'r') as f:\n",
    "                            feature_columns = json.load(f)\n",
    "                        logger.info(f\"Loaded feature_columns list from {feature_columns_list_path}\")\n",
    "                    else:\n",
    "                        logger.warning(\"feature_columns list not found. Cannot display coefficient names.\")\n",
    "                        feature_columns = [f\"feature_{i}\" for i in range(len(linear_model.coef_))]\n",
    "\n",
    "                coefficients = pd.DataFrame({'feature': feature_columns, 'coefficient': linear_model.coef_})\n",
    "                coefficients['abs_coefficient'] = np.abs(coefficients['coefficient'])\n",
    "                coefficients.sort_values(by='abs_coefficient', ascending=False, inplace=True)\n",
    "                \n",
    "                print(\"\\nTop Coefficients (by absolute value):\")\n",
    "                print(coefficients.head(20).to_string()) # Print top N coefficients\n",
    "\n",
    "                # --- 6. Save the Trained Model ---\n",
    "                model_path = MODEL_OUTPUT_DIR / \"linear_regression_btc_predictor_v1.joblib\"\n",
    "                joblib.dump(linear_model, model_path)\n",
    "                logger.info(f\"Trained Linear Regression model saved to: {model_path}\")\n",
    "\n",
    "                # Save model parameters (intercept, coefficients) to a JSON file for backtest.py\n",
    "                # This is an alternative to loading the whole joblib model in backtest.py\n",
    "                # and can be simpler if linreg_strategy.py only needs these.\n",
    "                model_params_for_backtest = {\n",
    "                    'intercept': linear_model.intercept_,\n",
    "                    'coefficients': dict(zip(feature_columns, linear_model.coef_)),\n",
    "                    'feature_order': feature_columns # Store the order for consistent dot product\n",
    "                }\n",
    "                params_path = MODEL_OUTPUT_DIR / \"lr_model_params_v1.json\"\n",
    "                with open(params_path, 'w') as f:\n",
    "                    json.dump(model_params_for_backtest, f, indent=4)\n",
    "                logger.info(f\"Model parameters (intercept, coefs, feature_order) saved to: {params_path}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.critical(f\"An error occurred during model training or evaluation: {e}\")\n",
    "            if 'linear_model' in locals():\n",
    "                 logger.info(\"Model training might have partially completed or failed during evaluation.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
