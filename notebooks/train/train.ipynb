{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-22 01:35:44,339 - INFO - model_training_classifier_20250522_013544.<module>:35 - Cell 1: current_notebook_dir resolved to: /Users/omarabul-hassan/Desktop/projects/kalshi/notebooks/train\n",
      "2025-05-22 01:35:44,339 - INFO - model_training_classifier_20250522_013544.<module>:39 - Cell 1: Attempting to find feature files in: /Users/omarabul-hassan/Desktop/projects/kalshi/notebooks/features\n",
      "2025-05-22 01:35:44,341 - INFO - model_training_classifier_20250522_013544.<module>:68 - Using features CSV: /Users/omarabul-hassan/Desktop/projects/kalshi/notebooks/features/kalshi_btc_features_target_v2_filtered_15m_20250521_163917.csv\n",
      "2025-05-22 01:35:44,341 - INFO - model_training_classifier_20250522_013544.<module>:79 - Cell 1: Intended MODEL_OUTPUT_DIR: /Users/omarabul-hassan/Desktop/projects/kalshi/notebooks/trained_models/rf\n",
      "2025-05-22 01:35:44,348 - INFO - model_training_classifier_20250522_013544.<module>:85 - Successfully ensured MODEL_OUTPUT_DIR exists and is a directory: /Users/omarabul-hassan/Desktop/projects/kalshi/notebooks/trained_models/rf\n",
      "2025-05-22 01:35:47,095 - INFO - model_training_classifier_20250522_013544.<module>:110 - Successfully loaded features data from: /Users/omarabul-hassan/Desktop/projects/kalshi/notebooks/features/kalshi_btc_features_target_v2_filtered_15m_20250521_163917.csv\n",
      "2025-05-22 01:35:47,096 - INFO - model_training_classifier_20250522_013544.<module>:111 - Shape of loaded data: (1157220, 44)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Data Head (Raw from CSV) ---\n",
      "          kalshi_market_ticker  decision_point_ts_utc  kalshi_strike_price  \\\n",
      "0  KXBTCD-25MAY1522-T106249.99             1747357200            106249.99   \n",
      "1  KXBTCD-25MAY1522-T106249.99             1747357260            106249.99   \n",
      "2  KXBTCD-25MAY1522-T106249.99             1747357320            106249.99   \n",
      "3  KXBTCD-25MAY1522-T106249.99             1747357380            106249.99   \n",
      "4  KXBTCD-25MAY1522-T106249.99             1747357440            106249.99   \n",
      "\n",
      "   btc_price_t_minus_1  btc_mom_5m  btc_mom_10m  btc_mom_15m  btc_mom_30m  \\\n",
      "0            103764.81       73.29       -69.79      -182.17        22.80   \n",
      "1            103709.10       17.67      -111.60      -246.90       -68.90   \n",
      "2            103785.66       83.21         7.89      -114.10      -109.26   \n",
      "3            103691.25      -34.40         5.91      -227.89      -285.74   \n",
      "4            103629.36     -110.19       -98.42      -303.61      -299.95   \n",
      "\n",
      "   btc_mom_60m  btc_vol_15m  btc_sma_10m  btc_price_vs_sma_10m    btc_sma_30m  \\\n",
      "0          NaN    95.991753   103732.700              1.000310  103868.674000   \n",
      "1       -14.12    86.424046   103721.540              0.999880  103866.377333   \n",
      "2        46.38    79.377628   103722.329              1.000611  103862.735333   \n",
      "3       -55.62    69.408713   103722.920              0.999695  103853.210667   \n",
      "4      -179.18    55.815136   103713.078              0.999193  103843.212333   \n",
      "\n",
      "   btc_price_vs_sma_30m  btc_sma_50m  btc_price_vs_sma_50m    btc_ema_12m  \\\n",
      "0              0.999000  103864.9356              0.999036  103766.593435   \n",
      "1              0.998486  103863.8500              0.998510  103757.748291   \n",
      "2              0.999258  103862.5242              0.999260  103762.042400   \n",
      "3              0.998440  103859.5240              0.998380  103751.151262   \n",
      "4              0.997941  103855.2860              0.997825  103732.414145   \n",
      "\n",
      "   btc_price_vs_ema_12m    btc_ema_26m  btc_price_vs_ema_26m    btc_ema_50m  \\\n",
      "0              0.999983  103814.379274              0.999523  103829.315485   \n",
      "1              0.999531  103806.580809              0.999061  103824.601153   \n",
      "2              1.000228  103805.031120              0.999813  103823.074049   \n",
      "3              0.999423  103796.602888              0.998985  103817.904478   \n",
      "4              0.999007  103784.214526              0.998508  103810.510577   \n",
      "\n",
      "   btc_price_vs_ema_50m    btc_rsi  btc_atr_14  distance_to_strike  \\\n",
      "0              0.999379  30.460910   45.968934            -2485.18   \n",
      "1              0.998888  30.493943   46.665439            -2540.89   \n",
      "2              0.999640  37.774318   50.382907            -2464.33   \n",
      "3              0.998780  30.708083   53.527700            -2558.74   \n",
      "4              0.998255  32.606780   55.325721            -2620.63   \n",
      "\n",
      "   distance_to_strike_norm_atr  time_until_market_close_min  hour_of_day_utc  \\\n",
      "0                   -54.062163                         60.0                1   \n",
      "1                   -54.449076                         59.0                1   \n",
      "2                   -48.912024                         58.0                1   \n",
      "3                   -47.802166                         57.0                1   \n",
      "4                   -47.367299                         56.0                1   \n",
      "\n",
      "   day_of_week_utc  hour_of_day_edt  TARGET_btc_diff_from_strike  \\\n",
      "0                4               21                     -2011.89   \n",
      "1                4               21                     -2011.89   \n",
      "2                4               21                     -2011.89   \n",
      "3                4               21                     -2011.89   \n",
      "4                4               21                     -2011.89   \n",
      "\n",
      "   kalshi_yes_bid  kalshi_yes_ask  kalshi_spread  kalshi_mid_price  \\\n",
      "0             NaN             NaN            NaN               NaN   \n",
      "1             NaN             NaN            NaN               NaN   \n",
      "2             0.0            30.0           30.0              15.0   \n",
      "3             0.0            30.0           30.0              15.0   \n",
      "4             0.0            30.0           30.0              15.0   \n",
      "\n",
      "   kalshi_volume_t_minus_1  kalshi_open_interest_t_minus_1  kalshi_mid_vol_5m  \\\n",
      "0                      NaN                             NaN                NaN   \n",
      "1                      NaN                             NaN                NaN   \n",
      "2                      0.0                             0.0                NaN   \n",
      "3                      0.0                             0.0                NaN   \n",
      "4                      0.0                             0.0                NaN   \n",
      "\n",
      "   kalshi_mid_vol_10m  kalshi_vs_btc_implied_spread  kalshi_mid_chg_1m  \\\n",
      "0                 NaN                           NaN                NaN   \n",
      "1                 NaN                           NaN                NaN   \n",
      "2                 NaN                          10.0                NaN   \n",
      "3                 NaN                          10.0                0.0   \n",
      "4                 NaN                          10.0                0.0   \n",
      "\n",
      "   kalshi_mid_chg_3m  kalshi_mid_chg_5m  kalshi_mid_chg_10m  \n",
      "0                NaN                NaN                 NaN  \n",
      "1                NaN                NaN                 NaN  \n",
      "2                NaN                NaN                 NaN  \n",
      "3                NaN                NaN                 NaN  \n",
      "4                NaN                NaN                 NaN  \n",
      "\n",
      "--- Data Info (Raw from CSV) ---\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1157220 entries, 0 to 1157219\n",
      "Data columns (total 44 columns):\n",
      " #   Column                          Non-Null Count    Dtype  \n",
      "---  ------                          --------------    -----  \n",
      " 0   kalshi_market_ticker            1157220 non-null  object \n",
      " 1   decision_point_ts_utc           1157220 non-null  int64  \n",
      " 2   kalshi_strike_price             1157220 non-null  float64\n",
      " 3   btc_price_t_minus_1             1157220 non-null  float64\n",
      " 4   btc_mom_5m                      1151595 non-null  float64\n",
      " 5   btc_mom_10m                     1145970 non-null  float64\n",
      " 6   btc_mom_15m                     1140345 non-null  float64\n",
      " 7   btc_mom_30m                     1123470 non-null  float64\n",
      " 8   btc_mom_60m                     1098840 non-null  float64\n",
      " 9   btc_vol_15m                     1156095 non-null  float64\n",
      " 10  btc_sma_10m                     1157220 non-null  float64\n",
      " 11  btc_price_vs_sma_10m            1157220 non-null  float64\n",
      " 12  btc_sma_30m                     1157220 non-null  float64\n",
      " 13  btc_price_vs_sma_30m            1157220 non-null  float64\n",
      " 14  btc_sma_50m                     1157220 non-null  float64\n",
      " 15  btc_price_vs_sma_50m            1157220 non-null  float64\n",
      " 16  btc_ema_12m                     1157220 non-null  float64\n",
      " 17  btc_price_vs_ema_12m            1157220 non-null  float64\n",
      " 18  btc_ema_26m                     1157220 non-null  float64\n",
      " 19  btc_price_vs_ema_26m            1157220 non-null  float64\n",
      " 20  btc_ema_50m                     1157220 non-null  float64\n",
      " 21  btc_price_vs_ema_50m            1157220 non-null  float64\n",
      " 22  btc_rsi                         1157220 non-null  float64\n",
      " 23  btc_atr_14                      1157220 non-null  float64\n",
      " 24  distance_to_strike              1157220 non-null  float64\n",
      " 25  distance_to_strike_norm_atr     1157220 non-null  float64\n",
      " 26  time_until_market_close_min     1157220 non-null  float64\n",
      " 27  hour_of_day_utc                 1157220 non-null  int64  \n",
      " 28  day_of_week_utc                 1157220 non-null  int64  \n",
      " 29  hour_of_day_edt                 1157220 non-null  int64  \n",
      " 30  TARGET_btc_diff_from_strike     1157220 non-null  float64\n",
      " 31  kalshi_yes_bid                  727823 non-null   float64\n",
      " 32  kalshi_yes_ask                  727823 non-null   float64\n",
      " 33  kalshi_spread                   727823 non-null   float64\n",
      " 34  kalshi_mid_price                727823 non-null   float64\n",
      " 35  kalshi_volume_t_minus_1         727823 non-null   float64\n",
      " 36  kalshi_open_interest_t_minus_1  727823 non-null   float64\n",
      " 37  kalshi_mid_vol_5m               680073 non-null   float64\n",
      " 38  kalshi_mid_vol_10m              632895 non-null   float64\n",
      " 39  kalshi_vs_btc_implied_spread    727823 non-null   float64\n",
      " 40  kalshi_mid_chg_1m               718651 non-null   float64\n",
      " 41  kalshi_mid_chg_3m               700307 non-null   float64\n",
      " 42  kalshi_mid_chg_5m               685024 non-null   float64\n",
      " 43  kalshi_mid_chg_10m              647022 non-null   float64\n",
      "dtypes: float64(39), int64(4), object(1)\n",
      "memory usage: 388.5+ MB\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Imports and Load Data for Classification\n",
    "# (This cell remains largely the same as your provided version, ensuring FEATURES_DIR and MODEL_OUTPUT_DIR are correct)\n",
    "# Make sure to re-run this cell if you restart your notebook.\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from pathlib import Path\n",
    "import datetime as dt\n",
    "from datetime import timezone, timedelta\n",
    "import logging\n",
    "import json # For saving feature_columns_list and imputation_values\n",
    "import joblib # For saving the model and scaler\n",
    "\n",
    "from sklearn.model_selection import train_test_split # We'll do a chronological split manually\n",
    "# RandomForest will be imported in Cell 3\n",
    "from sklearn.preprocessing import StandardScaler # For feature scaling\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, log_loss, confusion_matrix\n",
    "\n",
    "# --- Logging Setup ---\n",
    "logger_name = f\"model_training_classifier_{dt.datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
    "logger = logging.getLogger(logger_name)\n",
    "if not logger.handlers:\n",
    "    logger.setLevel(logging.INFO)\n",
    "    formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(name)s.%(funcName)s:%(lineno)d - %(message)s')\n",
    "    ch = logging.StreamHandler()\n",
    "    ch.setFormatter(formatter)\n",
    "    logger.addHandler(ch)\n",
    "else:\n",
    "    logger.setLevel(logging.INFO)\n",
    "\n",
    "# --- Configuration ---\n",
    "# Assuming train.ipynb is in /Users/omarabul-hassan/Desktop/projects/kalshi/notebooks/train/\n",
    "current_notebook_dir = Path.cwd()\n",
    "logger.info(f\"Cell 1: current_notebook_dir resolved to: {current_notebook_dir.resolve()}\")\n",
    "\n",
    "# FEATURES_DIR should point to .../kalshi/notebooks/features\n",
    "FEATURES_DIR = current_notebook_dir.parent / \"features\"\n",
    "logger.info(f\"Cell 1: Attempting to find feature files in: {FEATURES_DIR.resolve()}\")\n",
    "\n",
    "try:\n",
    "    if not FEATURES_DIR.exists():\n",
    "        # This fallback assumes your project structure might be /kalshi/features directly\n",
    "        # And train.ipynb is in /kalshi/notebooks/train\n",
    "        alt_features_dir = current_notebook_dir.parent.parent / \"features\"\n",
    "        logger.warning(f\"Primary FEATURES_DIR {FEATURES_DIR.resolve()} not found. Trying alternative: {alt_features_dir.resolve()}\")\n",
    "        if alt_features_dir.exists():\n",
    "            FEATURES_DIR = alt_features_dir\n",
    "            logger.info(f\"Using alternative FEATURES_DIR: {FEATURES_DIR.resolve()}\")\n",
    "        else:\n",
    "            logger.error(f\"Neither primary nor alternative FEATURES_DIR exists. Original: {FEATURES_DIR.resolve()}, Alt: {alt_features_dir.resolve()}\")\n",
    "            # Let the glob below fail more explicitly if FEATURES_DIR is truly wrong.\n",
    "            pass\n",
    "\n",
    "    feature_glob_pattern = \"kalshi_btc_features_target_v2_filtered_15m_*.csv\"\n",
    "    feature_files = sorted(FEATURES_DIR.glob(feature_glob_pattern), key=os.path.getctime, reverse=True)\n",
    "\n",
    "    if not feature_files:\n",
    "        logger.warning(f\"No '{feature_glob_pattern}' files found in {FEATURES_DIR.resolve()}. \"\n",
    "                       f\"Falling back to 'kalshi_btc_features_target_v1_filtered_*.csv' (older version)...\")\n",
    "        feature_glob_pattern_v1_filt = \"kalshi_btc_features_target_v1_filtered_*.csv\"\n",
    "        feature_files = sorted(FEATURES_DIR.glob(feature_glob_pattern_v1_filt), key=os.path.getctime, reverse=True)\n",
    "        if not feature_files:\n",
    "            raise FileNotFoundError(f\"No feature CSV files found in {FEATURES_DIR.resolve()} matching EITHER \"\n",
    "                                    f\"'{feature_glob_pattern}' OR '{feature_glob_pattern_v1_filt}'\")\n",
    "\n",
    "    FEATURES_CSV_PATH = feature_files[0]\n",
    "    logger.info(f\"Using features CSV: {FEATURES_CSV_PATH.resolve()}\")\n",
    "\n",
    "except FileNotFoundError as e:\n",
    "    logger.critical(str(e))\n",
    "    FEATURES_CSV_PATH = None\n",
    "except Exception as e:\n",
    "    logger.critical(f\"Error finding features CSV: {e}\", exc_info=True)\n",
    "    FEATURES_CSV_PATH = None\n",
    "\n",
    "# MODEL_OUTPUT_DIR should point to .../kalshi/notebooks/trained_models/rf\n",
    "MODEL_OUTPUT_DIR = current_notebook_dir.parent / \"trained_models\" / \"rf\"\n",
    "logger.info(f\"Cell 1: Intended MODEL_OUTPUT_DIR: {MODEL_OUTPUT_DIR.resolve()}\")\n",
    "\n",
    "# --- More Robust Directory Creation and Check ---\n",
    "try:\n",
    "    MODEL_OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "    if MODEL_OUTPUT_DIR.exists() and MODEL_OUTPUT_DIR.is_dir():\n",
    "        logger.info(f\"Successfully ensured MODEL_OUTPUT_DIR exists and is a directory: {MODEL_OUTPUT_DIR.resolve()}\")\n",
    "        # Test writability (optional, but can help diagnose permission issues early)\n",
    "        # test_file_path = MODEL_OUTPUT_DIR / f\"test_write_{dt.datetime.now().strftime('%Y%m%d%H%M%S')}.txt\"\n",
    "        # try:\n",
    "        #     with open(test_file_path, 'w') as f_test:\n",
    "        #         f_test.write(\"test\")\n",
    "        #     os.remove(test_file_path)\n",
    "        #     logger.info(f\"Write test to MODEL_OUTPUT_DIR successful.\")\n",
    "        # except Exception as e_write:\n",
    "        #     logger.error(f\"CRITICAL: Failed write test to MODEL_OUTPUT_DIR {MODEL_OUTPUT_DIR.resolve()}. Error: {e_write}. CHECK PERMISSIONS.\")\n",
    "        #     # Potentially raise an error here or set a flag to prevent further execution\n",
    "    else:\n",
    "        logger.error(f\"CRITICAL: Failed to create or verify MODEL_OUTPUT_DIR: {MODEL_OUTPUT_DIR.resolve()}. It might not be a directory or creation failed.\")\n",
    "        # This should ideally not happen if mkdir was successful without error.\n",
    "except Exception as e_mkdir:\n",
    "    logger.error(f\"CRITICAL: Exception during MODEL_OUTPUT_DIR creation for {MODEL_OUTPUT_DIR.resolve()}: {e_mkdir}. CHECK PATH AND PERMISSIONS.\")\n",
    "    # If directory creation fails, subsequent saves will fail.\n",
    "    # You might want to raise the exception here to stop the notebook.\n",
    "    # raise # Uncomment to stop execution if directory cannot be made\n",
    "\n",
    "# --- Load the Features DataFrame ---\n",
    "df_model_data = pd.DataFrame()\n",
    "if FEATURES_CSV_PATH and FEATURES_CSV_PATH.exists():\n",
    "    try:\n",
    "        df_model_data = pd.read_csv(FEATURES_CSV_PATH)\n",
    "        logger.info(f\"Successfully loaded features data from: {FEATURES_CSV_PATH.resolve()}\")\n",
    "        logger.info(f\"Shape of loaded data: {df_model_data.shape}\")\n",
    "        print(\"--- Data Head (Raw from CSV) ---\")\n",
    "        with pd.option_context('display.max_columns', None): print(df_model_data.head())\n",
    "        print(\"\\n--- Data Info (Raw from CSV) ---\")\n",
    "        df_model_data.info(verbose=True, show_counts=True)\n",
    "    except Exception as e:\n",
    "        logger.critical(f\"Error loading features CSV {FEATURES_CSV_PATH.resolve()}: {e}\")\n",
    "else:\n",
    "    if FEATURES_CSV_PATH: logger.critical(f\"Features CSV file not found: {FEATURES_CSV_PATH.resolve()}\")\n",
    "    else: logger.critical(\"FEATURES_CSV_PATH was not set. Cannot load data.\")\n",
    "\n",
    "if df_model_data.empty: logger.warning(\"DataFrame df_model_data is empty. Subsequent cells might fail.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-22 01:35:47,175 - INFO - model_training_classifier_20250522_013544.<module>:11 - Starting preprocessing for df_model_data with shape: (1157220, 44)\n",
      "2025-05-22 01:35:47,264 - INFO - model_training_classifier_20250522_013544.<module>:16 - Data sorted by 'decision_point_ts_utc'.\n",
      "2025-05-22 01:35:47,267 - INFO - model_training_classifier_20250522_013544.<module>:24 - Created binary classification target 'TARGET_market_resolves_yes'.\n",
      "2025-05-22 01:35:47,270 - INFO - model_training_classifier_20250522_013544.<module>:25 - Value counts for 'TARGET_market_resolves_yes':\n",
      "TARGET_market_resolves_yes\n",
      "1    0.519676\n",
      "0    0.480324\n",
      "Name: proportion, dtype: float64\n",
      "2025-05-22 01:35:47,270 - INFO - model_training_classifier_20250522_013544.<module>:33 - Identified 40 feature columns.\n",
      "2025-05-22 01:35:47,337 - INFO - model_training_classifier_20250522_013544.<module>:40 - NaN values in feature columns of df_model_data BEFORE ANY imputation/split:\n",
      "kalshi_mid_vol_10m                524325\n",
      "kalshi_mid_chg_10m                510198\n",
      "kalshi_mid_vol_5m                 477147\n",
      "kalshi_mid_chg_5m                 472196\n",
      "kalshi_mid_chg_3m                 456913\n",
      "kalshi_mid_chg_1m                 438569\n",
      "kalshi_volume_t_minus_1           429397\n",
      "kalshi_vs_btc_implied_spread      429397\n",
      "kalshi_open_interest_t_minus_1    429397\n",
      "kalshi_mid_price                  429397\n",
      "kalshi_spread                     429397\n",
      "kalshi_yes_ask                    429397\n",
      "kalshi_yes_bid                    429397\n",
      "btc_mom_60m                        58380\n",
      "btc_mom_30m                        33750\n",
      "btc_mom_15m                        16875\n",
      "btc_mom_10m                        11250\n",
      "btc_mom_5m                          5625\n",
      "btc_vol_15m                         1125\n",
      "dtype: int64\n",
      "2025-05-22 01:35:47,378 - INFO - model_training_classifier_20250522_013544.<module>:48 - Dropped 0 rows due to NaN in target 'TARGET_market_resolves_yes'.\n",
      "2025-05-22 01:35:47,378 - INFO - model_training_classifier_20250522_013544.<module>:49 - Shape of df_model_data after dropping NaNs in target: (1157220, 45)\n",
      "2025-05-22 01:35:47,501 - INFO - model_training_classifier_20250522_013544.<module>:72 - Data split chronologically:\n",
      "2025-05-22 01:35:47,502 - INFO - model_training_classifier_20250522_013544.<module>:73 -   X_train shape: (925776, 40), y_train shape: (925776,)\n",
      "2025-05-22 01:35:47,502 - INFO - model_training_classifier_20250522_013544.<module>:74 -   X_test shape: (231444, 40), y_test shape: (231444,)\n",
      "2025-05-22 01:35:47,529 - INFO - model_training_classifier_20250522_013544.<module>:77 - NaNs in X_train before imputation:\n",
      "btc_mom_5m                          4425\n",
      "btc_mom_10m                         8850\n",
      "btc_mom_15m                        13275\n",
      "btc_mom_30m                        26550\n",
      "btc_mom_60m                        46502\n",
      "btc_vol_15m                          885\n",
      "kalshi_yes_bid                    385019\n",
      "kalshi_yes_ask                    385019\n",
      "kalshi_spread                     385019\n",
      "kalshi_mid_price                  385019\n",
      "kalshi_volume_t_minus_1           385019\n",
      "kalshi_open_interest_t_minus_1    385019\n",
      "kalshi_mid_vol_5m                 419813\n",
      "kalshi_mid_vol_10m                452817\n",
      "kalshi_vs_btc_implied_spread      385019\n",
      "kalshi_mid_chg_1m                 391681\n",
      "kalshi_mid_chg_3m                 405005\n",
      "kalshi_mid_chg_5m                 415496\n",
      "kalshi_mid_chg_10m                441419\n",
      "dtype: int64\n",
      "2025-05-22 01:35:47,535 - INFO - model_training_classifier_20250522_013544.<module>:78 - NaNs in X_test before imputation:\n",
      "btc_mom_5m                         1200\n",
      "btc_mom_10m                        2400\n",
      "btc_mom_15m                        3600\n",
      "btc_mom_30m                        7200\n",
      "btc_mom_60m                       11878\n",
      "btc_vol_15m                         240\n",
      "kalshi_yes_bid                    44378\n",
      "kalshi_yes_ask                    44378\n",
      "kalshi_spread                     44378\n",
      "kalshi_mid_price                  44378\n",
      "kalshi_volume_t_minus_1           44378\n",
      "kalshi_open_interest_t_minus_1    44378\n",
      "kalshi_mid_vol_5m                 57334\n",
      "kalshi_mid_vol_10m                71508\n",
      "kalshi_vs_btc_implied_spread      44378\n",
      "kalshi_mid_chg_1m                 46888\n",
      "kalshi_mid_chg_3m                 51908\n",
      "kalshi_mid_chg_5m                 56700\n",
      "kalshi_mid_chg_10m                68779\n",
      "dtype: int64\n",
      "2025-05-22 01:35:47,535 - INFO - model_training_classifier_20250522_013544.<module>:83 - Calculating imputation values from X_train and applying to X_train & X_test...\n",
      "/var/folders/43/br9zl9l149d3rb94gdkr1wsm0000gn/T/ipykernel_2659/2181565403.py:88: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col_name].fillna(value_to_fill, inplace=True)\n",
      "/var/folders/43/br9zl9l149d3rb94gdkr1wsm0000gn/T/ipykernel_2659/2181565403.py:88: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col_name].fillna(value_to_fill, inplace=True)\n",
      "/var/folders/43/br9zl9l149d3rb94gdkr1wsm0000gn/T/ipykernel_2659/2181565403.py:88: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col_name].fillna(value_to_fill, inplace=True)\n",
      "/var/folders/43/br9zl9l149d3rb94gdkr1wsm0000gn/T/ipykernel_2659/2181565403.py:88: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col_name].fillna(value_to_fill, inplace=True)\n",
      "/var/folders/43/br9zl9l149d3rb94gdkr1wsm0000gn/T/ipykernel_2659/2181565403.py:88: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col_name].fillna(value_to_fill, inplace=True)\n",
      "/var/folders/43/br9zl9l149d3rb94gdkr1wsm0000gn/T/ipykernel_2659/2181565403.py:88: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col_name].fillna(value_to_fill, inplace=True)\n",
      "/var/folders/43/br9zl9l149d3rb94gdkr1wsm0000gn/T/ipykernel_2659/2181565403.py:88: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col_name].fillna(value_to_fill, inplace=True)\n",
      "/var/folders/43/br9zl9l149d3rb94gdkr1wsm0000gn/T/ipykernel_2659/2181565403.py:88: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col_name].fillna(value_to_fill, inplace=True)\n",
      "/var/folders/43/br9zl9l149d3rb94gdkr1wsm0000gn/T/ipykernel_2659/2181565403.py:88: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col_name].fillna(value_to_fill, inplace=True)\n",
      "/var/folders/43/br9zl9l149d3rb94gdkr1wsm0000gn/T/ipykernel_2659/2181565403.py:88: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col_name].fillna(value_to_fill, inplace=True)\n",
      "/var/folders/43/br9zl9l149d3rb94gdkr1wsm0000gn/T/ipykernel_2659/2181565403.py:88: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col_name].fillna(value_to_fill, inplace=True)\n",
      "/var/folders/43/br9zl9l149d3rb94gdkr1wsm0000gn/T/ipykernel_2659/2181565403.py:88: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col_name].fillna(value_to_fill, inplace=True)\n",
      "/var/folders/43/br9zl9l149d3rb94gdkr1wsm0000gn/T/ipykernel_2659/2181565403.py:88: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col_name].fillna(value_to_fill, inplace=True)\n",
      "/var/folders/43/br9zl9l149d3rb94gdkr1wsm0000gn/T/ipykernel_2659/2181565403.py:88: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col_name].fillna(value_to_fill, inplace=True)\n",
      "/var/folders/43/br9zl9l149d3rb94gdkr1wsm0000gn/T/ipykernel_2659/2181565403.py:88: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col_name].fillna(value_to_fill, inplace=True)\n",
      "/var/folders/43/br9zl9l149d3rb94gdkr1wsm0000gn/T/ipykernel_2659/2181565403.py:88: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col_name].fillna(value_to_fill, inplace=True)\n",
      "/var/folders/43/br9zl9l149d3rb94gdkr1wsm0000gn/T/ipykernel_2659/2181565403.py:88: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col_name].fillna(value_to_fill, inplace=True)\n",
      "2025-05-22 01:35:47,659 - INFO - model_training_classifier_20250522_013544.<module>:161 - Imputation values map created with 40 entries.\n",
      "2025-05-22 01:35:47,668 - INFO - model_training_classifier_20250522_013544.<module>:181 - Shapes after all imputation and final NaN drop:\n",
      "2025-05-22 01:35:47,669 - INFO - model_training_classifier_20250522_013544.<module>:182 -   X_train: (925776, 40), y_train: (925776,)\n",
      "2025-05-22 01:35:47,669 - INFO - model_training_classifier_20250522_013544.<module>:183 -   X_test: (231444, 40), y_test: (231444,)\n",
      "2025-05-22 01:35:47,879 - INFO - model_training_classifier_20250522_013544.<module>:197 - Features scaled using StandardScaler.\n",
      "2025-05-22 01:35:47,880 - INFO - model_training_classifier_20250522_013544.<module>:202 - Scaler for V2 features saved to: /Users/omarabul-hassan/Desktop/projects/kalshi/notebooks/trained_models/rf/feature_scaler_classifier_v2.joblib\n",
      "2025-05-22 01:35:47,881 - INFO - model_training_classifier_20250522_013544.<module>:207 - List of V2 feature columns (40 features) saved to: /Users/omarabul-hassan/Desktop/projects/kalshi/notebooks/trained_models/rf/feature_columns_classifier_v2.json\n",
      "2025-05-22 01:35:47,881 - INFO - model_training_classifier_20250522_013544.<module>:218 - Imputation values for V2 features saved to: /Users/omarabul-hassan/Desktop/projects/kalshi/notebooks/trained_models/rf/imputation_values_classifier_v2.json\n",
      "2025-05-22 01:35:47,882 - INFO - model_training_classifier_20250522_013544.<module>:237 -   Training data from: 2025-04-11T20:00:00+00:00 to 2025-05-08T08:24:00+00:00\n",
      "2025-05-22 01:35:47,882 - INFO - model_training_classifier_20250522_013544.<module>:238 -   Test data from:     2025-05-08T08:24:00+00:00 to 2025-05-16T01:44:00+00:00\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Data Preprocessing, Target Transformation, Feature Selection, and Splitting\n",
    "# THIS CELL IS SIGNIFICANTLY MODIFIED FOR IMUTATION\n",
    "\n",
    "if df_model_data.empty:\n",
    "    logger.error(\"df_model_data is empty. Cannot proceed. Ensure Cell 1 ran correctly.\")\n",
    "    # Initialize to prevent errors in subsequent cells if this path is taken\n",
    "    X, y, X_train, y_train, X_test, y_test, X_train_scaled_df, X_test_scaled_df = [pd.DataFrame()]*8\n",
    "    scaler = None\n",
    "    imputation_values = {}\n",
    "else:\n",
    "    logger.info(f\"Starting preprocessing for df_model_data with shape: {df_model_data.shape}\")\n",
    "\n",
    "    # --- 1. Ensure Chronological Order ---\n",
    "    df_model_data.sort_values(by='decision_point_ts_utc', inplace=True)\n",
    "    df_model_data.reset_index(drop=True, inplace=True)\n",
    "    logger.info(\"Data sorted by 'decision_point_ts_utc'.\")\n",
    "\n",
    "    # --- 2. Define Target Variable ---\n",
    "    original_target_col = 'TARGET_btc_diff_from_strike'\n",
    "    classification_target_col = 'TARGET_market_resolves_yes'\n",
    "    if original_target_col not in df_model_data.columns:\n",
    "        raise ValueError(f\"Missing required column for target: {original_target_col}\")\n",
    "    df_model_data[classification_target_col] = (df_model_data[original_target_col] > 0).astype(int)\n",
    "    logger.info(f\"Created binary classification target '{classification_target_col}'.\")\n",
    "    logger.info(f\"Value counts for '{classification_target_col}':\\n{df_model_data[classification_target_col].value_counts(normalize=True)}\")\n",
    "\n",
    "    # --- 3. Define Feature Columns ---\n",
    "    identifier_cols = ['kalshi_market_ticker', 'decision_point_ts_utc', 'kalshi_strike_price']\n",
    "    feature_columns = [\n",
    "        col for col in df_model_data.columns\n",
    "        if col not in identifier_cols + [original_target_col, classification_target_col]\n",
    "    ]\n",
    "    logger.info(f\"Identified {len(feature_columns)} feature columns.\")\n",
    "    # logger.info(f\"Feature columns list:\\n{feature_columns}\") # Uncomment for verbosity\n",
    "\n",
    "    # --- 4. Initial NaN Check (on df_model_data for features) ---\n",
    "    nan_summary_before_processing = df_model_data[feature_columns].isnull().sum()\n",
    "    nan_summary_before_processing = nan_summary_before_processing[nan_summary_before_processing > 0].sort_values(ascending=False)\n",
    "    if not nan_summary_before_processing.empty:\n",
    "        logger.info(f\"NaN values in feature columns of df_model_data BEFORE ANY imputation/split:\\n{nan_summary_before_processing}\")\n",
    "    else:\n",
    "        logger.info(\"No NaNs found in feature columns of df_model_data before any imputation/split.\")\n",
    "\n",
    "    # --- 5. Drop rows with NaN in target *before* splitting ---\n",
    "    # This ensures y_train and y_test do not have NaNs.\n",
    "    original_len_before_target_nan_drop = len(df_model_data)\n",
    "    df_model_data.dropna(subset=[classification_target_col], inplace=True)\n",
    "    logger.info(f\"Dropped {original_len_before_target_nan_drop - len(df_model_data)} rows due to NaN in target '{classification_target_col}'.\")\n",
    "    logger.info(f\"Shape of df_model_data after dropping NaNs in target: {df_model_data.shape}\")\n",
    "\n",
    "\n",
    "    # --- 6. Prepare X and y (from the potentially reduced df_model_data) ---\n",
    "    if df_model_data.empty:\n",
    "        logger.error(\"df_model_data is empty after dropping NaNs in target. Cannot proceed.\")\n",
    "        X, y, X_train, y_train, X_test, y_test, X_train_scaled_df, X_test_scaled_df = [pd.DataFrame()]*8\n",
    "        scaler = None\n",
    "        imputation_values = {}\n",
    "    else:\n",
    "        X = df_model_data[feature_columns].copy()\n",
    "        y = df_model_data[classification_target_col].copy()\n",
    "\n",
    "        # --- 7. Chronological Train-Test Split ---\n",
    "        split_ratio = 0.8\n",
    "        split_index = int(len(X) * split_ratio)\n",
    "\n",
    "        # Ensure X_train, y_train, X_test, y_test are fresh copies for imputation\n",
    "        X_train = X.iloc[:split_index].copy()\n",
    "        y_train = y.iloc[:split_index].copy()\n",
    "        X_test = X.iloc[split_index:].copy()\n",
    "        y_test = y.iloc[split_index:].copy()\n",
    "\n",
    "        logger.info(f\"Data split chronologically:\")\n",
    "        logger.info(f\"  X_train shape: {X_train.shape}, y_train shape: {y_train.shape}\")\n",
    "        logger.info(f\"  X_test shape: {X_test.shape}, y_test shape: {y_test.shape}\")\n",
    "        \n",
    "        # Log NaN counts per column in X_train and X_test BEFORE imputation\n",
    "        logger.info(f\"NaNs in X_train before imputation:\\n{X_train.isnull().sum()[X_train.isnull().sum() > 0]}\")\n",
    "        logger.info(f\"NaNs in X_test before imputation:\\n{X_test.isnull().sum()[X_test.isnull().sum() > 0]}\")\n",
    "\n",
    "\n",
    "        # --- 8. Calculate Imputation Values from X_train and Apply ---\n",
    "        imputation_values = {}\n",
    "        logger.info(\"Calculating imputation values from X_train and applying to X_train & X_test...\")\n",
    "\n",
    "        # Helper to apply imputation\n",
    "        def apply_imputation_value(df, col_name, value_to_fill):\n",
    "            if col_name in df.columns:\n",
    "                df[col_name].fillna(value_to_fill, inplace=True)\n",
    "\n",
    "        # Stage 1: Impute 'kalshi_yes_bid' and 'kalshi_yes_ask' first (fixed values)\n",
    "        # These are components for 'kalshi_spread' and 'kalshi_mid_price'\n",
    "        if 'kalshi_yes_bid' in feature_columns:\n",
    "            val = 0.0 # Fixed value from original logic\n",
    "            imputation_values['kalshi_yes_bid'] = val\n",
    "            apply_imputation_value(X_train, 'kalshi_yes_bid', val)\n",
    "            apply_imputation_value(X_test, 'kalshi_yes_bid', val)\n",
    "\n",
    "        if 'kalshi_yes_ask' in feature_columns:\n",
    "            val = 100.0 # Fixed value from original logic\n",
    "            imputation_values['kalshi_yes_ask'] = val\n",
    "            apply_imputation_value(X_train, 'kalshi_yes_ask', val)\n",
    "            apply_imputation_value(X_test, 'kalshi_yes_ask', val)\n",
    "\n",
    "        # Stage 2: Re-calculate derived features ('kalshi_spread', 'kalshi_mid_price')\n",
    "        # using (now imputed) components.\n",
    "        # These might still have NaNs if their components were fully NaN (unlikely after fixed imputation)\n",
    "        # or if the columns themselves were entirely NaN to begin with.\n",
    "        if 'kalshi_spread' in feature_columns and 'kalshi_yes_ask' in X_train.columns and 'kalshi_yes_bid' in X_train.columns:\n",
    "            X_train['kalshi_spread'] = X_train['kalshi_yes_ask'] - X_train['kalshi_yes_bid']\n",
    "            X_test['kalshi_spread'] = X_test['kalshi_yes_ask'] - X_test['kalshi_yes_bid']\n",
    "\n",
    "        if 'kalshi_mid_price' in feature_columns and 'kalshi_yes_ask' in X_train.columns and 'kalshi_yes_bid' in X_train.columns:\n",
    "            X_train['kalshi_mid_price'] = (X_train['kalshi_yes_bid'] + X_train['kalshi_yes_ask']) / 2.0\n",
    "            X_test['kalshi_mid_price'] = (X_test['kalshi_yes_bid'] + X_test['kalshi_yes_ask']) / 2.0\n",
    "\n",
    "        # Stage 3: Determine and apply imputation for all other features (including the derived ones)\n",
    "        for col in feature_columns:\n",
    "            if col in imputation_values: # Already handled (e.g., kalshi_yes_bid, kalshi_yes_ask)\n",
    "                continue\n",
    "\n",
    "            fill_value_for_col = np.nan # Initialize\n",
    "\n",
    "            # Determine fill_value_for_col based on X_train's data for 'col'\n",
    "            if X_train[col].isnull().any(): # If there are NaNs in X_train for this column\n",
    "                if 'btc_mom' in col or 'kalshi_mid_chg' in col: fill_value_for_col = 0.0\n",
    "                elif 'btc_vol' in col or 'kalshi_mid_vol' in col: fill_value_for_col = X_train[col].median()\n",
    "                elif 'btc_sma' in col or 'btc_ema' in col: fill_value_for_col = X_train[col].median()\n",
    "                elif 'btc_price_vs_sma' in col or 'btc_price_vs_ema' in col: fill_value_for_col = 1.0\n",
    "                elif 'btc_rsi' in col: fill_value_for_col = 50.0\n",
    "                elif 'btc_atr' in col: fill_value_for_col = X_train[col].median()\n",
    "                elif col == 'distance_to_strike_norm_atr': fill_value_for_col = 0.0\n",
    "                elif col == 'kalshi_vs_btc_implied_spread': fill_value_for_col = 0.0\n",
    "                elif col == 'kalshi_spread': fill_value_for_col = X_train[col].median() # Fallback for derived spread\n",
    "                elif col == 'kalshi_mid_price': fill_value_for_col = X_train[col].median() # Fallback for derived mid\n",
    "                elif 'kalshi_volume_t_minus_1' in col or 'kalshi_open_interest_t_minus_1' in col: fill_value_for_col = 0.0\n",
    "                else: # General fallback for any other unexpected column with NaNs\n",
    "                    logger.warning(f\"Col '{col}' in X_train has NaNs; using its median for imputation.\")\n",
    "                    fill_value_for_col = X_train[col].median()\n",
    "                \n",
    "                if pd.isna(fill_value_for_col): # If median calculation resulted in NaN (e.g. all NaNs in col)\n",
    "                    logger.warning(f\"Median for '{col}' in X_train is NaN. Using 0.0 as fallback imputation value.\")\n",
    "                    fill_value_for_col = 0.0\n",
    "            else: # No NaNs in X_train[col]. Store a representative value for X_test if it has NaNs.\n",
    "                  # For consistency with how NaNs would have been filled.\n",
    "                if 'btc_mom' in col or 'kalshi_mid_chg' in col: fill_value_for_col = 0.0\n",
    "                elif 'btc_price_vs_sma' in col or 'btc_price_vs_ema' in col: fill_value_for_col = 1.0\n",
    "                elif 'btc_rsi' in col: fill_value_for_col = 50.0\n",
    "                elif col == 'distance_to_strike_norm_atr': fill_value_for_col = 0.0\n",
    "                elif col == 'kalshi_vs_btc_implied_spread': fill_value_for_col = 0.0\n",
    "                elif col == 'kalshi_spread': fill_value_for_col = 100.0 # Default if no NaNs, consistent with typical range\n",
    "                elif col == 'kalshi_mid_price': fill_value_for_col = 50.0  # Default if no NaNs\n",
    "                elif 'kalshi_volume_t_minus_1' in col or 'kalshi_open_interest_t_minus_1' in col: fill_value_for_col = 0.0\n",
    "                else: # For vol, sma, ema, atr - if no NaNs, their \"imputation value\" is their median from X_train\n",
    "                    fill_value_for_col = X_train[col].median() if not X_train[col].empty else 0.0\n",
    "                    if pd.isna(fill_value_for_col): fill_value_for_col = 0.0 # Final fallback\n",
    "\n",
    "            imputation_values[col] = fill_value_for_col\n",
    "            apply_imputation_value(X_train, col, fill_value_for_col)\n",
    "            apply_imputation_value(X_test, col, fill_value_for_col)\n",
    "\n",
    "        logger.info(f\"Imputation values map created with {len(imputation_values)} entries.\")\n",
    "        # logger.debug(f\"Imputation values: {imputation_values}\") # Uncomment for verbose output\n",
    "\n",
    "        # --- 9. Final NaN Check and Drop (as a Safety Net) ---\n",
    "        if X_train.isnull().any().any(): # Check if any NaNs exist in any column of X_train\n",
    "            nan_cols_train = X_train.columns[X_train.isnull().any()].tolist()\n",
    "            logger.warning(f\"X_train still has NaNs after imputation in columns: {nan_cols_train}. Dropping affected rows.\")\n",
    "            rows_before_train = len(X_train)\n",
    "            X_train.dropna(inplace=True)\n",
    "            y_train = y_train.loc[X_train.index] # Align y_train\n",
    "            logger.info(f\"Dropped {rows_before_train - len(X_train)} rows from X_train/y_train due to persistent NaNs.\")\n",
    "\n",
    "        if X_test.isnull().any().any():\n",
    "            nan_cols_test = X_test.columns[X_test.isnull().any()].tolist()\n",
    "            logger.warning(f\"X_test still has NaNs after imputation in columns: {nan_cols_test}. Dropping affected rows.\")\n",
    "            rows_before_test = len(X_test)\n",
    "            X_test.dropna(inplace=True)\n",
    "            y_test = y_test.loc[X_test.index] # Align y_test\n",
    "            logger.info(f\"Dropped {rows_before_test - len(X_test)} rows from X_test/y_test due to persistent NaNs.\")\n",
    "\n",
    "        logger.info(f\"Shapes after all imputation and final NaN drop:\")\n",
    "        logger.info(f\"  X_train: {X_train.shape}, y_train: {y_train.shape}\")\n",
    "        logger.info(f\"  X_test: {X_test.shape}, y_test: {y_test.shape}\")\n",
    "\n",
    "        if X_train.empty or X_test.empty:\n",
    "            logger.error(\"X_train or X_test is empty after all NaN handling. Cannot proceed with scaling.\")\n",
    "            X_train_scaled_df, X_test_scaled_df = pd.DataFrame(), pd.DataFrame() # Ensure empty DFs\n",
    "            scaler = None # Ensure scaler is None\n",
    "        else:\n",
    "            # --- 10. Feature Scaling ---\n",
    "            scaler = StandardScaler()\n",
    "            X_train_scaled = scaler.fit_transform(X_train)\n",
    "            X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "            X_train_scaled_df = pd.DataFrame(X_train_scaled, columns=X_train.columns, index=X_train.index)\n",
    "            X_test_scaled_df = pd.DataFrame(X_test_scaled, columns=X_test.columns, index=X_test.index)\n",
    "            logger.info(\"Features scaled using StandardScaler.\")\n",
    "\n",
    "            # --- 11. Save Scaler, Feature List, and Imputation Values ---\n",
    "            scaler_path_v2 = MODEL_OUTPUT_DIR / \"feature_scaler_classifier_v2.joblib\"\n",
    "            joblib.dump(scaler, scaler_path_v2)\n",
    "            logger.info(f\"Scaler for V2 features saved to: {scaler_path_v2}\")\n",
    "\n",
    "            feature_columns_list_path_v2 = MODEL_OUTPUT_DIR / \"feature_columns_classifier_v2.json\"\n",
    "            with open(feature_columns_list_path_v2, 'w') as f:\n",
    "                json.dump(feature_columns, f)\n",
    "            logger.info(f\"List of V2 feature columns ({len(feature_columns)} features) saved to: {feature_columns_list_path_v2}\")\n",
    "\n",
    "            imputation_values_path_v2 = MODEL_OUTPUT_DIR / \"imputation_values_classifier_v2.json\"\n",
    "            serializable_imputation_values = {}\n",
    "            for k, v_val in imputation_values.items():\n",
    "                if isinstance(v_val, (np.generic, np.ndarray)): # Handle numpy types\n",
    "                    serializable_imputation_values[k] = v_val.item() if isinstance(v_val, np.generic) else v_val.tolist()\n",
    "                else:\n",
    "                    serializable_imputation_values[k] = v_val\n",
    "            with open(imputation_values_path_v2, 'w') as f:\n",
    "                json.dump(serializable_imputation_values, f, indent=4)\n",
    "            logger.info(f\"Imputation values for V2 features saved to: {imputation_values_path_v2}\")\n",
    "\n",
    "            # Log chronological range of training and test sets\n",
    "            if not X_train.empty and 'decision_point_ts_utc' in df_model_data.columns:\n",
    "                try:\n",
    "                    # Use .iloc[0] and .iloc[-1] on the original X_train/X_test before potential dropna\n",
    "                    # to get the intended boundary timestamps from df_model_data.\n",
    "                    # However, X_train.index might have changed if rows were dropped.\n",
    "                    # It's safer to use the indices that are confirmed to be in the final X_train/X_test.\n",
    "                    train_start_ts_unix = df_model_data.loc[X_train.index[0], 'decision_point_ts_utc']\n",
    "                    train_end_ts_unix = df_model_data.loc[X_train.index[-1], 'decision_point_ts_utc']\n",
    "                    test_start_ts_unix = df_model_data.loc[X_test.index[0], 'decision_point_ts_utc']\n",
    "                    test_end_ts_unix = df_model_data.loc[X_test.index[-1], 'decision_point_ts_utc']\n",
    "\n",
    "                    train_start_ts_iso = dt.datetime.fromtimestamp(train_start_ts_unix, tz=timezone.utc).isoformat()\n",
    "                    train_end_ts_iso = dt.datetime.fromtimestamp(train_end_ts_unix, tz=timezone.utc).isoformat()\n",
    "                    test_start_ts_iso = dt.datetime.fromtimestamp(test_start_ts_unix, tz=timezone.utc).isoformat()\n",
    "                    test_end_ts_iso = dt.datetime.fromtimestamp(test_end_ts_unix, tz=timezone.utc).isoformat()\n",
    "\n",
    "                    logger.info(f\"  Training data from: {train_start_ts_iso} to {train_end_ts_iso}\")\n",
    "                    logger.info(f\"  Test data from:     {test_start_ts_iso} to {test_end_ts_iso}\")\n",
    "                except IndexError:\n",
    "                    logger.warning(\"Could not determine train/test date ranges due to empty X_train/X_test after NaN drops.\")\n",
    "                except KeyError as e:\n",
    "                     logger.warning(f\"Could not determine train/test date ranges, KeyError: {e}. Indices might be out of bound for df_model_data.\")\n",
    "            else:\n",
    "                logger.warning(\"Train set is empty or 'decision_point_ts_utc' missing. Cannot log date ranges.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-22 01:40:57,049 - INFO - model_training_classifier_20250522_013544.<module>:10 - --- Starting Classification Model Training (Calibrated Random Forest) ---\n",
      "2025-05-22 01:40:57,049 - INFO - model_training_classifier_20250522_013544.<module>:23 - Using Regularized RF Params for OOB check and CalibratedCV: {'n_estimators': 200, 'max_depth': 8, 'min_samples_split': 100, 'min_samples_leaf': 50, 'class_weight': 'balanced_subsample', 'random_state': 42, 'n_jobs': -1}\n",
      "2025-05-22 01:40:57,050 - INFO - model_training_classifier_20250522_013544.<module>:30 - Fitting base RandomForest model (for OOB check) on 925776 samples...\n",
      "2025-05-22 01:41:56,136 - INFO - model_training_classifier_20250522_013544.<module>:36 - Base RandomForest model training complete for OOB check.\n",
      "2025-05-22 01:41:56,136 - INFO - model_training_classifier_20250522_013544.<module>:38 -   Base Model Out-of-Bag (OOB) Score (Regularized): 0.8673\n",
      "2025-05-22 01:41:56,136 - INFO - model_training_classifier_20250522_013544.<module>:45 - Training CalibratedRandomForest_classifier_v2 (Calibrated RF with sigmoid) on 925776 samples...\n",
      "2025-05-22 01:41:56,175 - INFO - model_training_classifier_20250522_013544.<module>:54 - Model parameters for CalibratedClassifierCV: {'cv': 3, 'ensemble': 'auto', 'estimator__bootstrap': True, 'estimator__ccp_alpha': 0.0, 'estimator__class_weight': 'balanced_subsample', 'estimator__criterion': 'gini', 'estimator__max_depth': 8, 'estimator__max_features': 'sqrt', 'estimator__max_leaf_nodes': None, 'estimator__max_samples': None, 'estimator__min_impurity_decrease': 0.0, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 100, 'estimator__min_weight_fraction_leaf': 0.0, 'estimator__monotonic_cst': None, 'estimator__n_estimators': 200, 'estimator__n_jobs': -1, 'estimator__oob_score': False, 'estimator__random_state': 42, 'estimator__verbose': 0, 'estimator__warm_start': False, 'estimator': RandomForestClassifier(class_weight='balanced_subsample', max_depth=8,\n",
      "                       min_samples_leaf=50, min_samples_split=100,\n",
      "                       n_estimators=200, n_jobs=-1, random_state=42), 'method': 'sigmoid', 'n_jobs': None}\n",
      "2025-05-22 01:43:23,076 - INFO - model_training_classifier_20250522_013544.<module>:61 - CalibratedRandomForest_classifier_v2 model training complete.\n",
      "2025-05-22 01:43:23,077 - INFO - model_training_classifier_20250522_013544.<module>:64 - Making predictions with CalibratedRandomForest_classifier_v2 on the test set (231444 samples)...\n",
      "\n",
      "2025-05-22 01:43:24,508 - INFO - model_training_classifier_20250522_013544.<module>:80 - --- CalibratedRandomForest_classifier_v2 Evaluation Metrics (Test Set, Regularized RF base) ---\n",
      "2025-05-22 01:43:24,508 - INFO - model_training_classifier_20250522_013544.<module>:81 -   Accuracy:          0.8159\n",
      "2025-05-22 01:43:24,508 - INFO - model_training_classifier_20250522_013544.<module>:82 -   Precision:         0.7475\n",
      "2025-05-22 01:43:24,509 - INFO - model_training_classifier_20250522_013544.<module>:83 -   Recall (TPR):      0.9699\n",
      "2025-05-22 01:43:24,509 - INFO - model_training_classifier_20250522_013544.<module>:84 -   F1-Score:          0.8443\n",
      "2025-05-22 01:43:24,509 - INFO - model_training_classifier_20250522_013544.<module>:85 -   ROC AUC:           0.9547\n",
      "2025-05-22 01:43:24,509 - INFO - model_training_classifier_20250522_013544.<module>:86 -   Log Loss:          0.4023\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-22 01:43:24,578 - INFO - model_training_classifier_20250522_013544.<module>:96 - Description of P(YES) for CalibratedRandomForest_classifier_v2 (Regularized RF base) on test set:\n",
      "count    231444.000000\n",
      "mean          0.659222\n",
      "std           0.259424\n",
      "min           0.140517\n",
      "25%           0.424946\n",
      "50%           0.644090\n",
      "75%           0.936134\n",
      "max           0.952088\n",
      "2025-05-22 01:43:24,578 - INFO - model_training_classifier_20250522_013544.<module>:99 - \n",
      "--- Confusion Matrix (Test Set) - CalibratedRandomForest_classifier_v2 (Regularized RF base) ---\n",
      "2025-05-22 01:43:24,581 - INFO - model_training_classifier_20250522_013544.<module>:101 - \n",
      "[[ 73313  39017]\n",
      " [  3586 115528]]\n",
      "2025-05-22 01:43:24,581 - INFO - model_training_classifier_20250522_013544.<module>:104 -   True Negatives (TN):  73313\n",
      "2025-05-22 01:43:24,581 - INFO - model_training_classifier_20250522_013544.<module>:105 -   False Positives (FP): 39017 (Type I Error)\n",
      "2025-05-22 01:43:24,581 - INFO - model_training_classifier_20250522_013544.<module>:106 -   False Negatives (FN): 3586 (Type II Error)\n",
      "2025-05-22 01:43:24,582 - INFO - model_training_classifier_20250522_013544.<module>:107 -   True Positives (TP):  115528\n",
      "2025-05-22 01:43:24,598 - INFO - model_training_classifier_20250522_013544.<module>:126 - \n",
      "\n",
      "--- Feature Importances (from base REGULARIZED model of CalibratedRandomForest_classifier_v2) ---\n",
      "2025-05-22 01:43:24,696 - INFO - model_training_classifier_20250522_013544.<module>:152 - Trained CalibratedRandomForest_classifier_v2 model (with regularized base) saved to: /Users/omarabul-hassan/Desktop/projects/kalshi/notebooks/trained_models/rf/CalibratedRandomForest_classifier_v2.joblib\n",
      "2025-05-22 01:43:24,697 - INFO - model_training_classifier_20250522_013544.<module>:164 - CalibratedRandomForest_classifier_v2 hyperparameters saved to: /Users/omarabul-hassan/Desktop/projects/kalshi/notebooks/trained_models/rf/CalibratedRandomForest_classifier_v2_hyperparams.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Sample of Test Set Predictions vs Actuals (CalibratedRandomForest_classifier_v2, Regularized RF base) ---\n",
      "        actual_target_resolves_yes  predicted_class_resolves_yes  predicted_proba_resolves_yes  original_target_diff         kalshi_market_ticker  decision_point_ts_utc\n",
      "925776                           0                             0                      0.320303              -1303.46  KXBTCD-25MAY0917-T104499.99             1746692640\n",
      "925777                           1                             1                      0.505475                529.52  KXBTCD-25MAY0817-T101999.99             1746692640\n",
      "925778                           1                             1                      0.546122                696.54  KXBTCD-25MAY0917-T102499.99             1746692640\n",
      "925779                           1                             1                      0.653453               2196.54  KXBTCD-25MAY0917-T100999.99             1746692640\n",
      "925780                           1                             1                      0.800426               3029.52   KXBTCD-25MAY0817-T99499.99             1746692640\n",
      "925781                           1                             1                      0.510023               2029.52  KXBTCD-25MAY0817-T100499.99             1746692640\n",
      "925782                           0                             0                      0.401510               -303.46  KXBTCD-25MAY0917-T103499.99             1746692640\n",
      "925783                           1                             1                      0.509207               1529.52  KXBTCD-25MAY0817-T100999.99             1746692640\n",
      "925784                           0                             0                      0.328664               -803.46  KXBTCD-25MAY0917-T103999.99             1746692640\n",
      "925785                           1                             1                      0.534262               2529.52   KXBTCD-25MAY0817-T99999.99             1746692640\n",
      "\n",
      "Top Feature Importances (from base REGULARIZED RF model):\n",
      "                           feature  importance\n",
      "21              distance_to_strike    0.278742\n",
      "22     distance_to_strike_norm_atr    0.255655\n",
      "30                kalshi_mid_price    0.100538\n",
      "27                  kalshi_yes_bid    0.096398\n",
      "28                  kalshi_yes_ask    0.074334\n",
      "23     time_until_market_close_min    0.058051\n",
      "35    kalshi_vs_btc_implied_spread    0.031749\n",
      "29                   kalshi_spread    0.014987\n",
      "13                     btc_ema_12m    0.010533\n",
      "15                     btc_ema_26m    0.009864\n",
      "7                      btc_sma_10m    0.009789\n",
      "0              btc_price_t_minus_1    0.009003\n",
      "17                     btc_ema_50m    0.008800\n",
      "11                     btc_sma_50m    0.008043\n",
      "9                      btc_sma_30m    0.007949\n",
      "32  kalshi_open_interest_t_minus_1    0.006396\n",
      "25                 day_of_week_utc    0.002724\n",
      "33               kalshi_mid_vol_5m    0.002615\n",
      "39              kalshi_mid_chg_10m    0.002256\n",
      "34              kalshi_mid_vol_10m    0.002248\n",
      "20                      btc_atr_14    0.001994\n",
      "38               kalshi_mid_chg_5m    0.001592\n",
      "26                 hour_of_day_edt    0.001409\n",
      "37               kalshi_mid_chg_3m    0.001041\n",
      "31         kalshi_volume_t_minus_1    0.000884\n",
      "24                 hour_of_day_utc    0.000654\n",
      "36               kalshi_mid_chg_1m    0.000536\n",
      "6                      btc_vol_15m    0.000343\n",
      "5                      btc_mom_60m    0.000221\n",
      "18            btc_price_vs_ema_50m    0.000148\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Classification Model Training and Evaluation\n",
    "# CORRECTED: Ensure CalibratedClassifierCV uses the regularized RF parameters\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.calibration import CalibratedClassifierCV # For probability calibration\n",
    "\n",
    "if 'X_train_scaled_df' not in globals() or X_train_scaled_df.empty:\n",
    "    logger.error(\"Scaled training data (X_train_scaled_df) not found or is empty. Please ensure Cell 2 ran successfully.\")\n",
    "else:\n",
    "    logger.info(\"--- Starting Classification Model Training (Calibrated Random Forest) ---\")\n",
    "\n",
    "    # --- Define Regularized RandomForest Parameters ---\n",
    "    REGULARIZED_RF_PARAMS = {\n",
    "        'n_estimators': 200,\n",
    "        'max_depth': 8,             # More regularized\n",
    "        'min_samples_split': 100,   # More regularized\n",
    "        'min_samples_leaf': 50,     # More regularized\n",
    "        'class_weight': 'balanced_subsample',\n",
    "        'random_state': 42,\n",
    "        'n_jobs': -1,\n",
    "        # oob_score is True for the base_rf_model for checking, False for CalibratedCV's internal one\n",
    "    }\n",
    "    logger.info(f\"Using Regularized RF Params for OOB check and CalibratedCV: {REGULARIZED_RF_PARAMS}\")\n",
    "\n",
    "    # --- 1. Initialize Base RandomForestClassifier Model (for OOB check) ---\n",
    "    base_rf_model_for_oob = RandomForestClassifier(**REGULARIZED_RF_PARAMS, oob_score=True)\n",
    "    \n",
    "    model_name = \"CalibratedRandomForest_classifier_v2\" # Name remains v2, but internally it's more regularized\n",
    "    \n",
    "    logger.info(f\"Fitting base RandomForest model (for OOB check) on {X_train_scaled_df.shape[0]} samples...\")\n",
    "    if 'y_train' not in globals() or y_train.empty:\n",
    "        logger.error(\"y_train (binary target) is not available. Cannot train base model.\")\n",
    "    else:\n",
    "        try:\n",
    "            base_rf_model_for_oob.fit(X_train_scaled_df, y_train) # Fit on scaled data\n",
    "            logger.info(f\"Base RandomForest model training complete for OOB check.\")\n",
    "            if hasattr(base_rf_model_for_oob, 'oob_score_') and base_rf_model_for_oob.oob_score_:\n",
    "                 logger.info(f\"  Base Model Out-of-Bag (OOB) Score (Regularized): {base_rf_model_for_oob.oob_score_:.4f}\")\n",
    "            else:\n",
    "                logger.warning(\"  Base Model OOB Score not available (oob_score=True might not have run or failed).\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error fitting base RF model for OOB check: {e}\", exc_info=True)\n",
    "    \n",
    "    # --- 2. Initialize and Train CalibratedClassifierCV (using REGULARIZED RF) ---\n",
    "    logger.info(f\"Training {model_name} (Calibrated RF with sigmoid) on {X_train_scaled_df.shape[0]} samples...\")\n",
    "    \n",
    "    # Pass a NEW instance of RandomForestClassifier with the REGULARIZED parameters\n",
    "    calibrated_classifier_model = CalibratedClassifierCV(\n",
    "        RandomForestClassifier(**REGULARIZED_RF_PARAMS, oob_score=False), # oob_score=False for estimator in CalibratedCV\n",
    "        method='sigmoid', \n",
    "        cv=3 # Number of folds for calibration\n",
    "    )\n",
    "    \n",
    "    logger.info(f\"Model parameters for CalibratedClassifierCV: {calibrated_classifier_model.get_params()}\")\n",
    "    \n",
    "    if 'y_train' not in globals() or y_train.empty:\n",
    "        logger.error(\"y_train (binary target) is not available. Cannot train calibrated model.\")\n",
    "    else:\n",
    "        try:\n",
    "            calibrated_classifier_model.fit(X_train_scaled_df, y_train) # Fit on scaled data\n",
    "            logger.info(f\"{model_name} model training complete.\")\n",
    "\n",
    "            # --- 3. Make Predictions on the Test Set ---\n",
    "            logger.info(f\"Making predictions with {model_name} on the test set ({X_test_scaled_df.shape[0]} samples)...\\n\")\n",
    "            y_pred_test_class = calibrated_classifier_model.predict(X_test_scaled_df)\n",
    "            y_pred_test_proba = calibrated_classifier_model.predict_proba(X_test_scaled_df)[:, 1]\n",
    "\n",
    "            # --- 4. Evaluate Model Performance (Classification Metrics) ---\n",
    "            if 'y_test' not in globals() or y_test.empty:\n",
    "                logger.error(\"y_test (binary target) is not available. Cannot evaluate model.\")\n",
    "            else:\n",
    "                accuracy = accuracy_score(y_test, y_pred_test_class)\n",
    "                precision = precision_score(y_test, y_pred_test_class, zero_division=0)\n",
    "                recall = recall_score(y_test, y_pred_test_class, zero_division=0)\n",
    "                f1 = f1_score(y_test, y_pred_test_class, zero_division=0)\n",
    "                try: roc_auc = roc_auc_score(y_test, y_pred_test_proba)\n",
    "                except ValueError as e: logger.warning(f\"Could not calculate ROC AUC: {e}\"); roc_auc = np.nan\n",
    "                logloss = log_loss(y_test, y_pred_test_proba)\n",
    "\n",
    "                logger.info(f\"--- {model_name} Evaluation Metrics (Test Set, Regularized RF base) ---\") # Updated log message\n",
    "                logger.info(f\"  Accuracy:          {accuracy:.4f}\")\n",
    "                logger.info(f\"  Precision:         {precision:.4f}\")\n",
    "                logger.info(f\"  Recall (TPR):      {recall:.4f}\")\n",
    "                logger.info(f\"  F1-Score:          {f1:.4f}\")\n",
    "                logger.info(f\"  ROC AUC:           {roc_auc:.4f}\")\n",
    "                logger.info(f\"  Log Loss:          {logloss:.4f}\")\n",
    "\n",
    "                import matplotlib.pyplot as plt\n",
    "                plt.figure(figsize=(10,6))\n",
    "                plt.hist(y_pred_test_proba, bins=50, alpha=0.7, label=f'P(YES) - {model_name}')\n",
    "                plt.title(f'Histogram of Predicted Probabilities (P(YES)) on Test Set - {model_name} (Regularized RF base)') # Updated title\n",
    "                plt.xlabel('Predicted Probability of YES')\n",
    "                plt.ylabel('Frequency')\n",
    "                plt.legend()\n",
    "                plt.show()\n",
    "                logger.info(f\"Description of P(YES) for {model_name} (Regularized RF base) on test set:\\n{pd.Series(y_pred_test_proba).describe().to_string()}\")\n",
    "\n",
    "\n",
    "                logger.info(f\"\\n--- Confusion Matrix (Test Set) - {model_name} (Regularized RF base) ---\") # Updated log message\n",
    "                cm = confusion_matrix(y_test, y_pred_test_class)\n",
    "                logger.info(f\"\\n{cm}\")\n",
    "                try:\n",
    "                    tn, fp, fn, tp = cm.ravel()\n",
    "                    logger.info(f\"  True Negatives (TN):  {tn}\")\n",
    "                    logger.info(f\"  False Positives (FP): {fp} (Type I Error)\")\n",
    "                    logger.info(f\"  False Negatives (FN): {fn} (Type II Error)\")\n",
    "                    logger.info(f\"  True Positives (TP):  {tp}\")\n",
    "                except ValueError: logger.warning(\"Could not unpack full confusion matrix.\")\n",
    "\n",
    "                df_results_class = pd.DataFrame({\n",
    "                    'actual_target_resolves_yes': y_test,\n",
    "                    'predicted_class_resolves_yes': y_pred_test_class,\n",
    "                    'predicted_proba_resolves_yes': y_pred_test_proba\n",
    "                })\n",
    "                if 'original_target_col' in globals() and original_target_col in df_model_data.columns and not X_test.empty :\n",
    "                    df_results_class['original_target_diff'] = df_model_data.loc[X_test.index, original_target_col].values\n",
    "                if 'kalshi_market_ticker' in df_model_data.columns and not X_test.empty:\n",
    "                    df_results_class['kalshi_market_ticker'] = df_model_data.loc[X_test.index, 'kalshi_market_ticker'].values\n",
    "                if 'decision_point_ts_utc' in df_model_data.columns and not X_test.empty:\n",
    "                    df_results_class['decision_point_ts_utc'] = df_model_data.loc[X_test.index, 'decision_point_ts_utc'].values\n",
    "                \n",
    "                print(f\"\\n--- Sample of Test Set Predictions vs Actuals ({model_name}, Regularized RF base) ---\")\n",
    "                print(df_results_class.head(10).to_string())\n",
    "\n",
    "                # --- 5. Inspect Feature Importances (from the BASE REGULARIZED RandomForest model used for OOB) ---\n",
    "                logger.info(f\"\\n\\n--- Feature Importances (from base REGULARIZED model of {model_name}) ---\")\n",
    "                \n",
    "                if hasattr(base_rf_model_for_oob, 'feature_importances_'): # Use the regularized one\n",
    "                    if 'feature_columns' not in globals() or not feature_columns:\n",
    "                        logger.warning(\"feature_columns list not found or empty.\")\n",
    "                        feat_col_path = MODEL_OUTPUT_DIR / \"feature_columns_classifier_v2.json\"\n",
    "                        if feat_col_path.exists():\n",
    "                            with open(feat_col_path, 'r') as f_cols: loaded_feature_cols = json.load(f_cols)\n",
    "                            if len(loaded_feature_cols) == X_train_scaled_df.shape[1]: feature_columns_for_importance = loaded_feature_cols\n",
    "                            else: feature_columns_for_importance = [f\"feature_{i}\" for i in range(X_train_scaled_df.shape[1])]\n",
    "                        else: feature_columns_for_importance = [f\"feature_{i}\" for i in range(X_train_scaled_df.shape[1])]\n",
    "                    else: feature_columns_for_importance = feature_columns\n",
    "                    \n",
    "                    importances = pd.DataFrame({\n",
    "                        'feature': feature_columns_for_importance, \n",
    "                        'importance': base_rf_model_for_oob.feature_importances_ # Use the regularized one\n",
    "                    })\n",
    "                    importances.sort_values(by='importance', ascending=False, inplace=True)\n",
    "                    print(\"\\nTop Feature Importances (from base REGULARIZED RF model):\")\n",
    "                    print(importances.head(30).to_string())\n",
    "                else:\n",
    "                    logger.warning(f\"Could not retrieve feature importances from the base regularized RF model for {model_name}.\")\n",
    "\n",
    "                # --- 6. Save the Trained CALIBRATED Model (which now uses regularized RF base) ---\n",
    "                model_path = MODEL_OUTPUT_DIR / f\"{model_name}.joblib\"\n",
    "                joblib.dump(calibrated_classifier_model, model_path)\n",
    "                logger.info(f\"Trained {model_name} model (with regularized base) saved to: {model_path}\")\n",
    "\n",
    "                model_hyperparams = calibrated_classifier_model.get_params(deep=True)\n",
    "                params_path = MODEL_OUTPUT_DIR / f\"{model_name}_hyperparams.json\"\n",
    "                with open(params_path, 'w') as f:\n",
    "                    serializable_params = {}\n",
    "                    for k_param, v_param in model_hyperparams.items():\n",
    "                        if isinstance(v_param, np.ndarray): serializable_params[k_param] = v_param.tolist()\n",
    "                        elif isinstance(v_param, (np.bool_, np.integer, np.floating)): serializable_params[k_param] = v_param.item()\n",
    "                        elif isinstance(v_param, (BaseException)): serializable_params[k_param] = str(v_param) # For estimator objects\n",
    "                        else: serializable_params[k_param] = v_param\n",
    "                    json.dump(serializable_params, f, indent=4, default=lambda o: '<not serializable>')\n",
    "                logger.info(f\"{model_name} hyperparameters saved to: {params_path}\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            logger.critical(f\"An error occurred during {model_name} model training or evaluation: {e}\", exc_info=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
