{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Imports and Load Data (Corrected Path and Timestamp Logic, Add Strategy Params)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import os\n",
    "import glob \n",
    "import re \n",
    "\n",
    "# --- Configuration ---\n",
    "current_notebook_dir = Path.cwd() \n",
    "LOGS_PARENT_DIR = current_notebook_dir.parent / \"logs\"\n",
    "print(f\"Calculated LOGS_PARENT_DIR: {LOGS_PARENT_DIR.resolve()}\")\n",
    "\n",
    "MODEL_TYPE_LOG_SUBDIR_NAME = \"backtest_random_forest_calibrated_v2_15m_offset\" \n",
    "print(f\"Expecting detailed logs in subdir: {MODEL_TYPE_LOG_SUBDIR_NAME}\")\n",
    "\n",
    "# --- STRATEGY PARAMETERS (Manually set to match the backtest run being analyzed) ---\n",
    "# These were the values used in your backtest_classifier_v1.py for the RF Calibrated V2 run\n",
    "# (as per your log \"Strategy Params: MinProb=0.7, Edge=0.15\")\n",
    "# Or, if you used different values, update them here.\n",
    "# The values from your previous provided log were: MinProb=0.60, Edge=0.10\n",
    "# The values from your more recent successful run log were: MinProb=0.8, Edge=0.2 (from live_backtest_main.py)\n",
    "# Let's assume the ones from the successful run that generated the BUY_YES trades:\n",
    "# MinProb=0.55, Edge=0.05 (as suggested to try)\n",
    "# If the logs you are analyzing were with MinProb=0.6, Edge=0.1, use those:\n",
    "STRATEGY_MIN_MODEL_PROB_FOR_CONSIDERATION = 0.60\n",
    "STRATEGY_EDGE_THRESHOLD_FOR_TRADE = 0.10\n",
    "print(f\"Using for EDA: STRATEGY_MIN_MODEL_PROB_FOR_CONSIDERATION = {STRATEGY_MIN_MODEL_PROB_FOR_CONSIDERATION}\")\n",
    "print(f\"Using for EDA: STRATEGY_EDGE_THRESHOLD_FOR_TRADE = {STRATEGY_EDGE_THRESHOLD_FOR_TRADE}\")\n",
    "\n",
    "\n",
    "# --- Load Main Aggregated Trades File ---\n",
    "all_trades_files_pattern = \"ALL_TRADES_WITH_EVALS_random_forest_*.csv\" \n",
    "all_trades_files = sorted(LOGS_PARENT_DIR.glob(all_trades_files_pattern), key=os.path.getctime, reverse=True)\n",
    "\n",
    "df_all_decisions = pd.DataFrame()\n",
    "ALL_TRADES_CSV_PATH = None\n",
    "run_ts_from_filename = None \n",
    "\n",
    "if not all_trades_files:\n",
    "    print(f\"ERROR: No '{all_trades_files_pattern}' file found in {LOGS_PARENT_DIR.resolve()}\")\n",
    "else:\n",
    "    ALL_TRADES_CSV_PATH = all_trades_files[0] \n",
    "    if ALL_TRADES_CSV_PATH:\n",
    "        print(f\"Loading main decision log: {ALL_TRADES_CSV_PATH}\")\n",
    "        try:\n",
    "            df_all_decisions = pd.read_csv(ALL_TRADES_CSV_PATH)\n",
    "            df_all_decisions['decision_timestamp_utc'] = pd.to_datetime(df_all_decisions['decision_timestamp_utc'])\n",
    "            print(f\"Loaded {len(df_all_decisions)} total decision records from main log.\")\n",
    "\n",
    "            filename_stem = Path(ALL_TRADES_CSV_PATH).stem\n",
    "            match_ts = re.search(r'(\\d{8}_\\d{6})', filename_stem) \n",
    "            if match_ts:\n",
    "                run_ts_from_filename = match_ts.group(1)\n",
    "            else:\n",
    "                parts = filename_stem.split('_')\n",
    "                if parts and len(parts[-1]) >= 15 and parts[-1][:8].isdigit() and parts[-1][9:].isdigit(): # Check for YYYYMMDD_HHMMSS\n",
    "                    run_ts_from_filename = parts[-1]\n",
    "                elif parts and len(parts[-1]) == 6 and parts[-1].isdigit(): # Fallback for just HHMMSS (less ideal)\n",
    "                    print(f\"WARNING: Only HHMMSS timestamp found in '{filename_stem}'. Full timestamp needed for best matching.\")\n",
    "                    run_ts_from_filename = parts[-1] \n",
    "                # *** IF AUTOMATIC PARSING FAILS, MANUALLY SET THE TIMESTAMP OF YOUR LOGS HERE ***\n",
    "                # run_ts_from_filename = \"20250521_170924\" # Example: replace with your actual log timestamp\n",
    "                # print(f\"Using MANUAL OVERRIDE for run_ts_from_filename: {run_ts_from_filename}\")\n",
    "\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading {ALL_TRADES_CSV_PATH}: {e}\")\n",
    "            df_all_decisions = pd.DataFrame()\n",
    "    else:\n",
    "        print(f\"ERROR: Could not determine a suitable 'ALL_TRADES_WITH_EVALS_random_forest_*.csv' file.\")\n",
    "\n",
    "\n",
    "# --- Load and Merge Detailed Decision Evaluation Logs ---\n",
    "df_eval_details = pd.DataFrame()\n",
    "if not df_all_decisions.empty and run_ts_from_filename and len(run_ts_from_filename) == 15 : \n",
    "    print(f\"Using run_timestamp '{run_ts_from_filename}' for finding decision_eval_logs.\")\n",
    "    decision_eval_log_specific_dir = LOGS_PARENT_DIR / MODEL_TYPE_LOG_SUBDIR_NAME\n",
    "    eval_log_pattern = f\"decision_eval_log_*_random_forest_{run_ts_from_filename}.csv\"\n",
    "    \n",
    "    print(f\"Looking for decision_eval_log files in: {decision_eval_log_specific_dir.resolve()}\")\n",
    "    print(f\"Using pattern: {eval_log_pattern}\")\n",
    "    \n",
    "    decision_eval_files = sorted(list(decision_eval_log_specific_dir.glob(eval_log_pattern)))\n",
    "\n",
    "    if not decision_eval_files:\n",
    "        print(f\"WARNING: No '{eval_log_pattern}' files found in {decision_eval_log_specific_dir.resolve()}\")\n",
    "    else:\n",
    "        print(f\"Found {len(decision_eval_files)} decision_eval_log files to merge.\")\n",
    "        df_list = []\n",
    "        for f_path in decision_eval_files:\n",
    "            try:\n",
    "                df_temp = pd.read_csv(f_path)\n",
    "                df_list.append(df_temp)\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading {f_path}: {e}\")\n",
    "        if df_list:\n",
    "            df_eval_details = pd.concat(df_list, ignore_index=True)\n",
    "            df_eval_details['decision_dt_utc'] = pd.to_datetime(df_eval_details['decision_dt_utc'])\n",
    "            print(f\"Loaded and combined {len(df_eval_details)} records from decision_eval_logs.\")\n",
    "            \n",
    "            df_all_decisions = pd.merge(\n",
    "                df_all_decisions,\n",
    "                df_eval_details[['decision_dt_utc', 'market_ticker', 'implied_proba_yes_at_ask', 'edge_for_yes', 'predicted_proba_no', 'implied_proba_no_at_bid', 'edge_for_no', 'considered_action']],\n",
    "                left_on=['decision_timestamp_utc', 'market_ticker'],\n",
    "                right_on=['decision_dt_utc', 'market_ticker'],\n",
    "                how='left',\n",
    "                suffixes=('', '_eval') \n",
    "            )\n",
    "            if 'decision_dt_utc_eval' in df_all_decisions.columns: \n",
    "                 df_all_decisions.drop(columns=['decision_dt_utc_eval'], inplace=True)\n",
    "            elif 'decision_dt_utc' in df_all_decisions.columns and df_all_decisions.columns.tolist().count('decision_dt_utc') > 1: \n",
    "                 df_all_decisions = df_all_decisions.loc[:,~df_all_decisions.columns.duplicated(keep='first')]\n",
    "\n",
    "            if 'considered_action_eval' in df_all_decisions.columns:\n",
    "                df_all_decisions['considered_action'] = df_all_decisions['considered_action_eval']\n",
    "                df_all_decisions.drop(columns=['considered_action_eval'], inplace=True)\n",
    "                \n",
    "            print(f\"Merged df_eval_details (edge info) into df_all_decisions. New shape: {df_all_decisions.shape}\")\n",
    "            newly_added_cols_from_eval = ['implied_proba_yes_at_ask', 'edge_for_yes', 'predicted_proba_no', 'implied_proba_no_at_bid', 'edge_for_no', 'considered_action']\n",
    "            for col in newly_added_cols_from_eval:\n",
    "                if col not in df_all_decisions.columns:\n",
    "                    print(f\"WARNING: Column '{col}' not found after merge.\")\n",
    "                else:\n",
    "                    print(f\"Column '{col}' merged. Non-NaN count: {df_all_decisions[col].notna().sum()}\")\n",
    "        else:\n",
    "            print(\"No data loaded from decision_eval_logs, df_eval_details is empty.\")\n",
    "elif not df_all_decisions.empty:\n",
    "    print(\"WARNING: run_ts_from_filename issue ('{run_ts_from_filename}'). Skipping merge of detailed eval logs.\")\n",
    "\n",
    "\n",
    "if not df_all_decisions.empty:\n",
    "    print(f\"\\nShape of df_all_decisions after potential merge: {df_all_decisions.shape}\")\n",
    "    df_all_decisions.info(verbose=True, show_counts=True)\n",
    "    print(df_all_decisions.head().to_string()) # Use to_string for wider output\n",
    "\n",
    "    df_executed_trades = df_all_decisions[\n",
    "        (df_all_decisions['num_contracts_sim'] > 0) &\n",
    "        (df_all_decisions['executed_trade_action'].isin(['BUY_YES', 'BUY_NO']))\n",
    "    ].copy()\n",
    "    print(f\"\\nNumber of actual executed trades: {len(df_executed_trades)}\")\n",
    "    if not df_executed_trades.empty:\n",
    "        print(\"Sample of executed trades:\")\n",
    "        cols_to_show = ['decision_timestamp_utc', 'market_ticker', 'predicted_proba_yes', \n",
    "                        'executed_trade_action', 'num_contracts_sim', 'simulated_entry_price_cents', \n",
    "                        'pnl_cents', 'actual_market_result', 'edge_for_yes', 'edge_for_no', 'considered_action']\n",
    "        existing_cols_to_show = [col for col in cols_to_show if col in df_executed_trades.columns]\n",
    "        print(df_executed_trades[existing_cols_to_show].head().to_string())\n",
    "else:\n",
    "    print(\"df_all_decisions is empty. Cannot proceed with EDA.\")\n",
    "\n",
    "plt.style.use('seaborn-v0_8-whitegrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Overall Performance Summary\n",
    "\n",
    "if not df_all_decisions.empty and not df_executed_trades.empty:\n",
    "    total_pnl = df_executed_trades['pnl_cents'].sum() / 100\n",
    "    total_contracts = df_executed_trades['num_contracts_sim'].sum()\n",
    "    num_trades = len(df_executed_trades)\n",
    "\n",
    "    print(f\"--- Overall Backtest Performance ---\")\n",
    "    print(f\"Total P&L: ${total_pnl:.2f}\")\n",
    "    print(f\"Total Executed Trades: {num_trades}\")\n",
    "    print(f\"Total Contracts Traded: {total_contracts}\")\n",
    "    if num_trades > 0:\n",
    "        print(f\"Average P&L per Trade: ${total_pnl / num_trades:.2f}\")\n",
    "    if total_contracts > 0:\n",
    "        print(f\"Average P&L per Contract: ${total_pnl / total_contracts:.4f}\")\n",
    "\n",
    "    # P&L by Trade Action\n",
    "    pnl_by_action = df_executed_trades.groupby('executed_trade_action')['pnl_cents'].sum() / 100\n",
    "    print(\"\\nP&L by Trade Action:\")\n",
    "    print(pnl_by_action)\n",
    "\n",
    "    # Win/Loss Analysis\n",
    "    df_executed_trades['is_win'] = np.where(df_executed_trades['pnl_cents'] > 0, 1, 0)\n",
    "    win_rate = df_executed_trades['is_win'].mean()\n",
    "    print(f\"\\nOverall Win Rate (Executed Trades): {win_rate:.2%}\")\n",
    "\n",
    "    win_rate_by_action = df_executed_trades.groupby('executed_trade_action')['is_win'].mean()\n",
    "    print(\"\\nWin Rate by Trade Action:\")\n",
    "    print(win_rate_by_action)\n",
    "    \n",
    "    # Cumulative P&L Plot\n",
    "    if 'decision_timestamp_utc' in df_executed_trades.columns:\n",
    "        df_executed_trades_sorted = df_executed_trades.sort_values(by='decision_timestamp_utc')\n",
    "        df_executed_trades_sorted['cumulative_pnl_usd'] = df_executed_trades_sorted['pnl_cents'].cumsum() / 100\n",
    "        \n",
    "        plt.figure(figsize=(12, 6))\n",
    "        plt.plot(df_executed_trades_sorted['decision_timestamp_utc'], df_executed_trades_sorted['cumulative_pnl_usd'])\n",
    "        plt.title('Cumulative P&L Over Time (Executed Trades)')\n",
    "        plt.xlabel('Time')\n",
    "        plt.ylabel('Cumulative P&L (USD)')\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(\"Skipping cumulative P&L plot as 'decision_timestamp_utc' is missing or trades are empty.\")\n",
    "else:\n",
    "    print(\"No executed trades to analyze for overall performance.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Analysis of Model Probabilities and Edge\n",
    "\n",
    "if not df_all_decisions.empty:\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.histplot(df_all_decisions['predicted_proba_yes'].dropna(), bins=50, kde=False, label='All Decisions P(YES)')\n",
    "    if not df_executed_trades.empty:\n",
    "        sns.histplot(df_executed_trades['predicted_proba_yes'].dropna(), bins=50, kde=False, color='red', alpha=0.7, label='Executed Trades P(YES)')\n",
    "    plt.title('Distribution of Model Predicted P(YES)')\n",
    "    plt.xlabel('Predicted P(YES)')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    print(\"\\nDescriptive statistics for predicted_proba_yes (All Decisions):\")\n",
    "    print(df_all_decisions['predicted_proba_yes'].describe())\n",
    "    \n",
    "    if not df_executed_trades.empty:\n",
    "        print(\"\\nDescriptive statistics for predicted_proba_yes (Executed Trades):\")\n",
    "        print(df_executed_trades['predicted_proba_yes'].describe())\n",
    "\n",
    "    edge_cols_exist = all(col in df_all_decisions.columns for col in ['edge_for_yes', 'edge_for_no'])\n",
    "    if edge_cols_exist:\n",
    "        plt.figure(figsize=(14, 6))\n",
    "        plt.subplot(1, 2, 1)\n",
    "        sns.histplot(df_all_decisions['edge_for_yes'].dropna(), bins=50, kde=False, label='Edge for YES')\n",
    "        if not df_executed_trades.empty and not df_executed_trades[df_executed_trades['executed_trade_action'] == 'BUY_YES'].empty: # Check if df is not empty\n",
    "             sns.histplot(df_executed_trades[df_executed_trades['executed_trade_action'] == 'BUY_YES']['edge_for_yes'].dropna(), \n",
    "                          bins=20, kde=False, color='green', alpha=0.7, label='Executed BUY_YES Edge')\n",
    "        plt.title('Distribution of Edge for YES')\n",
    "        plt.xlabel('Edge (P_model - P_market_ask)')\n",
    "        # Use the variable defined in Cell 1\n",
    "        plt.axvline(STRATEGY_EDGE_THRESHOLD_FOR_TRADE, color='r', linestyle='--', label=f'Edge Threshold ({STRATEGY_EDGE_THRESHOLD_FOR_TRADE})')\n",
    "        plt.legend()\n",
    "\n",
    "        plt.subplot(1, 2, 2)\n",
    "        sns.histplot(df_all_decisions['edge_for_no'].dropna(), bins=50, kde=False, label='Edge for NO')\n",
    "        if not df_executed_trades.empty and not df_executed_trades[df_executed_trades['executed_trade_action'] == 'BUY_NO'].empty: # Check if df is not empty\n",
    "            sns.histplot(df_executed_trades[df_executed_trades['executed_trade_action'] == 'BUY_NO']['edge_for_no'].dropna(), \n",
    "                         bins=20, kde=False, color='orange', alpha=0.7, label='Executed BUY_NO Edge')\n",
    "        plt.title('Distribution of Edge for NO')\n",
    "        plt.xlabel('Edge (P_model_no - P_market_no_bid)')\n",
    "        # Use the variable defined in Cell 1\n",
    "        plt.axvline(STRATEGY_EDGE_THRESHOLD_FOR_TRADE, color='r', linestyle='--', label=f'Edge Threshold ({STRATEGY_EDGE_THRESHOLD_FOR_TRADE})')\n",
    "        plt.legend()\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "        print(\"\\nDescriptive statistics for edge_for_yes (All Decisions):\")\n",
    "        print(df_all_decisions['edge_for_yes'].describe())\n",
    "        print(\"\\nDescriptive statistics for edge_for_no (All Decisions):\")\n",
    "        print(df_all_decisions['edge_for_no'].describe())\n",
    "        \n",
    "        if not df_executed_trades.empty:\n",
    "            if not df_executed_trades[df_executed_trades['executed_trade_action'] == 'BUY_YES'].empty:\n",
    "                print(\"\\nDescriptive statistics for edge_for_yes (Executed BUY_YES Trades):\")\n",
    "                print(df_executed_trades[df_executed_trades['executed_trade_action'] == 'BUY_YES']['edge_for_yes'].describe())\n",
    "            else:\n",
    "                print(\"\\nNo BUY_YES trades executed to describe edge for.\")\n",
    "            \n",
    "            if not df_executed_trades[df_executed_trades['executed_trade_action'] == 'BUY_NO'].empty:\n",
    "                print(\"\\nDescriptive statistics for edge_for_no (Executed BUY_NO Trades):\")\n",
    "                print(df_executed_trades[df_executed_trades['executed_trade_action'] == 'BUY_NO']['edge_for_no'].describe())\n",
    "            else:\n",
    "                print(\"\\nNo BUY_NO trades executed to describe edge for.\")\n",
    "            \n",
    "    else:\n",
    "        print(\"\\nEdge columns ('edge_for_yes', 'edge_for_no') not found in df_all_decisions. Ensure decision_eval_logs were merged correctly in Cell 1.\")\n",
    "\n",
    "else:\n",
    "    print(\"No data in df_all_decisions for probability/edge analysis.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Analysis of Trade Reasons and Market Conditions\n",
    "\n",
    "if not df_all_decisions.empty:\n",
    "    print(\"\\n--- Analysis of Non-Executed Decisions ---\")\n",
    "    # executed_trade_action column in df_all_decisions will have reasons like 'NO_TRADE_THRESHOLD_NOT_MET' etc.\n",
    "    # from the main trades log.\n",
    "    # The 'considered_action' from df_eval_details (now merged) is more granular for the initial model output.\n",
    "    \n",
    "    if 'considered_action' in df_all_decisions.columns:\n",
    "        print(\"\\nBreakdown of 'considered_action' (from detailed eval logs):\")\n",
    "        print(df_all_decisions['considered_action'].value_counts(normalize=True) * 100)\n",
    "    \n",
    "    print(\"\\nBreakdown of 'executed_trade_action' (final outcome in main log):\")\n",
    "    print(df_all_decisions['executed_trade_action'].value_counts(normalize=True) * 100)\n",
    "\n",
    "\n",
    "    if not df_executed_trades.empty:\n",
    "        print(\"\\n--- Analysis of Executed Trades ---\")\n",
    "        # When are trades being made in terms of time_until_market_close_min?\n",
    "        # This requires 'time_until_market_close_min' to be in your features CSV and loaded into df_all_decisions\n",
    "        # If it was part of feature_vector_series, it would be a column if your training features CSV included it.\n",
    "        # For this, we might need to re-extract it or ensure it's in the original CSV.\n",
    "        # Let's assume 'decision_timestamp_utc' and 'market_close_time_iso' (from merge if needed) are available.\n",
    "        \n",
    "        # To get time_until_market_close_min for executed trades, we need market_close_time_iso\n",
    "        # This would typically come from merging with an outcomes file or being part of the feature set.\n",
    "        # For simplicity, let's analyze by hour of day for now.\n",
    "        \n",
    "        df_executed_trades['hour_of_day'] = df_executed_trades['decision_timestamp_utc'].dt.hour\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        sns.countplot(data=df_executed_trades, x='hour_of_day', hue='executed_trade_action')\n",
    "        plt.title('Number of Executed Trades by Hour of Day (UTC)')\n",
    "        plt.show()\n",
    "\n",
    "        # P&L vs. Predicted Probability\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        # For BUY_YES trades\n",
    "        buy_yes_trades = df_executed_trades[df_executed_trades['executed_trade_action'] == 'BUY_YES']\n",
    "        if not buy_yes_trades.empty:\n",
    "            sns.scatterplot(data=buy_yes_trades, x='predicted_proba_yes', y='pnl_cents', alpha=0.5, label='BUY_YES')\n",
    "        \n",
    "        # For BUY_NO trades (plot against P(NO) = 1 - P(YES) for consistency on x-axis)\n",
    "        buy_no_trades = df_executed_trades[df_executed_trades['executed_trade_action'] == 'BUY_NO'].copy()\n",
    "        if not buy_no_trades.empty:\n",
    "            buy_no_trades['predicted_proba_no'] = 1 - buy_no_trades['predicted_proba_yes']\n",
    "            # To plot on same P(YES) scale, let's use P(YES) for x-axis for NO trades too.\n",
    "            # Their PNL is based on P(NO) being correct.\n",
    "            sns.scatterplot(data=buy_no_trades, x='predicted_proba_yes', y='pnl_cents', alpha=0.5, label='BUY_NO (P(YES) shown)', marker='x')\n",
    "\n",
    "        plt.title('P&L vs. Model Predicted P(YES) for Executed Trades')\n",
    "        plt.xlabel('Model Predicted P(YES)')\n",
    "        plt.ylabel('P&L (cents)')\n",
    "        plt.axhline(0, color='grey', linestyle='--')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "        # If edge columns exist, plot P&L vs Edge\n",
    "        if edge_cols_exist:\n",
    "            plt.figure(figsize=(14, 6))\n",
    "            plt.subplot(1,2,1)\n",
    "            if not buy_yes_trades.empty:\n",
    "                sns.scatterplot(data=buy_yes_trades, x='edge_for_yes', y='pnl_cents', alpha=0.5)\n",
    "            plt.title('BUY_YES: P&L vs. Edge for Yes')\n",
    "            plt.xlabel('Edge for YES')\n",
    "            plt.ylabel('P&L (cents)')\n",
    "            plt.axhline(0, color='grey', linestyle='--')\n",
    "\n",
    "            plt.subplot(1,2,2)\n",
    "            if not buy_no_trades.empty:\n",
    "                 sns.scatterplot(data=buy_no_trades, x='edge_for_no', y='pnl_cents', alpha=0.5)\n",
    "            plt.title('BUY_NO: P&L vs. Edge for No')\n",
    "            plt.xlabel('Edge for NO')\n",
    "            plt.ylabel('P&L (cents)')\n",
    "            plt.axhline(0, color='grey', linestyle='--')\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "\n",
    "    else:\n",
    "        print(\"No executed trades to analyze for market conditions.\")\n",
    "else:\n",
    "    print(\"df_all_decisions is empty. Cannot perform further EDA.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Focus on Losing Trades\n",
    "\n",
    "if not df_executed_trades.empty:\n",
    "    df_losing_trades = df_executed_trades[df_executed_trades['pnl_cents'] < 0].copy()\n",
    "    print(f\"\\n--- Analysis of {len(df_losing_trades)} Losing Trades ---\")\n",
    "\n",
    "    if not df_losing_trades.empty:\n",
    "        print(\"Breakdown of Losing Trades by Action:\")\n",
    "        print(df_losing_trades['executed_trade_action'].value_counts())\n",
    "\n",
    "        print(\"\\nDescriptive Stats for P(YES) in Losing Trades:\")\n",
    "        print(df_losing_trades['predicted_proba_yes'].describe())\n",
    "        \n",
    "        if edge_cols_exist:\n",
    "            print(\"\\nDescriptive Stats for Edge (YES) in Losing BUY_YES Trades:\")\n",
    "            print(df_losing_trades[df_losing_trades['executed_trade_action']=='BUY_YES']['edge_for_yes'].describe())\n",
    "            print(\"\\nDescriptive Stats for Edge (NO) in Losing BUY_NO Trades:\")\n",
    "            print(df_losing_trades[df_losing_trades['executed_trade_action']=='BUY_NO']['edge_for_no'].describe())\n",
    "\n",
    "\n",
    "        # Plot P(chosen side) for losing trades\n",
    "        df_losing_trades['prob_chosen_side_for_loss'] = df_losing_trades['model_prob_chosen_side']\n",
    "        \n",
    "        plt.figure(figsize=(10,6))\n",
    "        sns.histplot(data=df_losing_trades, x='prob_chosen_side_for_loss', hue='executed_trade_action', bins=30, kde=True)\n",
    "        plt.title('Distribution of Model Probability for Chosen Side (Losing Trades)')\n",
    "        plt.xlabel('Model P(Chosen Side)')\n",
    "        plt.show()\n",
    "        \n",
    "        # What was the actual outcome when we lost?\n",
    "        print(\"\\nActual Outcomes for Losing Trades:\")\n",
    "        print(pd.crosstab(df_losing_trades['executed_trade_action'], df_losing_trades['actual_market_result']))\n",
    "        \n",
    "        # Display some examples of large losses\n",
    "        print(\"\\nExamples of Large Losing Trades (Top 10 by Loss Amount):\")\n",
    "        print(df_losing_trades.sort_values(by='pnl_cents').head(10)[\n",
    "            ['decision_timestamp_utc', 'market_ticker', 'executed_trade_action', 'predicted_proba_yes', 'model_prob_chosen_side', 'simulated_entry_price_cents', 'actual_market_result', 'pnl_cents']\n",
    "        ].to_string())\n",
    "\n",
    "    else:\n",
    "        print(\"No losing trades to analyze.\")\n",
    "else:\n",
    "    print(\"No executed trades to analyze for losses.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: Detailed Analysis of P(YES) Buckets\n",
    "\n",
    "if not df_all_decisions.empty and 'predicted_proba_yes' in df_all_decisions.columns:\n",
    "    print(\"\\n--- Analysis of P(YES) Buckets (All Decisions) ---\")\n",
    "    \n",
    "    bins = [0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.55, 0.6, 0.65, 0.70, 0.75, 0.80, 0.85, 0.9, 0.95, 1.01] \n",
    "    labels = [f\"{bins[i]:.2f}-{bins[i+1]:.2f}\" for i in range(len(bins)-1)]\n",
    "    df_all_decisions['proba_yes_bucket'] = pd.cut(df_all_decisions['predicted_proba_yes'], bins=bins, labels=labels, right=False, include_lowest=True)\n",
    "\n",
    "    bucket_analysis = df_all_decisions.groupby('proba_yes_bucket', observed=False).agg(\n",
    "        total_decisions=('actual_market_result', 'count'),\n",
    "        actual_yes_outcomes=('actual_market_result', lambda x: (x == 'yes').sum())\n",
    "    )\n",
    "    bucket_analysis['empirical_p_yes'] = bucket_analysis['actual_yes_outcomes'] / bucket_analysis['total_decisions']\n",
    "    bucket_analysis['avg_predicted_p_yes'] = df_all_decisions.groupby('proba_yes_bucket', observed=False)['predicted_proba_yes'].mean()\n",
    "\n",
    "    # Handle potential NaN results from division by zero if a bucket has no decisions\n",
    "    bucket_analysis.fillna(0, inplace=True)\n",
    "\n",
    "    print(\"\\nModel P(YES) vs. Empirical P(YES) in Backtest Data:\")\n",
    "    print(bucket_analysis)\n",
    "\n",
    "    plt.figure(figsize=(12, 7))\n",
    "    ax1 = bucket_analysis['avg_predicted_p_yes'].plot(kind='bar', alpha=0.7, label='Avg. Model P(YES) in Bucket', color='skyblue')\n",
    "    ax2 = bucket_analysis['empirical_p_yes'].plot(kind='line', marker='o', linewidth=2, label='Empirical P(YES) in Bucket', color='red', secondary_y=False, ax=ax1) # Plot on same y-axis\n",
    "    \n",
    "    # Add y=x line for perfect calibration\n",
    "    lims = [\n",
    "        np.min([ax1.get_xlim(), ax1.get_ylim()]),  # min of both axes\n",
    "        np.max([ax1.get_xlim(), ax1.get_ylim()]),  # max of both axes\n",
    "    ]\n",
    "    ax1.plot(lims, lims, 'k--', alpha=0.75, zorder=0, label='Perfect Calibration')\n",
    "\n",
    "\n",
    "    plt.title('Model P(YES) vs. Empirical P(YES) by Predicted Probability Bucket')\n",
    "    plt.xlabel('Predicted P(YES) Bucket by Model')\n",
    "    plt.ylabel('Probability')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    ax1.legend(loc='upper left')\n",
    "    # ax2.legend(loc='upper right') # Not needed if plotted on same axis\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    if not df_executed_trades.empty and 'predicted_proba_yes' in df_executed_trades.columns:\n",
    "        actionable_min_prob = df_executed_trades['predicted_proba_yes'].min()\n",
    "        actionable_max_prob = df_executed_trades['predicted_proba_yes'].max()\n",
    "        print(f\"\\nExecuted trades occurred in P(YES) range: [{actionable_min_prob:.4f} - {actionable_max_prob:.4f}]\")\n",
    "        \n",
    "        # Filter buckets based on the range of executed trades\n",
    "        # Accessing CategoricalIndex interval properties\n",
    "        if isinstance(bucket_analysis.index, pd.CategoricalIndex) and isinstance(bucket_analysis.index.categories, pd.IntervalIndex):\n",
    "            actionable_bucket_data = bucket_analysis[\n",
    "                (bucket_analysis.index.categories.left >= actionable_min_prob*0.95) & \n",
    "                (bucket_analysis.index.categories.right <= actionable_max_prob*1.05)\n",
    "            ]\n",
    "            if not actionable_bucket_data.empty:\n",
    "                print(\"\\nCalibration in Actionable Range (approximate):\")\n",
    "                print(actionable_bucket_data)\n",
    "            else:\n",
    "                print(f\"No buckets fully within the approximate actionable range based on current binning.\")\n",
    "        else:\n",
    "            print(\"Could not perform actionable range analysis due to unexpected index type for buckets.\")\n",
    "            \n",
    "else:\n",
    "    print(\"df_all_decisions is empty or 'predicted_proba_yes' column is missing for bucket analysis.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: Feature Analysis for Specific Trade Outcomes\n",
    "\n",
    "if not df_all_decisions.empty and not df_executed_trades.empty:\n",
    "    # --- Compare features of Losing BUY_YES vs. Winning BUY_YES (if any) ---\n",
    "    losing_buy_yes = df_executed_trades[(df_executed_trades['executed_trade_action'] == 'BUY_YES') & (df_executed_trades['pnl_cents'] < 0)]\n",
    "    winning_buy_yes = df_executed_trades[(df_executed_trades['executed_trade_action'] == 'BUY_YES') & (df_executed_trades['pnl_cents'] > 0)]\n",
    "\n",
    "    if not losing_buy_yes.empty:\n",
    "        print(f\"\\n--- Losing BUY_YES Trades ({len(losing_buy_yes)}) ---\")\n",
    "        print(\"Losing BUY_YES - P(YES) stats:\")\n",
    "        print(losing_buy_yes['predicted_proba_yes'].describe())\n",
    "        if 'edge_for_yes' in losing_buy_yes.columns:\n",
    "            print(\"Losing BUY_YES - Edge for YES stats:\")\n",
    "            print(losing_buy_yes['edge_for_yes'].describe())\n",
    "            \n",
    "        if 'kalshi_yes_ask_at_decision_t' in losing_buy_yes.columns:\n",
    "            plt.figure(figsize=(8,5))\n",
    "            sns.histplot(losing_buy_yes['kalshi_yes_ask_at_decision_t'].dropna(), bins=20, kde=True)\n",
    "            plt.title('Kalshi YES Ask Price for Losing BUY_YES Trades')\n",
    "            plt.xlabel('YES Ask (cents)')\n",
    "            plt.show()\n",
    "\n",
    "    if not winning_buy_yes.empty:\n",
    "        print(f\"\\n--- Winning BUY_YES Trades ({len(winning_buy_yes)}) ---\")\n",
    "        print(\"Winning BUY_YES - P(YES) stats:\")\n",
    "        print(winning_buy_yes['predicted_proba_yes'].describe())\n",
    "        if 'edge_for_yes' in winning_buy_yes.columns:\n",
    "            print(\"Winning BUY_YES - Edge for YES stats:\")\n",
    "            print(winning_buy_yes['edge_for_yes'].describe())\n",
    "            \n",
    "        if 'kalshi_yes_ask_at_decision_t' in winning_buy_yes.columns:\n",
    "            plt.figure(figsize=(8,5))\n",
    "            sns.histplot(winning_buy_yes['kalshi_yes_ask_at_decision_t'].dropna(), bins=20, kde=True, color='green')\n",
    "            plt.title('Kalshi YES Ask Price for Winning BUY_YES Trades')\n",
    "            plt.xlabel('YES Ask (cents)')\n",
    "            plt.show()\n",
    "    else:\n",
    "        print(\"\\nNo winning BUY_YES trades found in this backtest period.\")\n",
    "        \n",
    "    # --- Compare high P(YES) predictions that resolved YES vs. NO ---\n",
    "    # Use the variable defined in Cell 1\n",
    "    high_conf_yes_preds = df_all_decisions[df_all_decisions['predicted_proba_yes'] > STRATEGY_MIN_MODEL_PROB_FOR_CONSIDERATION].copy()\n",
    "    \n",
    "    if not high_conf_yes_preds.empty:\n",
    "        print(f\"\\n--- Decisions where model predicted P(YES) > {STRATEGY_MIN_MODEL_PROB_FOR_CONSIDERATION} ({len(high_conf_yes_preds)}) ---\")\n",
    "        \n",
    "        # Ensure 'proba_yes_bucket' is available for crosstab\n",
    "        if 'proba_yes_bucket' not in high_conf_yes_preds.columns and 'predicted_proba_yes' in high_conf_yes_preds.columns:\n",
    "            # Re-apply binning if needed (bins/labels should be defined from Cell 6 or redefined here)\n",
    "            bins_cell7 = [0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.55, 0.6, 0.65, 0.70, 0.75, 0.80, 0.85, 0.9, 0.95, 1.01] \n",
    "            labels_cell7 = [f\"{bins_cell7[i]:.2f}-{bins_cell7[i+1]:.2f}\" for i in range(len(bins_cell7)-1)]\n",
    "            high_conf_yes_preds['proba_yes_bucket'] = pd.cut(high_conf_yes_preds['predicted_proba_yes'], bins=bins_cell7, labels=labels_cell7, right=False, include_lowest=True)\n",
    "\n",
    "\n",
    "        if 'proba_yes_bucket' in high_conf_yes_preds.columns:\n",
    "            actual_outcomes_for_high_conf_yes = pd.crosstab(high_conf_yes_preds['proba_yes_bucket'], high_conf_yes_preds['actual_market_result'], dropna=False)\n",
    "            print(\"Actual outcomes when model was confident YES (by P(YES) bucket):\")\n",
    "            print(actual_outcomes_for_high_conf_yes)\n",
    "        else:\n",
    "            print(\"Cannot create crosstab: 'proba_yes_bucket' missing from high_conf_yes_preds.\")\n",
    "            \n",
    "    else:\n",
    "        print(f\"No decisions found where model predicted P(YES) > {STRATEGY_MIN_MODEL_PROB_FOR_CONSIDERATION}\")\n",
    "\n",
    "else:\n",
    "    print(\"df_all_decisions or df_executed_trades is empty for detailed feature analysis.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
