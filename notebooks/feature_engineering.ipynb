{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-19 12:06:49,374 - INFO - feature_engineering_20250519_120649.<module>:45 - Using Kalshi NTM outcomes CSV: kalshi_data/kalshi_btc_hourly_NTM_filtered_market_outcomes_20250519_014250.csv\n",
      "2025-05-19 12:06:49,374 - INFO - feature_engineering_20250519_120649.<module>:72 - Feature Engineering Setup Complete.\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Imports and Setup\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from pathlib import Path\n",
    "import datetime as dt\n",
    "from datetime import timezone, timedelta\n",
    "import re\n",
    "from tqdm.notebook import tqdm\n",
    "import logging\n",
    "# For TA features (optional, install if needed: pip install ta)\n",
    "# import ta \n",
    "\n",
    "# --- Logging Setup ---\n",
    "logger_name = f\"feature_engineering_{dt.datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
    "logger = logging.getLogger(logger_name)\n",
    "if not logger.handlers:\n",
    "    logger.setLevel(logging.INFO)\n",
    "    formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(name)s.%(funcName)s:%(lineno)d - %(message)s')\n",
    "    ch = logging.StreamHandler()\n",
    "    ch.setFormatter(formatter)\n",
    "    logger.addHandler(ch)\n",
    "else:\n",
    "    logger.setLevel(logging.INFO)\n",
    "\n",
    "# --- Configuration ---\n",
    "# Paths to your data directories (adjust if your notebook is not in the 'notebooks' folder)\n",
    "BASE_PROJECT_DIR = Path.cwd() # Assumes notebook is in 'notebooks' directory, and data is relative to project root\n",
    "# If notebook is in ./notebooks/ and data is in ./kalshi_data/ and ./binance_data/\n",
    "# then Path.cwd().parent would be the project root.\n",
    "# For simplicity, let's assume data directories are directly accessible or paths are adjusted.\n",
    "\n",
    "# KALSHI_NTM_DATA_DIR = Path.cwd().parent / \"kalshi_data\" # Example if notebook is in 'notebooks'\n",
    "# BINANCE_FLAT_DATA_DIR = Path.cwd().parent / \"binance_data\" # Example for flat Binance CSVs\n",
    "KALSHI_NTM_DATA_DIR = Path(\"./kalshi_data\") # If kalshi_data is in the same dir as notebook or ./notebooks/kalshi_data\n",
    "BINANCE_FLAT_DATA_DIR = Path(\"./binance_data\") # If binance_data is in the same dir or ./notebooks/binance_data\n",
    "\n",
    "# Find the latest outcomes CSV\n",
    "try:\n",
    "    outcomes_files = list(KALSHI_NTM_DATA_DIR.glob(\"kalshi_btc_hourly_NTM_filtered_market_outcomes_*.csv\"))\n",
    "    if not outcomes_files:\n",
    "        raise FileNotFoundError(\"No NTM outcomes CSV found in KALSHI_NTM_DATA_DIR.\")\n",
    "    KALSHI_OUTCOMES_CSV_PATH = max(outcomes_files, key=os.path.getctime)\n",
    "    logger.info(f\"Using Kalshi NTM outcomes CSV: {KALSHI_OUTCOMES_CSV_PATH}\")\n",
    "except FileNotFoundError as e:\n",
    "    logger.critical(str(e))\n",
    "    KALSHI_OUTCOMES_CSV_PATH = None # Handle this in loading\n",
    "except Exception as e:\n",
    "    logger.critical(f\"Error finding outcomes CSV: {e}\")\n",
    "    KALSHI_OUTCOMES_CSV_PATH = None\n",
    "\n",
    "# --- Parameters for Feature Engineering ---\n",
    "# For BTC features\n",
    "BTC_MOMENTUM_WINDOWS = [5, 10, 15, 30] # In minutes\n",
    "BTC_VOLATILITY_WINDOW = 15 # In minutes\n",
    "BTC_SMA_WINDOWS = [10, 30] # Short and long SMA\n",
    "BTC_EMA_WINDOWS = [12, 26] # For MACD-like features or direct EMA\n",
    "BTC_RSI_WINDOW = 14\n",
    "\n",
    "# For Kalshi features\n",
    "KALSHI_PRICE_CHANGE_WINDOWS = [1, 3, 5] # In minutes, for changes in bid/ask/mid\n",
    "\n",
    "# Decision point: How many minutes before Kalshi market close do we make a prediction?\n",
    "# Or, iterate every minute? For now, let's aim for a fixed offset.\n",
    "# This matches the backtest logic.\n",
    "DECISION_OFFSET_MINUTES_BEFORE_CLOSE = 5 \n",
    "\n",
    "# How far back from the decision point do we look for Kalshi data (staleness)?\n",
    "KALSHI_MAX_STALENESS_SECONDS = 120 # 2 minutes\n",
    "\n",
    "logger.info(\"Feature Engineering Setup Complete.\")\n",
    "if not KALSHI_OUTCOMES_CSV_PATH:\n",
    "    logger.warning(\"KALSHI_OUTCOMES_CSV_PATH is not set. Data loading will likely fail.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-19 12:06:52,682 - INFO - feature_engineering_20250519_120649.<module>:6 - Loaded 9192 NTM market outcomes from kalshi_data/kalshi_btc_hourly_NTM_filtered_market_outcomes_20250519_014250.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-19 12:06:52,690 - INFO - feature_engineering_20250519_120649.<module>:18 - Outcomes DataFrame shape after initial cleaning: (9192, 8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outcomes DataFrame head:\n",
      "                 market_ticker result event_resolution_time_iso  \\\n",
      "0  KXBTCD-25MAY1522-T106249.99     no 2025-05-16 02:00:00+00:00   \n",
      "1  KXBTCD-25MAY1522-T105999.99     no 2025-05-16 02:00:00+00:00   \n",
      "2  KXBTCD-25MAY1522-T105749.99     no 2025-05-16 02:00:00+00:00   \n",
      "3  KXBTCD-25MAY1522-T105499.99     no 2025-05-16 02:00:00+00:00   \n",
      "4  KXBTCD-25MAY1522-T105249.99     no 2025-05-16 02:00:00+00:00   \n",
      "\n",
      "   reference_btc_price_for_ntm  kalshi_strike_price      market_open_time_iso  \\\n",
      "0                     103709.1            106249.99 2025-05-16 01:00:00+00:00   \n",
      "1                     103709.1            105999.99 2025-05-16 01:00:00+00:00   \n",
      "2                     103709.1            105749.99 2025-05-16 01:00:00+00:00   \n",
      "3                     103709.1            105499.99 2025-05-16 01:00:00+00:00   \n",
      "4                     103709.1            105249.99 2025-05-16 01:00:00+00:00   \n",
      "\n",
      "      market_close_time_iso event_ticker_parent  \n",
      "0 2025-05-16 02:00:00+00:00    KXBTCD-25MAY1522  \n",
      "1 2025-05-16 02:00:00+00:00    KXBTCD-25MAY1522  \n",
      "2 2025-05-16 02:00:00+00:00    KXBTCD-25MAY1522  \n",
      "3 2025-05-16 02:00:00+00:00    KXBTCD-25MAY1522  \n",
      "4 2025-05-16 02:00:00+00:00    KXBTCD-25MAY1522  \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38675fc9265f43b7a53a9080004f958c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching BTC price at resolution for target:   0%|          | 0/9192 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-19 12:06:53,076 - INFO - feature_engineering_20250519_120649.<module>:107 - Dropped 0 rows due to missing BTC price at resolution for target calculation.\n",
      "2025-05-19 12:06:53,076 - INFO - feature_engineering_20250519_120649.<module>:109 - Target variable 'target_btc_diff_from_strike' calculated for 9192 markets.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Outcomes DataFrame with target variable (head):\n",
      "                 market_ticker  kalshi_strike_price event_resolution_time_iso  \\\n",
      "0  KXBTCD-25MAY1522-T106249.99            106249.99 2025-05-16 02:00:00+00:00   \n",
      "1  KXBTCD-25MAY1522-T105999.99            105999.99 2025-05-16 02:00:00+00:00   \n",
      "2  KXBTCD-25MAY1522-T105749.99            105749.99 2025-05-16 02:00:00+00:00   \n",
      "3  KXBTCD-25MAY1522-T105499.99            105499.99 2025-05-16 02:00:00+00:00   \n",
      "4  KXBTCD-25MAY1522-T105249.99            105249.99 2025-05-16 02:00:00+00:00   \n",
      "\n",
      "   btc_price_at_resolution  target_btc_diff_from_strike  \n",
      "0                 104238.1                     -2011.89  \n",
      "1                 104238.1                     -1761.89  \n",
      "2                 104238.1                     -1511.89  \n",
      "3                 104238.1                     -1261.89  \n",
      "4                 104238.1                     -1011.89  \n",
      "\n",
      "Target variable statistics:\n",
      "count    9192.000000\n",
      "mean       21.333182\n",
      "std      1434.677324\n",
      "min     -3932.710000\n",
      "25%     -1164.980000\n",
      "50%        24.010000\n",
      "75%      1206.402500\n",
      "max      4250.510000\n",
      "Name: target_btc_diff_from_strike, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Load Kalshi Outcomes and Define Target Variable\n",
    "\n",
    "if KALSHI_OUTCOMES_CSV_PATH and KALSHI_OUTCOMES_CSV_PATH.exists():\n",
    "    try:\n",
    "        df_outcomes = pd.read_csv(KALSHI_OUTCOMES_CSV_PATH)\n",
    "        logger.info(f\"Loaded {len(df_outcomes)} NTM market outcomes from {KALSHI_OUTCOMES_CSV_PATH}\")\n",
    "        \n",
    "        # Convert relevant columns to correct types\n",
    "        df_outcomes['event_resolution_time_iso'] = pd.to_datetime(df_outcomes['event_resolution_time_iso'], errors='coerce', utc=True)\n",
    "        df_outcomes['market_open_time_iso'] = pd.to_datetime(df_outcomes['market_open_time_iso'], errors='coerce', utc=True)\n",
    "        df_outcomes['market_close_time_iso'] = pd.to_datetime(df_outcomes['market_close_time_iso'], errors='coerce', utc=True)\n",
    "        \n",
    "        # Drop rows where essential date conversions failed or key info is missing\n",
    "        df_outcomes.dropna(subset=['market_ticker', 'event_resolution_time_iso', \n",
    "                                   'market_open_time_iso', 'market_close_time_iso',\n",
    "                                   'kalshi_strike_price'], inplace=True)\n",
    "        \n",
    "        logger.info(f\"Outcomes DataFrame shape after initial cleaning: {df_outcomes.shape}\")\n",
    "        print(\"Outcomes DataFrame head:\")\n",
    "        print(df_outcomes.head())\n",
    "    except Exception as e:\n",
    "        logger.critical(f\"Error loading or processing outcomes CSV {KALSHI_OUTCOMES_CSV_PATH}: {e}\")\n",
    "        df_outcomes = pd.DataFrame() # Empty df if load fails\n",
    "else:\n",
    "    logger.critical(\"Kalshi NTM outcomes CSV path not found or not set. Cannot proceed.\")\n",
    "    df_outcomes = pd.DataFrame()\n",
    "\n",
    "# --- Define Target Variable: BTC_price_at_resolution - kalshi_strike_price ---\n",
    "# We need the actual BTC price at the Kalshi event_resolution_time_iso.\n",
    "# This requires loading Binance data for the resolution time of each market.\n",
    "\n",
    "# Create a cache for daily Binance data to avoid reloading the same day multiple times\n",
    "_binance_daily_data_cache_for_target = {}\n",
    "\n",
    "def get_btc_price_at_resolution(resolution_dt_utc: pd.Timestamp) -> float | None:\n",
    "    \"\"\"\n",
    "    Fetches the BTC closing price from the 1-minute candle that contains or immediately precedes\n",
    "    the Kalshi market's resolution_dt_utc.\n",
    "    \"\"\"\n",
    "    if pd.isna(resolution_dt_utc):\n",
    "        return None\n",
    "        \n",
    "    global _binance_daily_data_cache_for_target\n",
    "    date_str = resolution_dt_utc.strftime(\"%Y-%m-%d\")\n",
    "    \n",
    "    if date_str not in _binance_daily_data_cache_for_target:\n",
    "        filepath = BINANCE_FLAT_DATA_DIR / f\"BTCUSDT-1m-{date_str}.csv\"\n",
    "        if not filepath.exists():\n",
    "            logger.warning(f\"Target: Binance data file not found for {date_str} at {filepath}\")\n",
    "            _binance_daily_data_cache_for_target[date_str] = None # Mark as tried\n",
    "            return None\n",
    "        try:\n",
    "            column_names = [\"open_time_raw\", \"open\", \"high\", \"low\", \"close\", \"volume\",\n",
    "                            \"close_time_ms\", \"quote_asset_volume\", \"number_of_trades\",\n",
    "                            \"taker_buy_base_asset_volume\", \"taker_buy_quote_asset_volume\", \"ignore\"]\n",
    "            df_binance_day = pd.read_csv(filepath, header=None, names=column_names)\n",
    "            df_binance_day['timestamp_s'] = df_binance_day['open_time_raw'] // 1_000_000\n",
    "            df_binance_day.set_index('timestamp_s', inplace=True)\n",
    "            df_binance_day['close'] = pd.to_numeric(df_binance_day['close'])\n",
    "            _binance_daily_data_cache_for_target[date_str] = df_binance_day\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Target: Error loading Binance data from {filepath}: {e}\")\n",
    "            _binance_daily_data_cache_for_target[date_str] = None\n",
    "            return None\n",
    "            \n",
    "    df_binance_day_cached = _binance_daily_data_cache_for_target[date_str]\n",
    "    if df_binance_day_cached is None:\n",
    "        return None\n",
    "\n",
    "    # Find the candle whose open_time_s <= resolution_timestamp_s < next_candle_open_time_s\n",
    "    resolution_timestamp_s = int(resolution_dt_utc.timestamp())\n",
    "    \n",
    "    # searchsorted finds where resolution_timestamp_s would be inserted to maintain order.\n",
    "    # 'right' means if resolution_timestamp_s is an exact match, it gives the index AFTER the match.\n",
    "    # So, the relevant candle is at index position - 1.\n",
    "    idx_pos = df_binance_day_cached.index.searchsorted(resolution_timestamp_s, side='right')\n",
    "    \n",
    "    if idx_pos == 0:\n",
    "        # Resolution time is before the first candle of the day. This might happen if\n",
    "        # resolution is exactly at 00:00:00 UTC and our timestamp logic is off by a bit,\n",
    "        # or data for the day is missing its first minute.\n",
    "        # Try to get last candle of previous day.\n",
    "        prev_day_dt = resolution_dt_utc.date() - timedelta(days=1)\n",
    "        prev_day_str = prev_day_dt.strftime(\"%Y-%m-%d\")\n",
    "        # logger.debug(f\"Resolution {resolution_dt_utc.isoformat()} at start of day {date_str}, trying previous day {prev_day_str} for target.\")\n",
    "        # Recursively call, but prevent infinite loop with a depth counter or by ensuring it only goes back once.\n",
    "        # For simplicity here, just return None if it's at the very start. A more robust solution may be needed.\n",
    "        if resolution_dt_utc.time() < dt.time(0,1,0): # If within first minute of UTC day\n",
    "             logger.warning(f\"Target: Resolution time {resolution_dt_utc.isoformat()} is too early in {date_str}, BTC price might be from previous day or ambiguous. Skipping.\")\n",
    "        return None # Or attempt to load previous day's last minute\n",
    "        \n",
    "    btc_price_at_resolution = df_binance_day_cached.iloc[idx_pos - 1]['close']\n",
    "    # actual_candle_ts = df_binance_day_cached.index[idx_pos - 1]\n",
    "    # logger.debug(f\"Target: For resolution {resolution_dt_utc.isoformat()} ({resolution_timestamp_s}), BTC price is {btc_price_at_resolution} from candle at {actual_candle_ts}\")\n",
    "    return float(btc_price_at_resolution)\n",
    "\n",
    "if not df_outcomes.empty:\n",
    "    tqdm.pandas(desc=\"Fetching BTC price at resolution for target\")\n",
    "    df_outcomes['btc_price_at_resolution'] = df_outcomes['event_resolution_time_iso'].progress_apply(get_btc_price_at_resolution)\n",
    "    \n",
    "    # Calculate the target variable\n",
    "    df_outcomes['target_btc_diff_from_strike'] = df_outcomes['btc_price_at_resolution'] - df_outcomes['kalshi_strike_price']\n",
    "    \n",
    "    # Drop rows where target could not be calculated\n",
    "    original_len = len(df_outcomes)\n",
    "    df_outcomes.dropna(subset=['btc_price_at_resolution', 'target_btc_diff_from_strike'], inplace=True)\n",
    "    logger.info(f\"Dropped {original_len - len(df_outcomes)} rows due to missing BTC price at resolution for target calculation.\")\n",
    "    \n",
    "    logger.info(f\"Target variable 'target_btc_diff_from_strike' calculated for {len(df_outcomes)} markets.\")\n",
    "    print(\"\\nOutcomes DataFrame with target variable (head):\")\n",
    "    print(df_outcomes[['market_ticker', 'kalshi_strike_price', 'event_resolution_time_iso', 'btc_price_at_resolution', 'target_btc_diff_from_strike']].head())\n",
    "    print(\"\\nTarget variable statistics:\")\n",
    "    print(df_outcomes['target_btc_diff_from_strike'].describe())\n",
    "else:\n",
    "    logger.warning(\"Outcomes DataFrame is empty, cannot calculate target variable.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-19 12:08:43,654 - INFO - feature_engineering_20250519_120649.<module>:163 - Starting feature generation for 9192 Kalshi markets.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df2ba265359d418d82a2be7737216b25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Kalshi Markets:   0%|          | 0/9192 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/43/br9zl9l149d3rb94gdkr1wsm0000gn/T/ipykernel_11837/553029708.py:110: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['btc_rsi'].fillna(50, inplace=True) # Fill initial NaNs/Infs with neutral 50\n",
      "/var/folders/43/br9zl9l149d3rb94gdkr1wsm0000gn/T/ipykernel_11837/553029708.py:110: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['btc_rsi'].fillna(50, inplace=True) # Fill initial NaNs/Infs with neutral 50\n",
      "/var/folders/43/br9zl9l149d3rb94gdkr1wsm0000gn/T/ipykernel_11837/553029708.py:110: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['btc_rsi'].fillna(50, inplace=True) # Fill initial NaNs/Infs with neutral 50\n",
      "/var/folders/43/br9zl9l149d3rb94gdkr1wsm0000gn/T/ipykernel_11837/553029708.py:110: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['btc_rsi'].fillna(50, inplace=True) # Fill initial NaNs/Infs with neutral 50\n",
      "/var/folders/43/br9zl9l149d3rb94gdkr1wsm0000gn/T/ipykernel_11837/553029708.py:110: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['btc_rsi'].fillna(50, inplace=True) # Fill initial NaNs/Infs with neutral 50\n",
      "/var/folders/43/br9zl9l149d3rb94gdkr1wsm0000gn/T/ipykernel_11837/553029708.py:110: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['btc_rsi'].fillna(50, inplace=True) # Fill initial NaNs/Infs with neutral 50\n",
      "/var/folders/43/br9zl9l149d3rb94gdkr1wsm0000gn/T/ipykernel_11837/553029708.py:110: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['btc_rsi'].fillna(50, inplace=True) # Fill initial NaNs/Infs with neutral 50\n",
      "/var/folders/43/br9zl9l149d3rb94gdkr1wsm0000gn/T/ipykernel_11837/553029708.py:110: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['btc_rsi'].fillna(50, inplace=True) # Fill initial NaNs/Infs with neutral 50\n",
      "/var/folders/43/br9zl9l149d3rb94gdkr1wsm0000gn/T/ipykernel_11837/553029708.py:110: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['btc_rsi'].fillna(50, inplace=True) # Fill initial NaNs/Infs with neutral 50\n",
      "/var/folders/43/br9zl9l149d3rb94gdkr1wsm0000gn/T/ipykernel_11837/553029708.py:110: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['btc_rsi'].fillna(50, inplace=True) # Fill initial NaNs/Infs with neutral 50\n",
      "/var/folders/43/br9zl9l149d3rb94gdkr1wsm0000gn/T/ipykernel_11837/553029708.py:110: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['btc_rsi'].fillna(50, inplace=True) # Fill initial NaNs/Infs with neutral 50\n",
      "/var/folders/43/br9zl9l149d3rb94gdkr1wsm0000gn/T/ipykernel_11837/553029708.py:110: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['btc_rsi'].fillna(50, inplace=True) # Fill initial NaNs/Infs with neutral 50\n",
      "/var/folders/43/br9zl9l149d3rb94gdkr1wsm0000gn/T/ipykernel_11837/553029708.py:110: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['btc_rsi'].fillna(50, inplace=True) # Fill initial NaNs/Infs with neutral 50\n",
      "/var/folders/43/br9zl9l149d3rb94gdkr1wsm0000gn/T/ipykernel_11837/553029708.py:110: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['btc_rsi'].fillna(50, inplace=True) # Fill initial NaNs/Infs with neutral 50\n",
      "/var/folders/43/br9zl9l149d3rb94gdkr1wsm0000gn/T/ipykernel_11837/553029708.py:110: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['btc_rsi'].fillna(50, inplace=True) # Fill initial NaNs/Infs with neutral 50\n",
      "/var/folders/43/br9zl9l149d3rb94gdkr1wsm0000gn/T/ipykernel_11837/553029708.py:110: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['btc_rsi'].fillna(50, inplace=True) # Fill initial NaNs/Infs with neutral 50\n",
      "/var/folders/43/br9zl9l149d3rb94gdkr1wsm0000gn/T/ipykernel_11837/553029708.py:110: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['btc_rsi'].fillna(50, inplace=True) # Fill initial NaNs/Infs with neutral 50\n",
      "/var/folders/43/br9zl9l149d3rb94gdkr1wsm0000gn/T/ipykernel_11837/553029708.py:110: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['btc_rsi'].fillna(50, inplace=True) # Fill initial NaNs/Infs with neutral 50\n",
      "/var/folders/43/br9zl9l149d3rb94gdkr1wsm0000gn/T/ipykernel_11837/553029708.py:110: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['btc_rsi'].fillna(50, inplace=True) # Fill initial NaNs/Infs with neutral 50\n",
      "/var/folders/43/br9zl9l149d3rb94gdkr1wsm0000gn/T/ipykernel_11837/553029708.py:110: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['btc_rsi'].fillna(50, inplace=True) # Fill initial NaNs/Infs with neutral 50\n",
      "/var/folders/43/br9zl9l149d3rb94gdkr1wsm0000gn/T/ipykernel_11837/553029708.py:110: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['btc_rsi'].fillna(50, inplace=True) # Fill initial NaNs/Infs with neutral 50\n",
      "/var/folders/43/br9zl9l149d3rb94gdkr1wsm0000gn/T/ipykernel_11837/553029708.py:110: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['btc_rsi'].fillna(50, inplace=True) # Fill initial NaNs/Infs with neutral 50\n",
      "/var/folders/43/br9zl9l149d3rb94gdkr1wsm0000gn/T/ipykernel_11837/553029708.py:110: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['btc_rsi'].fillna(50, inplace=True) # Fill initial NaNs/Infs with neutral 50\n",
      "/var/folders/43/br9zl9l149d3rb94gdkr1wsm0000gn/T/ipykernel_11837/553029708.py:110: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['btc_rsi'].fillna(50, inplace=True) # Fill initial NaNs/Infs with neutral 50\n",
      "/var/folders/43/br9zl9l149d3rb94gdkr1wsm0000gn/T/ipykernel_11837/553029708.py:110: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['btc_rsi'].fillna(50, inplace=True) # Fill initial NaNs/Infs with neutral 50\n",
      "/var/folders/43/br9zl9l149d3rb94gdkr1wsm0000gn/T/ipykernel_11837/553029708.py:110: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['btc_rsi'].fillna(50, inplace=True) # Fill initial NaNs/Infs with neutral 50\n",
      "/var/folders/43/br9zl9l149d3rb94gdkr1wsm0000gn/T/ipykernel_11837/553029708.py:110: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['btc_rsi'].fillna(50, inplace=True) # Fill initial NaNs/Infs with neutral 50\n",
      "/var/folders/43/br9zl9l149d3rb94gdkr1wsm0000gn/T/ipykernel_11837/553029708.py:110: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['btc_rsi'].fillna(50, inplace=True) # Fill initial NaNs/Infs with neutral 50\n",
      "/var/folders/43/br9zl9l149d3rb94gdkr1wsm0000gn/T/ipykernel_11837/553029708.py:110: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['btc_rsi'].fillna(50, inplace=True) # Fill initial NaNs/Infs with neutral 50\n",
      "/var/folders/43/br9zl9l149d3rb94gdkr1wsm0000gn/T/ipykernel_11837/553029708.py:110: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['btc_rsi'].fillna(50, inplace=True) # Fill initial NaNs/Infs with neutral 50\n",
      "/var/folders/43/br9zl9l149d3rb94gdkr1wsm0000gn/T/ipykernel_11837/553029708.py:110: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['btc_rsi'].fillna(50, inplace=True) # Fill initial NaNs/Infs with neutral 50\n",
      "/var/folders/43/br9zl9l149d3rb94gdkr1wsm0000gn/T/ipykernel_11837/553029708.py:110: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['btc_rsi'].fillna(50, inplace=True) # Fill initial NaNs/Infs with neutral 50\n",
      "/var/folders/43/br9zl9l149d3rb94gdkr1wsm0000gn/T/ipykernel_11837/553029708.py:110: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['btc_rsi'].fillna(50, inplace=True) # Fill initial NaNs/Infs with neutral 50\n",
      "/var/folders/43/br9zl9l149d3rb94gdkr1wsm0000gn/T/ipykernel_11837/553029708.py:110: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['btc_rsi'].fillna(50, inplace=True) # Fill initial NaNs/Infs with neutral 50\n",
      "/var/folders/43/br9zl9l149d3rb94gdkr1wsm0000gn/T/ipykernel_11837/553029708.py:110: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['btc_rsi'].fillna(50, inplace=True) # Fill initial NaNs/Infs with neutral 50\n",
      "/var/folders/43/br9zl9l149d3rb94gdkr1wsm0000gn/T/ipykernel_11837/553029708.py:110: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['btc_rsi'].fillna(50, inplace=True) # Fill initial NaNs/Infs with neutral 50\n",
      "2025-05-19 12:15:57,998 - INFO - feature_engineering_20250519_120649.<module>:274 - Generated 1294800 feature records in total.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample of generated features (first 5 rows):\n",
      "          kalshi_market_ticker  decision_point_ts_utc  kalshi_strike_price  btc_price_t_minus_1  btc_mom_5m  btc_mom_10m  btc_mom_15m  btc_mom_30m  btc_vol_15m  btc_sma_10m    btc_sma_30m    btc_ema_12m    btc_ema_26m    btc_rsi  distance_to_strike  time_until_market_close_min  hour_of_day_utc  day_of_week_utc  hour_of_day_edt  TARGET_btc_diff_from_strike  kalshi_yes_bid  kalshi_yes_ask  kalshi_spread  kalshi_mid_price  kalshi_volume_t_minus_1  kalshi_open_interest_t_minus_1  kalshi_mid_chg_1m  kalshi_mid_chg_3m  kalshi_mid_chg_5m\n",
      "0  KXBTCD-25MAY1522-T106249.99             1747357200            106249.99            103764.81       73.29       -69.79      -182.17        22.80    95.991753   103732.700  103868.674000  103766.593435  103814.379274  30.460910            -2485.18                         60.0                1                4               21                     -2011.89             NaN             NaN            NaN               NaN                      NaN                             NaN                NaN                NaN                NaN\n",
      "1  KXBTCD-25MAY1522-T106249.99             1747357260            106249.99            103709.10       17.67      -111.60      -246.90       -68.90    86.424046   103721.540  103866.377333  103757.748291  103806.580809  30.493943            -2540.89                         59.0                1                4               21                     -2011.89             NaN             NaN            NaN               NaN                      NaN                             NaN                NaN                NaN                NaN\n",
      "2  KXBTCD-25MAY1522-T106249.99             1747357320            106249.99            103785.66       83.21         7.89      -114.10      -109.26    79.377628   103722.329  103862.735333  103762.042400  103805.031120  37.774318            -2464.33                         58.0                1                4               21                     -2011.89             0.0            30.0           30.0              15.0                      0.0                             0.0                NaN                NaN                NaN\n",
      "3  KXBTCD-25MAY1522-T106249.99             1747357380            106249.99            103691.25      -34.40         5.91      -227.89      -285.74    69.408713   103722.920  103853.210667  103751.151262  103796.602888  30.708083            -2558.74                         57.0                1                4               21                     -2011.89             0.0            30.0           30.0              15.0                      0.0                             0.0                0.0                NaN                NaN\n",
      "4  KXBTCD-25MAY1522-T106249.99             1747357440            106249.99            103629.36     -110.19       -98.42      -303.61      -299.95    55.815136   103713.078  103843.212333  103732.414145  103784.214526  32.606780            -2620.63                         56.0                1                4               21                     -2011.89             0.0            30.0           30.0              15.0                      0.0                             0.0                0.0                NaN                NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-19 12:16:09,886 - INFO - feature_engineering_20250519_120649.<module>:284 - Successfully saved features and target to: /Users/omarabul-hassan/Desktop/projects/kalshi/notebooks/kalshi_btc_features_target_v1_20250519_121558.csv\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Feature Generation Loop\n",
    "\n",
    "# --- Helper function to parse Kalshi tickers (needed for directory lookup) ---\n",
    "# This function was previously in the NTM data download notebook.\n",
    "# We need it here to correctly locate Kalshi market CSV files.\n",
    "def get_event_resolution_details(ticker_string: str | None):\n",
    "    if not ticker_string: return None\n",
    "    # Pattern for event ticker like KXBTCD-25MAY1523 (less common here, mostly market tickers)\n",
    "    event_match = re.match(r\"^(.*?)-(\\d{2}[A-Z]{3}\\d{2})(\\d{2})$\", ticker_string)\n",
    "    # Pattern for market ticker like KXBTCD-25MAY1523-T104999.99\n",
    "    market_match = re.match(r\"^(.*?)-(\\d{2}[A-Z]{3}\\d{2})(\\d{2})-(T(\\d+\\.?\\d*))$\", ticker_string)\n",
    "    \n",
    "    match_to_use = market_match if market_match else event_match\n",
    "    if not match_to_use:\n",
    "        # logger.debug(f\"Ticker {ticker_string} did not match event/market pattern in get_event_resolution_details.\")\n",
    "        return None\n",
    "        \n",
    "    groups = match_to_use.groups()\n",
    "    series, date_str_yymmmdd, hour_str_edt = groups[0], groups[1], groups[2]\n",
    "    # Strike price is only present in market_match\n",
    "    strike_price = float(groups[4]) if market_match and len(groups) > 4 and groups[4] else None\n",
    "    \n",
    "    try:\n",
    "        year_int = 2000 + int(date_str_yymmmdd[:2])\n",
    "        month_str = date_str_yymmmdd[2:5].upper()\n",
    "        day_int = int(date_str_yymmmdd[5:])\n",
    "        month_map = {'JAN': 1, 'FEB': 2, 'MAR': 3, 'APR': 4, 'MAY': 5, 'JUN': 6,\n",
    "                     'JUL': 7, 'AUG': 8, 'SEP': 9, 'OCT': 10, 'NOV': 11, 'DEC': 12}\n",
    "        month_int = month_map[month_str]\n",
    "        hour_edt_int = int(hour_str_edt) # This is the closing hour in EDT\n",
    "        \n",
    "        # For event_resolution_dt_utc, it's the same logic as before\n",
    "        event_resolution_dt_naive_edt = dt.datetime(year_int, month_int, day_int, hour_edt_int, 0, 0)\n",
    "        utc_offset_hours = 4 # Assuming EDT is UTC-4\n",
    "        event_resolution_dt_utc_aware = event_resolution_dt_naive_edt.replace(tzinfo=timezone(timedelta(hours=-utc_offset_hours)))\n",
    "        event_resolution_dt_utc = event_resolution_dt_utc_aware.astimezone(timezone.utc)\n",
    "        \n",
    "        return {\n",
    "            \"series\": series,\n",
    "            \"date_str_yymmmdd\": date_str_yymmmdd, # e.g., 25MAY15\n",
    "            \"hour_str_edt\": hour_str_edt,         # e.g., 23 (closing hour EDT)\n",
    "            \"strike_price\": strike_price,         # Can be None if it was an event_ticker\n",
    "            \"event_resolution_dt_utc\": event_resolution_dt_utc\n",
    "        }\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error parsing ticker '{ticker_string}' in get_event_resolution_details: {e}\")\n",
    "        return None\n",
    "\n",
    "# --- Binance Data Loading and Feature Calculation Helpers ---\n",
    "# Cache for daily Binance data with pre-calculated TA features\n",
    "_binance_daily_data_with_features_cache = {}\n",
    "\n",
    "def get_binance_data_with_features(date_str: str) -> pd.DataFrame | None:\n",
    "    \"\"\"\n",
    "    Loads Binance 1-minute data for a given date_str (YYYY-MM-DD),\n",
    "    calculates TA features, and caches it.\n",
    "    Assumes feature configuration variables (BTC_MOMENTUM_WINDOWS, etc.)\n",
    "    are defined globally (e.g., in Cell 1).\n",
    "    \"\"\"\n",
    "    global _binance_daily_data_with_features_cache # To modify the cache\n",
    "    \n",
    "    # Check if configuration variables are globally defined (they should be by Cell 1)\n",
    "    # If any are missing, log an error and return None as features cannot be calculated.\n",
    "    required_configs = [\n",
    "        'BINANCE_FLAT_DATA_DIR', 'BTC_MOMENTUM_WINDOWS', 'BTC_VOLATILITY_WINDOW',\n",
    "        'BTC_SMA_WINDOWS', 'BTC_EMA_WINDOWS', 'BTC_RSI_WINDOW'\n",
    "    ]\n",
    "    for config_var_name in required_configs:\n",
    "        if config_var_name not in globals():\n",
    "            logger.error(f\"Global configuration variable '{config_var_name}' not defined. Cannot calculate Binance features.\")\n",
    "            return None\n",
    "\n",
    "    if date_str in _binance_daily_data_with_features_cache:\n",
    "        cached_df = _binance_daily_data_with_features_cache[date_str]\n",
    "        return cached_df.copy() if cached_df is not None else None\n",
    "\n",
    "    filepath = BINANCE_FLAT_DATA_DIR / f\"BTCUSDT-1m-{date_str}.csv\"\n",
    "    if not filepath.exists():\n",
    "        _binance_daily_data_with_features_cache[date_str] = None\n",
    "        return None\n",
    "        \n",
    "    try:\n",
    "        column_names = [\"open_time_raw\", \"open\", \"high\", \"low\", \"close\", \"volume\",\n",
    "                        \"close_time_ms\", \"quote_asset_volume\", \"number_of_trades\",\n",
    "                        \"taker_buy_base_asset_volume\", \"taker_buy_quote_asset_volume\", \"ignore\"]\n",
    "        df = pd.read_csv(filepath, header=None, names=column_names)\n",
    "        df['timestamp_s'] = df['open_time_raw'] // 1_000_000\n",
    "        df.set_index('timestamp_s', inplace=True)\n",
    "        \n",
    "        for col in ['open', 'high', 'low', 'close', 'volume']:\n",
    "            df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "        df.dropna(subset=['close'], inplace=True) \n",
    "\n",
    "        # Access global configuration variables directly\n",
    "        for window in BTC_MOMENTUM_WINDOWS: # Uses global BTC_MOMENTUM_WINDOWS\n",
    "            df[f'btc_mom_{window}m'] = df['close'].diff(periods=window)\n",
    "        df[f'btc_vol_{BTC_VOLATILITY_WINDOW}m'] = df['close'].rolling(window=BTC_VOLATILITY_WINDOW, min_periods=1).std() # Uses global BTC_VOLATILITY_WINDOW\n",
    "        for window in BTC_SMA_WINDOWS: # Uses global BTC_SMA_WINDOWS\n",
    "            df[f'btc_sma_{window}m'] = df['close'].rolling(window=window, min_periods=1).mean()\n",
    "        for window in BTC_EMA_WINDOWS: # Uses global BTC_EMA_WINDOWS\n",
    "            df[f'btc_ema_{window}m'] = df['close'].ewm(span=window, adjust=False, min_periods=1).mean()\n",
    "        if BTC_RSI_WINDOW > 0: # Uses global BTC_RSI_WINDOW\n",
    "            delta = df['close'].diff(1)\n",
    "            gain = delta.where(delta > 0, 0)\n",
    "            loss = -delta.where(delta < 0, 0)\n",
    "            avg_gain = gain.rolling(window=BTC_RSI_WINDOW, min_periods=1).mean()\n",
    "            avg_loss = loss.rolling(window=BTC_RSI_WINDOW, min_periods=1).mean()\n",
    "            rs = avg_gain / avg_loss.replace(0, 0.000001) # Avoid division by zero for rs\n",
    "            df['btc_rsi'] = 100 - (100 / (1 + rs))\n",
    "            df['btc_rsi'].fillna(50, inplace=True) # Fill initial NaNs/Infs with neutral 50\n",
    "\n",
    "        _binance_daily_data_with_features_cache[date_str] = df\n",
    "        return df.copy()\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"FeatureGen: Error loading/processing Binance data from {filepath}: {e}\")\n",
    "        _binance_daily_data_with_features_cache[date_str] = None\n",
    "        return None\n",
    "\n",
    "# --- Kalshi Data Loading Helper ---\n",
    "_kalshi_market_data_cache = {}\n",
    "\n",
    "def load_kalshi_market_data(market_ticker: str, date_str_yymmmdd: str, hour_str_edt: str) -> pd.DataFrame | None:\n",
    "    global _kalshi_market_data_cache\n",
    "    \n",
    "    if 'KALSHI_NTM_DATA_DIR' not in globals():\n",
    "        logger.error(\"KALSHI_NTM_DATA_DIR not defined globally. Cannot load Kalshi data.\")\n",
    "        return None\n",
    "\n",
    "    if market_ticker in _kalshi_market_data_cache:\n",
    "        cached_df = _kalshi_market_data_cache[market_ticker]\n",
    "        return cached_df.copy() if cached_df is not None else None\n",
    "    \n",
    "    filepath = KALSHI_NTM_DATA_DIR / date_str_yymmmdd / hour_str_edt.zfill(2) / f\"{market_ticker}.csv\"\n",
    "    if not filepath.exists():\n",
    "        _kalshi_market_data_cache[market_ticker] = None\n",
    "        return None\n",
    "    try:\n",
    "        df = pd.read_csv(filepath)\n",
    "        if df.empty:\n",
    "            _kalshi_market_data_cache[market_ticker] = pd.DataFrame()\n",
    "            return pd.DataFrame()\n",
    "            \n",
    "        df['timestamp_s'] = pd.to_numeric(df['timestamp_s'])\n",
    "        df.set_index('timestamp_s', inplace=True)\n",
    "        for col in df.columns:\n",
    "            if 'cents' in col or 'volume' in col or 'interest' in col:\n",
    "                df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "        _kalshi_market_data_cache[market_ticker] = df\n",
    "        return df.copy()\n",
    "    except Exception as e:\n",
    "        logger.error(f\"FeatureGen: Error loading Kalshi market data from {filepath}: {e}\")\n",
    "        _kalshi_market_data_cache[market_ticker] = None\n",
    "        return None\n",
    "\n",
    "# --- Main Feature List ---\n",
    "all_feature_records = []\n",
    "\n",
    "# Ensure df_outcomes is not empty (should be loaded in Cell 2)\n",
    "if 'df_outcomes' not in globals() or df_outcomes.empty:\n",
    "    logger.error(\"df_outcomes is not defined or is empty. Please run Cell 2 first.\")\n",
    "else:\n",
    "    logger.info(f\"Starting feature generation for {len(df_outcomes)} Kalshi markets.\")\n",
    "\n",
    "    for idx, market_row in tqdm(df_outcomes.iterrows(), total=len(df_outcomes), desc=\"Processing Kalshi Markets\"):\n",
    "        kalshi_market_ticker = market_row['market_ticker']\n",
    "        kalshi_strike_price = market_row['kalshi_strike_price']\n",
    "        kalshi_market_open_dt = market_row['market_open_time_iso']\n",
    "        kalshi_market_close_dt = market_row['market_close_time_iso']\n",
    "        target_value = market_row['target_btc_diff_from_strike']\n",
    "\n",
    "        if pd.isna(kalshi_market_open_dt) or pd.isna(kalshi_market_close_dt):\n",
    "            logger.warning(f\"Market {kalshi_market_ticker} has invalid open/close times. Skipping.\")\n",
    "            continue\n",
    "            \n",
    "        parsed_ticker_info = get_event_resolution_details(kalshi_market_ticker)\n",
    "        if not parsed_ticker_info:\n",
    "            logger.warning(f\"Could not parse {kalshi_market_ticker} for dir info. Skipping market.\")\n",
    "            continue\n",
    "        if not all(k in parsed_ticker_info for k in [\"date_str_yymmmdd\", \"hour_str_edt\"]):\n",
    "            logger.warning(f\"Parsed info for {kalshi_market_ticker} missing date/hour for dir. Parsed: {parsed_ticker_info}. Skipping.\")\n",
    "            continue\n",
    "\n",
    "        date_dir_str = parsed_ticker_info[\"date_str_yymmmdd\"]\n",
    "        hour_dir_str = parsed_ticker_info[\"hour_str_edt\"]\n",
    "\n",
    "        df_kalshi_market = load_kalshi_market_data(kalshi_market_ticker, date_dir_str, hour_dir_str)\n",
    "        if df_kalshi_market is None or df_kalshi_market.empty:\n",
    "            continue\n",
    "\n",
    "        current_minute_dt = kalshi_market_open_dt\n",
    "        while current_minute_dt < kalshi_market_close_dt:\n",
    "            decision_point_dt_utc = current_minute_dt \n",
    "            decision_point_ts_utc = int(decision_point_dt_utc.timestamp())\n",
    "            signal_ts_utc = decision_point_ts_utc - 60\n",
    "            \n",
    "            signal_dt_utc_obj = dt.datetime.fromtimestamp(signal_ts_utc, tz=timezone.utc)\n",
    "            binance_day_str = signal_dt_utc_obj.strftime(\"%Y-%m-%d\")\n",
    "            df_binance_day_features = get_binance_data_with_features(binance_day_str)\n",
    "\n",
    "            btc_features = {}\n",
    "            if df_binance_day_features is not None and not df_binance_day_features.empty:\n",
    "                if signal_ts_utc in df_binance_day_features.index:\n",
    "                    btc_row = df_binance_day_features.loc[signal_ts_utc]\n",
    "                    btc_features['btc_price_t_minus_1'] = btc_row['close']\n",
    "                    # Access global feature config variables directly\n",
    "                    for window in BTC_MOMENTUM_WINDOWS: btc_features[f'btc_mom_{window}m'] = btc_row.get(f'btc_mom_{window}m')\n",
    "                    btc_features[f'btc_vol_{BTC_VOLATILITY_WINDOW}m'] = btc_row.get(f'btc_vol_{BTC_VOLATILITY_WINDOW}m')\n",
    "                    for window in BTC_SMA_WINDOWS: btc_features[f'btc_sma_{window}m'] = btc_row.get(f'btc_sma_{window}m')\n",
    "                    for window in BTC_EMA_WINDOWS: btc_features[f'btc_ema_{window}m'] = btc_row.get(f'btc_ema_{window}m')\n",
    "                    if BTC_RSI_WINDOW > 0: btc_features['btc_rsi'] = btc_row.get('btc_rsi')\n",
    "            \n",
    "            if 'btc_price_t_minus_1' not in btc_features or pd.isna(btc_features['btc_price_t_minus_1']):\n",
    "                current_minute_dt += timedelta(minutes=1)\n",
    "                continue\n",
    "            \n",
    "            kalshi_features = {}\n",
    "            relevant_kalshi_rows = df_kalshi_market[df_kalshi_market.index <= signal_ts_utc]\n",
    "            if not relevant_kalshi_rows.empty:\n",
    "                latest_kalshi_row = relevant_kalshi_rows.iloc[-1]\n",
    "                latest_kalshi_ts = latest_kalshi_row.name\n",
    "                \n",
    "                if 'KALSHI_MAX_STALENESS_SECONDS' not in globals(): KALSHI_MAX_STALENESS_SECONDS = 120\n",
    "                \n",
    "                if (signal_ts_utc - latest_kalshi_ts) <= KALSHI_MAX_STALENESS_SECONDS:\n",
    "                    kalshi_features['kalshi_yes_bid'] = latest_kalshi_row.get('yes_bid_close_cents')\n",
    "                    kalshi_features['kalshi_yes_ask'] = latest_kalshi_row.get('yes_ask_close_cents')\n",
    "                    \n",
    "                    if pd.notna(kalshi_features.get('kalshi_yes_bid')) and pd.notna(kalshi_features.get('kalshi_yes_ask')):\n",
    "                        kalshi_features['kalshi_spread'] = kalshi_features['kalshi_yes_ask'] - kalshi_features['kalshi_yes_bid']\n",
    "                        kalshi_features['kalshi_mid_price'] = (kalshi_features['kalshi_yes_bid'] + kalshi_features['kalshi_yes_ask']) / 2\n",
    "                    \n",
    "                    if 'KALSHI_PRICE_CHANGE_WINDOWS' not in globals(): KALSHI_PRICE_CHANGE_WINDOWS = [1,3,5]\n",
    "\n",
    "                    for window in KALSHI_PRICE_CHANGE_WINDOWS:\n",
    "                        prev_mid_price_ts = signal_ts_utc - (window * 60)\n",
    "                        prev_mid_rows = df_kalshi_market[df_kalshi_market.index <= prev_mid_price_ts]\n",
    "                        if not prev_mid_rows.empty and 'kalshi_mid_price' in kalshi_features and pd.notna(kalshi_features.get('kalshi_mid_price')):\n",
    "                            prev_mid_latest_row = prev_mid_rows.iloc[-1]\n",
    "                            prev_yes_bid = prev_mid_latest_row.get('yes_bid_close_cents')\n",
    "                            prev_yes_ask = prev_mid_latest_row.get('yes_ask_close_cents')\n",
    "                            if pd.notna(prev_yes_bid) and pd.notna(prev_yes_ask):\n",
    "                                prev_mid = (prev_yes_bid + prev_yes_ask) / 2\n",
    "                                kalshi_features[f'kalshi_mid_chg_{window}m'] = kalshi_features['kalshi_mid_price'] - prev_mid\n",
    "                    \n",
    "                    kalshi_features['kalshi_volume_t_minus_1'] = latest_kalshi_row.get('volume')\n",
    "                    kalshi_features['kalshi_open_interest_t_minus_1'] = latest_kalshi_row.get('open_interest')\n",
    "\n",
    "            kalshi_features['distance_to_strike'] = btc_features['btc_price_t_minus_1'] - kalshi_strike_price\n",
    "\n",
    "            time_features = {}\n",
    "            time_features['time_until_market_close_min'] = (kalshi_market_close_dt - decision_point_dt_utc).total_seconds() / 60\n",
    "            time_features['hour_of_day_utc'] = decision_point_dt_utc.hour \n",
    "            time_features['day_of_week_utc'] = decision_point_dt_utc.weekday()\n",
    "            decision_point_dt_edt = decision_point_dt_utc.astimezone(timezone(timedelta(hours=-4)))\n",
    "            time_features['hour_of_day_edt'] = decision_point_dt_edt.hour\n",
    "\n",
    "            current_record = {\n",
    "                'kalshi_market_ticker': kalshi_market_ticker,\n",
    "                'decision_point_ts_utc': decision_point_ts_utc,\n",
    "                'kalshi_strike_price': kalshi_strike_price,\n",
    "                **btc_features, **kalshi_features, **time_features,\n",
    "                'TARGET_btc_diff_from_strike': target_value\n",
    "            }\n",
    "            all_feature_records.append(current_record)\n",
    "            current_minute_dt += timedelta(minutes=1)\n",
    "\n",
    "        if kalshi_market_ticker in _kalshi_market_data_cache: # Check before popping\n",
    "            _kalshi_market_data_cache.pop(kalshi_market_ticker, None)\n",
    "    \n",
    "    _binance_daily_data_with_features_cache = {}\n",
    "\n",
    "df_features = pd.DataFrame(all_feature_records)\n",
    "logger.info(f\"Generated {len(df_features)} feature records in total.\")\n",
    "\n",
    "if not df_features.empty:\n",
    "    print(\"\\nSample of generated features (first 5 rows):\")\n",
    "    print(df_features.head().to_string())\n",
    "    \n",
    "    save_dir = Path.cwd()\n",
    "    features_csv_path = save_dir / f\"kalshi_btc_features_target_v1_{dt.datetime.now().strftime('%Y%m%d_%H%M%S')}.csv\"\n",
    "    try:\n",
    "        df_features.to_csv(features_csv_path, index=False)\n",
    "        logger.info(f\"Successfully saved features and target to: {features_csv_path}\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error saving features DataFrame to CSV: {e}\")\n",
    "else:\n",
    "    logger.warning(\"No feature records were generated.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
