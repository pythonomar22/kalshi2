{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Imports and Setup\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import glob\n",
    "import os\n",
    "import logging\n",
    "import datetime as dt # For type hinting if needed, pandas handles most conversions\n",
    "\n",
    "# --- Logging Setup ---\n",
    "logger_eda = logging.getLogger(\"eda_backtest_logs\")\n",
    "if not logger_eda.handlers:\n",
    "    logger_eda.setLevel(logging.INFO)\n",
    "    formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(name)s - %(message)s')\n",
    "    ch = logging.StreamHandler()\n",
    "    ch.setFormatter(formatter)\n",
    "    logger_eda.addHandler(ch)\n",
    "else:\n",
    "    logger_eda.setLevel(logging.INFO)\n",
    "\n",
    "# --- Directories ---\n",
    "# Assuming this notebook is in /notebooks/eda/\n",
    "# Adjust if your notebook is elsewhere relative to the project root.\n",
    "BASE_PROJECT_DIR = Path(\"/Users/omarabul-hassan/Desktop/projects/kalshi\")\n",
    "NOTEBOOKS_DIR = BASE_PROJECT_DIR / \"notebooks\"\n",
    "BACKTEST_DIR = NOTEBOOKS_DIR / \"backtest\"\n",
    "LOG_DIR_FROM_BACKTEST = BACKTEST_DIR / \"logs\" # Where the trade logs are saved\n",
    "\n",
    "# --- Plotting Style ---\n",
    "plt.style.use('seaborn-v0_8-whitegrid') # Using a seaborn style\n",
    "sns.set_palette(\"pastel\")\n",
    "\n",
    "logger_eda.info(f\"Trade logs expected from: {LOG_DIR_FROM_BACKTEST}\")\n",
    "logger_eda.info(\"EDA Setup complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Load and Consolidate Trade Logs\n",
    "\n",
    "if not LOG_DIR_FROM_BACKTEST.exists():\n",
    "    logger_eda.error(f\"Trade log directory not found: {LOG_DIR_FROM_BACKTEST}\")\n",
    "    all_trades_df = pd.DataFrame() # Create empty df to prevent errors later\n",
    "else:\n",
    "    log_files = sorted(list(LOG_DIR_FROM_BACKTEST.glob(\"*_trades.csv\")))\n",
    "    \n",
    "    if not log_files:\n",
    "        logger_eda.warning(f\"No trade log CSV files found in {LOG_DIR_FROM_BACKTEST}.\")\n",
    "        all_trades_df = pd.DataFrame()\n",
    "    else:\n",
    "        logger_eda.info(f\"Found {len(log_files)} trade log files. Consolidating...\")\n",
    "        df_list = []\n",
    "        for log_file in log_files:\n",
    "            try:\n",
    "                daily_df = pd.read_csv(log_file)\n",
    "                if not daily_df.empty:\n",
    "                    # Extract date from filename for verification or grouping if needed\n",
    "                    daily_df['log_file_date_str'] = log_file.stem.split('_trades')[0]\n",
    "                    df_list.append(daily_df)\n",
    "                else:\n",
    "                    logger_eda.info(f\"Log file {log_file.name} is empty.\")\n",
    "            except Exception as e:\n",
    "                logger_eda.error(f\"Error reading log file {log_file.name}: {e}\")\n",
    "        \n",
    "        if df_list:\n",
    "            all_trades_df = pd.concat(df_list, ignore_index=True)\n",
    "            logger_eda.info(f\"Consolidated {len(all_trades_df)} trades from {len(df_list)} non-empty log files.\")\n",
    "            \n",
    "            # --- Data Type Conversions and Basic Cleaning ---\n",
    "            # Convert timestamps\n",
    "            all_trades_df['trade_execution_time_utc'] = pd.to_datetime(all_trades_df['trade_execution_time_utc'])\n",
    "            all_trades_df['decision_timestamp_s'] = pd.to_numeric(all_trades_df['decision_timestamp_s'])\n",
    "            all_trades_df['resolution_time_ts'] = pd.to_numeric(all_trades_df['resolution_time_ts'])\n",
    "\n",
    "            # Ensure numeric types for P&L, costs etc.\n",
    "            numeric_cols = ['strike_price', 'predicted_prob_yes', 'bet_cost_cents', \n",
    "                            'contracts_traded', 'kalshi_outcome_target', 'pnl_cents', \n",
    "                            'time_to_resolution_minutes']\n",
    "            for col in numeric_cols:\n",
    "                if col in all_trades_df.columns:\n",
    "                    all_trades_df[col] = pd.to_numeric(all_trades_df[col], errors='coerce')\n",
    "            \n",
    "            # Sort by trade execution time\n",
    "            all_trades_df.sort_values(by='trade_execution_time_utc', inplace=True)\n",
    "            all_trades_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "            logger_eda.info(\"Data types converted and trades sorted.\")\n",
    "            display(all_trades_df.head())\n",
    "            # logger_eda.info(all_trades_df.info()) # For detailed type check\n",
    "        else:\n",
    "            logger_eda.info(\"No trade data loaded from log files.\")\n",
    "            all_trades_df = pd.DataFrame()\n",
    "\n",
    "if all_trades_df.empty:\n",
    "    logger_eda.warning(\"No trade data to analyze.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Overall Performance Metrics\n",
    "\n",
    "if not all_trades_df.empty:\n",
    "    total_pnl_cents = all_trades_df['pnl_cents'].sum()\n",
    "    total_trades = len(all_trades_df)\n",
    "    \n",
    "    wins = all_trades_df[all_trades_df['pnl_cents'] > 0]\n",
    "    losses = all_trades_df[all_trades_df['pnl_cents'] < 0]\n",
    "    num_wins = len(wins)\n",
    "    num_losses = len(losses)\n",
    "    \n",
    "    win_rate = num_wins / total_trades if total_trades > 0 else 0\n",
    "    \n",
    "    avg_pnl_per_trade_cents = all_trades_df['pnl_cents'].mean() if total_trades > 0 else 0\n",
    "    avg_win_cents = wins['pnl_cents'].mean() if num_wins > 0 else 0\n",
    "    avg_loss_cents = losses['pnl_cents'].mean() if num_losses > 0 else 0 # Will be negative\n",
    "    \n",
    "    profit_factor = wins['pnl_cents'].sum() / abs(losses['pnl_cents'].sum()) if num_losses > 0 and losses['pnl_cents'].sum() !=0 else np.inf\n",
    "\n",
    "    logger_eda.info(\"--- Overall Backtest Performance ---\")\n",
    "    logger_eda.info(f\"Total Trades: {total_trades}\")\n",
    "    logger_eda.info(f\"Total P&L: {total_pnl_cents / 100:.2f} USD\")\n",
    "    logger_eda.info(f\"Number of Wins: {num_wins}\")\n",
    "    logger_eda.info(f\"Number of Losses: {num_losses}\")\n",
    "    logger_eda.info(f\"Win Rate: {win_rate:.2%}\")\n",
    "    logger_eda.info(f\"Average P&L per Trade: {avg_pnl_per_trade_cents / 100:.4f} USD\")\n",
    "    logger_eda.info(f\"Average Win Amount: {avg_win_cents / 100:.2f} USD (when winning)\")\n",
    "    logger_eda.info(f\"Average Loss Amount: {avg_loss_cents / 100:.2f} USD (when losing)\")\n",
    "    logger_eda.info(f\"Profit Factor: {profit_factor:.2f}\")\n",
    "\n",
    "    # Display as a DataFrame for clarity\n",
    "    summary_data = {\n",
    "        \"Metric\": [\"Total Trades\", \"Total P&L (USD)\", \"Num Wins\", \"Num Losses\", \"Win Rate\", \n",
    "                   \"Avg P&L/Trade (USD)\", \"Avg Win (USD)\", \"Avg Loss (USD)\", \"Profit Factor\"],\n",
    "        \"Value\": [total_trades, f\"{total_pnl_cents / 100:.2f}\", num_wins, num_losses, f\"{win_rate:.2%}\",\n",
    "                  f\"{avg_pnl_per_trade_cents / 100:.4f}\", f\"{avg_win_cents / 100:.2f}\", \n",
    "                  f\"{avg_loss_cents / 100:.2f}\", f\"{profit_factor:.2f}\"]\n",
    "    }\n",
    "    summary_df = pd.DataFrame(summary_data)\n",
    "    display(summary_df)\n",
    "    \n",
    "else:\n",
    "    logger_eda.warning(\"all_trades_df is empty. Cannot calculate overall performance.\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: P&L Over Time (Equity Curve)\n",
    "\n",
    "if not all_trades_df.empty and 'pnl_cents' in all_trades_df.columns and 'trade_execution_time_utc' in all_trades_df.columns:\n",
    "    all_trades_df['cumulative_pnl_cents'] = all_trades_df['pnl_cents'].cumsum()\n",
    "    \n",
    "    plt.figure(figsize=(14, 7))\n",
    "    plt.plot(all_trades_df['trade_execution_time_utc'], all_trades_df['cumulative_pnl_cents'] / 100.0) # Convert to USD\n",
    "    plt.title('Cumulative P&L Over Backtest Period')\n",
    "    plt.xlabel('Trade Execution Time (UTC)')\n",
    "    plt.ylabel('Cumulative P&L (USD)')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "else:\n",
    "    logger_eda.warning(\"Cannot plot equity curve: DataFrame empty or required columns missing.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Performance by Day\n",
    "\n",
    "if not all_trades_df.empty and 'trade_execution_time_utc' in all_trades_df.columns:\n",
    "    # Extract just the date part for grouping\n",
    "    all_trades_df['decision_date'] = all_trades_df['trade_execution_time_utc'].dt.date\n",
    "    \n",
    "    daily_performance = all_trades_df.groupby('decision_date').agg(\n",
    "        total_trades_daily=('market_ticker', 'count'),\n",
    "        total_pnl_cents_daily=('pnl_cents', 'sum'),\n",
    "        win_rate_daily=('pnl_cents', lambda x: (x > 0).sum() / x.count() if x.count() > 0 else 0)\n",
    "    ).reset_index()\n",
    "    \n",
    "    daily_performance['total_pnl_usd_daily'] = daily_performance['total_pnl_cents_daily'] / 100.0\n",
    "    \n",
    "    logger_eda.info(\"\\n--- Daily Performance ---\")\n",
    "    display(daily_performance[['decision_date', 'total_trades_daily', 'total_pnl_usd_daily', 'win_rate_daily']])\n",
    "    \n",
    "    # Plot daily P&L\n",
    "    plt.figure(figsize=(14, 6))\n",
    "    plt.bar(daily_performance['decision_date'].astype(str), daily_performance['total_pnl_usd_daily'], \n",
    "            color=np.where(daily_performance['total_pnl_usd_daily'] >= 0, 'g', 'r'))\n",
    "    plt.title('Daily P&L (USD)')\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('P&L (USD)')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.grid(axis='y')\n",
    "    plt.show()\n",
    "    \n",
    "else:\n",
    "    logger_eda.warning(\"Cannot analyze daily performance: DataFrame empty or required columns missing.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: Analysis by Trade Action (BUY_YES vs BUY_NO)\n",
    "\n",
    "if not all_trades_df.empty and 'action' in all_trades_df.columns:\n",
    "    action_performance = all_trades_df.groupby('action').agg(\n",
    "        count=('market_ticker', 'size'),\n",
    "        total_pnl_cents=('pnl_cents', 'sum'),\n",
    "        avg_pnl_per_trade_cents=('pnl_cents', 'mean'),\n",
    "        win_count=('pnl_cents', lambda x: (x > 0).sum()),\n",
    "        loss_count=('pnl_cents', lambda x: (x < 0).sum())\n",
    "    ).reset_index()\n",
    "    \n",
    "    action_performance['win_rate'] = action_performance['win_count'] / (action_performance['win_count'] + action_performance['loss_count'])\n",
    "    action_performance['total_pnl_usd'] = action_performance['total_pnl_cents'] / 100.0\n",
    "    action_performance['avg_pnl_per_trade_usd'] = action_performance['avg_pnl_per_trade_cents'] / 100.0\n",
    "    \n",
    "    logger_eda.info(\"\\n--- Performance by Trade Action ---\")\n",
    "    display(action_performance[['action', 'count', 'total_pnl_usd', 'avg_pnl_per_trade_usd', 'win_rate']])\n",
    "else:\n",
    "    logger_eda.warning(\"Cannot analyze by trade action: DataFrame empty or 'action' column missing.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: Analysis by Predicted Probability\n",
    "\n",
    "if not all_trades_df.empty and 'predicted_prob_yes' in all_trades_df.columns:\n",
    "    logger_eda.info(\"\\n--- Predicted Probability Analysis ---\")\n",
    "    \n",
    "    # Distribution of predicted probabilities for BUY_YES trades\n",
    "    buy_yes_trades = all_trades_df[all_trades_df['action'] == 'BUY_YES']\n",
    "    if not buy_yes_trades.empty:\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        sns.histplot(buy_yes_trades['predicted_prob_yes'], bins=20, kde=False, color='skyblue')\n",
    "        plt.title('Distribution of Predicted P(Yes) for BUY_YES Trades')\n",
    "        plt.xlabel('Predicted P(Yes)')\n",
    "        plt.ylabel('Frequency')\n",
    "        plt.show()\n",
    "    else:\n",
    "        logger_eda.info(\"No BUY_YES trades to analyze for probability distribution.\")\n",
    "\n",
    "    # Distribution of predicted P(No) (1 - P(Yes)) for BUY_NO trades\n",
    "    buy_no_trades = all_trades_df[all_trades_df['action'] == 'BUY_NO']\n",
    "    if not buy_no_trades.empty:\n",
    "        buy_no_trades['predicted_prob_no'] = 1 - buy_no_trades['predicted_prob_yes']\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        sns.histplot(buy_no_trades['predicted_prob_no'], bins=20, kde=False, color='salmon')\n",
    "        plt.title('Distribution of Predicted P(No) for BUY_NO Trades')\n",
    "        plt.xlabel('Predicted P(No)')\n",
    "        plt.ylabel('Frequency')\n",
    "        plt.show()\n",
    "    else:\n",
    "        logger_eda.info(\"No BUY_NO trades to analyze for probability distribution.\")\n",
    "        \n",
    "    # P&L vs. Predicted Probability (binned)\n",
    "    # Create bins for predicted_prob_yes\n",
    "    # For BUY_YES, use predicted_prob_yes. For BUY_NO, use 1 - predicted_prob_yes (i.e. P(No))\n",
    "    # Let's create a 'confidence_in_bet_direction' column\n",
    "    \n",
    "    def calculate_confidence(row):\n",
    "        if row['action'] == 'BUY_YES':\n",
    "            return row['predicted_prob_yes']\n",
    "        elif row['action'] == 'BUY_NO':\n",
    "            return 1 - row['predicted_prob_yes']\n",
    "        return np.nan\n",
    "        \n",
    "    all_trades_df['confidence_in_bet_direction'] = all_trades_df.apply(calculate_confidence, axis=1)\n",
    "    \n",
    "    if 'confidence_in_bet_direction' in all_trades_df.columns and not all_trades_df['confidence_in_bet_direction'].isnull().all():\n",
    "        all_trades_df['prob_bin'] = pd.cut(all_trades_df['confidence_in_bet_direction'], bins=np.arange(0.5, 1.01, 0.05), right=False) # Bins from 0.5-0.55, 0.55-0.6 etc.\n",
    "    \n",
    "        binned_pnl = all_trades_df.groupby('prob_bin', observed=False).agg(\n",
    "            count=('market_ticker', 'size'),\n",
    "            avg_pnl_cents=('pnl_cents', 'mean'),\n",
    "            win_rate=('pnl_cents', lambda x: (x > 0).sum() / x.count() if x.count() > 0 else 0)\n",
    "        ).reset_index()\n",
    "        binned_pnl['avg_pnl_usd'] = binned_pnl['avg_pnl_cents'] / 100.0\n",
    "        \n",
    "        logger_eda.info(\"\\n--- P&L and Win Rate by Binned Model Confidence (in bet direction) ---\")\n",
    "        display(binned_pnl)\n",
    "    else:\n",
    "        logger_eda.info(\"Could not perform binned probability analysis.\")\n",
    "else:\n",
    "    logger_eda.warning(\"Cannot analyze by predicted probability: DataFrame empty or 'predicted_prob_yes' column missing.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8: Analysis by `time_to_resolution_minutes`\n",
    "\n",
    "if not all_trades_df.empty and 'time_to_resolution_minutes' in all_trades_df.columns:\n",
    "    logger_eda.info(\"\\n--- Performance by Time to Resolution at Decision ---\")\n",
    "    \n",
    "    # Create bins for time_to_resolution_minutes\n",
    "    # Example bins: (0-5], (5-15], (15-30], (30-60], (60+]\n",
    "    # The max time_to_resolution in your sample was ~1500 minutes.\n",
    "    # Let's use broader bins for hourly markets.\n",
    "    time_bins = [0, 5, 15, 30, 45, 60, np.inf] \n",
    "    time_labels = ['0-5min', '5-15min', '15-30min', '30-45min', '45-60min', '60+min'] \n",
    "    \n",
    "    # For per-minute, more granular bins might be better for the first hour\n",
    "    # time_bins = [0, 1, 3, 5, 10, 15, 30, 45, 59, np.inf]\n",
    "    # time_labels = ['T-1m','T-3m','T-5m','T-10m','T-15m','T-30m','T-45m', 'T-59m', 'Earlier']\n",
    "    # Using your feature engineering deltas: [1, 3, 5, 10, 15, 30, 45]\n",
    "    time_bins_from_features = sorted([0] + list(set(ft_delta for ft_delta in [1,3,5,10,15,30,45] if ft_delta > 0))) + [np.inf]\n",
    "    time_labels_from_features = []\n",
    "    for i in range(len(time_bins_from_features)-1):\n",
    "        if time_bins_from_features[i+1] == np.inf:\n",
    "            time_labels_from_features.append(f\"{time_bins_from_features[i]}+ min\")\n",
    "        else:\n",
    "            time_labels_from_features.append(f\"{time_bins_from_features[i]}-{time_bins_from_features[i+1]}min\")\n",
    "\n",
    "\n",
    "    all_trades_df['time_to_res_bin'] = pd.cut(all_trades_df['time_to_resolution_minutes'], \n",
    "                                              bins=time_bins_from_features, \n",
    "                                              labels=time_labels_from_features, \n",
    "                                              right=False, # [closed, open) interval\n",
    "                                              include_lowest=True) # Include 0 if it occurs\n",
    "\n",
    "    time_binned_performance = all_trades_df.groupby('time_to_res_bin', observed=False).agg(\n",
    "        count=('market_ticker', 'size'),\n",
    "        avg_pnl_cents=('pnl_cents', 'mean'),\n",
    "        total_pnl_cents=('pnl_cents', 'sum'),\n",
    "        win_rate=('pnl_cents', lambda x: (x > 0).sum() / x.count() if x.count() > 0 else 0)\n",
    "    ).reset_index()\n",
    "    time_binned_performance['avg_pnl_usd'] = time_binned_performance['avg_pnl_cents'] / 100.0\n",
    "    time_binned_performance['total_pnl_usd'] = time_binned_performance['total_pnl_cents'] / 100.0\n",
    "    \n",
    "    logger_eda.info(\"\\n--- P&L and Win Rate by Time to Resolution Bin ---\")\n",
    "    display(time_binned_performance[['time_to_res_bin', 'count', 'total_pnl_usd', 'avg_pnl_usd', 'win_rate']])\n",
    "\n",
    "    # Plot average P&L per trade by time to resolution bin\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.barplot(data=time_binned_performance, x='time_to_res_bin', y='avg_pnl_usd', palette=\"viridis\")\n",
    "    plt.title('Average P&L per Trade by Time to Resolution Bin')\n",
    "    plt.xlabel('Time to Resolution (Minutes from decision to market close)')\n",
    "    plt.ylabel('Average P&L (USD)')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    logger_eda.warning(\"Cannot analyze by time to resolution: DataFrame empty or column missing.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
